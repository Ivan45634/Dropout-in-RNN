{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBwZ3vJyifu8"
      },
      "source": [
        "# `Часть 0. Загрузка и предобработка данных (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMt5CNa0ifu9"
      },
      "source": [
        "## `Рекомендуемые гиперпараметры`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:28.454122Z",
          "start_time": "2021-04-02T00:04:28.438278Z"
        },
        "id": "lP5I0KgSifu9"
      },
      "outputs": [],
      "source": [
        "max_length = 200\n",
        "top_n_words = 5000\n",
        "\n",
        "hidden_dim = 128\n",
        "embedding_dim = 32\n",
        "\n",
        "num_epochs = 15\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8F6oL4Tifu-"
      },
      "source": [
        "Первое, что нужно сделать — скачать, предобработать данные и организовать их таким образом, чтобы их можно было подавать в нейронную сеть.\n",
        "\n",
        "Для обеих частей задания мы будем использовать [**Large Movie Review Dataset**](https://ai.stanford.edu/~amaas/data/sentiment/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN2xeAsFifu-"
      },
      "source": [
        "## `Загрузка и предобработка данных`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGBEUyBiifu-"
      },
      "source": [
        "Загрузите данные по ссылке выше. (**tip**: используйте `wget`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-30T18:34:47.261797Z",
          "start_time": "2021-03-30T18:34:33.768597Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LLJ8ttXifu_",
        "outputId": "d19c9c93-e310-460a-ee44-c14fb758a41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-27 10:46:01--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  33.7MB/s    in 2.4s    \n",
            "\n",
            "2023-04-27 10:46:03 (33.7 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koYuOndZifu_"
      },
      "source": [
        "Распакуйте скачанные данные в папку `aclImdb` (**tip:** используйте `tar`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-30T17:48:59.763990Z",
          "start_time": "2021-03-30T17:48:56.998383Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsHnhXjHifu_",
        "outputId": "f084bede-96a5-41ab-a84d-87e40851eabf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "aclImdb/train/unsup/44983_0.txt\n",
            "aclImdb/train/unsup/44982_0.txt\n",
            "aclImdb/train/unsup/44981_0.txt\n",
            "aclImdb/train/unsup/44980_0.txt\n",
            "aclImdb/train/unsup/44979_0.txt\n",
            "aclImdb/train/unsup/44978_0.txt\n",
            "aclImdb/train/unsup/44977_0.txt\n",
            "aclImdb/train/unsup/44976_0.txt\n",
            "aclImdb/train/unsup/44975_0.txt\n",
            "aclImdb/train/unsup/44974_0.txt\n",
            "aclImdb/train/unsup/44973_0.txt\n",
            "aclImdb/train/unsup/44972_0.txt\n",
            "aclImdb/train/unsup/44971_0.txt\n",
            "aclImdb/train/unsup/44970_0.txt\n",
            "aclImdb/train/unsup/44969_0.txt\n",
            "aclImdb/train/unsup/44968_0.txt\n",
            "aclImdb/train/unsup/44967_0.txt\n",
            "aclImdb/train/unsup/44966_0.txt\n",
            "aclImdb/train/unsup/44965_0.txt\n",
            "aclImdb/train/unsup/44964_0.txt\n",
            "aclImdb/train/unsup/44963_0.txt\n",
            "aclImdb/train/unsup/44962_0.txt\n",
            "aclImdb/train/unsup/44961_0.txt\n",
            "aclImdb/train/unsup/44960_0.txt\n",
            "aclImdb/train/unsup/44959_0.txt\n",
            "aclImdb/train/unsup/44958_0.txt\n",
            "aclImdb/train/unsup/44957_0.txt\n",
            "aclImdb/train/unsup/44956_0.txt\n",
            "aclImdb/train/unsup/44955_0.txt\n",
            "aclImdb/train/unsup/44954_0.txt\n",
            "aclImdb/train/unsup/44953_0.txt\n",
            "aclImdb/train/unsup/44952_0.txt\n",
            "aclImdb/train/unsup/44951_0.txt\n",
            "aclImdb/train/unsup/44950_0.txt\n",
            "aclImdb/train/unsup/44949_0.txt\n",
            "aclImdb/train/unsup/44948_0.txt\n",
            "aclImdb/train/unsup/44947_0.txt\n",
            "aclImdb/train/unsup/44946_0.txt\n",
            "aclImdb/train/unsup/44945_0.txt\n",
            "aclImdb/train/unsup/44944_0.txt\n",
            "aclImdb/train/unsup/44943_0.txt\n",
            "aclImdb/train/unsup/44942_0.txt\n",
            "aclImdb/train/unsup/44941_0.txt\n",
            "aclImdb/train/unsup/44940_0.txt\n",
            "aclImdb/train/unsup/44939_0.txt\n",
            "aclImdb/train/unsup/44938_0.txt\n",
            "aclImdb/train/unsup/44937_0.txt\n",
            "aclImdb/train/unsup/44936_0.txt\n",
            "aclImdb/train/unsup/44935_0.txt\n",
            "aclImdb/train/unsup/44934_0.txt\n",
            "aclImdb/train/unsup/44933_0.txt\n",
            "aclImdb/train/unsup/44932_0.txt\n",
            "aclImdb/train/unsup/44931_0.txt\n",
            "aclImdb/train/unsup/44930_0.txt\n",
            "aclImdb/train/unsup/44929_0.txt\n",
            "aclImdb/train/unsup/44928_0.txt\n",
            "aclImdb/train/unsup/45183_0.txt\n",
            "aclImdb/train/unsup/45182_0.txt\n",
            "aclImdb/train/unsup/45181_0.txt\n",
            "aclImdb/train/unsup/45180_0.txt\n",
            "aclImdb/train/unsup/45179_0.txt\n",
            "aclImdb/train/unsup/45178_0.txt\n",
            "aclImdb/train/unsup/45177_0.txt\n",
            "aclImdb/train/unsup/45176_0.txt\n",
            "aclImdb/train/unsup/45175_0.txt\n",
            "aclImdb/train/unsup/45174_0.txt\n",
            "aclImdb/train/unsup/45173_0.txt\n",
            "aclImdb/train/unsup/45172_0.txt\n",
            "aclImdb/train/unsup/45171_0.txt\n",
            "aclImdb/train/unsup/45170_0.txt\n",
            "aclImdb/train/unsup/45169_0.txt\n",
            "aclImdb/train/unsup/45168_0.txt\n",
            "aclImdb/train/unsup/45167_0.txt\n",
            "aclImdb/train/unsup/45166_0.txt\n",
            "aclImdb/train/unsup/45165_0.txt\n",
            "aclImdb/train/unsup/45164_0.txt\n",
            "aclImdb/train/unsup/45163_0.txt\n",
            "aclImdb/train/unsup/45162_0.txt\n",
            "aclImdb/train/unsup/45161_0.txt\n",
            "aclImdb/train/unsup/45160_0.txt\n",
            "aclImdb/train/unsup/45159_0.txt\n",
            "aclImdb/train/unsup/45158_0.txt\n",
            "aclImdb/train/unsup/45157_0.txt\n",
            "aclImdb/train/unsup/45156_0.txt\n",
            "aclImdb/train/unsup/45155_0.txt\n",
            "aclImdb/train/unsup/45154_0.txt\n",
            "aclImdb/train/unsup/45153_0.txt\n",
            "aclImdb/train/unsup/45152_0.txt\n",
            "aclImdb/train/unsup/45151_0.txt\n",
            "aclImdb/train/unsup/45150_0.txt\n",
            "aclImdb/train/unsup/45149_0.txt\n",
            "aclImdb/train/unsup/45148_0.txt\n",
            "aclImdb/train/unsup/45147_0.txt\n",
            "aclImdb/train/unsup/45146_0.txt\n",
            "aclImdb/train/unsup/45145_0.txt\n",
            "aclImdb/train/unsup/45144_0.txt\n",
            "aclImdb/train/unsup/45143_0.txt\n",
            "aclImdb/train/unsup/45142_0.txt\n",
            "aclImdb/train/unsup/45141_0.txt\n",
            "aclImdb/train/unsup/45140_0.txt\n",
            "aclImdb/train/unsup/45139_0.txt\n",
            "aclImdb/train/unsup/45138_0.txt\n",
            "aclImdb/train/unsup/45137_0.txt\n",
            "aclImdb/train/unsup/45136_0.txt\n",
            "aclImdb/train/unsup/45135_0.txt\n",
            "aclImdb/train/unsup/45134_0.txt\n",
            "aclImdb/train/unsup/45133_0.txt\n",
            "aclImdb/train/unsup/45132_0.txt\n",
            "aclImdb/train/unsup/45131_0.txt\n",
            "aclImdb/train/unsup/45130_0.txt\n",
            "aclImdb/train/unsup/45129_0.txt\n",
            "aclImdb/train/unsup/45128_0.txt\n",
            "aclImdb/train/unsup/45127_0.txt\n",
            "aclImdb/train/unsup/45126_0.txt\n",
            "aclImdb/train/unsup/45125_0.txt\n",
            "aclImdb/train/unsup/45124_0.txt\n",
            "aclImdb/train/unsup/45123_0.txt\n",
            "aclImdb/train/unsup/45122_0.txt\n",
            "aclImdb/train/unsup/45121_0.txt\n",
            "aclImdb/train/unsup/45120_0.txt\n",
            "aclImdb/train/unsup/45119_0.txt\n",
            "aclImdb/train/unsup/45118_0.txt\n",
            "aclImdb/train/unsup/45117_0.txt\n",
            "aclImdb/train/unsup/45116_0.txt\n",
            "aclImdb/train/unsup/45115_0.txt\n",
            "aclImdb/train/unsup/45114_0.txt\n",
            "aclImdb/train/unsup/45113_0.txt\n",
            "aclImdb/train/unsup/45112_0.txt\n",
            "aclImdb/train/unsup/45111_0.txt\n",
            "aclImdb/train/unsup/45110_0.txt\n",
            "aclImdb/train/unsup/45109_0.txt\n",
            "aclImdb/train/unsup/45108_0.txt\n",
            "aclImdb/train/unsup/45107_0.txt\n",
            "aclImdb/train/unsup/45106_0.txt\n",
            "aclImdb/train/unsup/45105_0.txt\n",
            "aclImdb/train/unsup/45104_0.txt\n",
            "aclImdb/train/unsup/45103_0.txt\n",
            "aclImdb/train/unsup/45102_0.txt\n",
            "aclImdb/train/unsup/45101_0.txt\n",
            "aclImdb/train/unsup/45100_0.txt\n",
            "aclImdb/train/unsup/45099_0.txt\n",
            "aclImdb/train/unsup/45098_0.txt\n",
            "aclImdb/train/unsup/45097_0.txt\n",
            "aclImdb/train/unsup/45096_0.txt\n",
            "aclImdb/train/unsup/45095_0.txt\n",
            "aclImdb/train/unsup/45094_0.txt\n",
            "aclImdb/train/unsup/45093_0.txt\n",
            "aclImdb/train/unsup/45092_0.txt\n",
            "aclImdb/train/unsup/45091_0.txt\n",
            "aclImdb/train/unsup/45090_0.txt\n",
            "aclImdb/train/unsup/45089_0.txt\n",
            "aclImdb/train/unsup/45088_0.txt\n",
            "aclImdb/train/unsup/45087_0.txt\n",
            "aclImdb/train/unsup/45086_0.txt\n",
            "aclImdb/train/unsup/45085_0.txt\n",
            "aclImdb/train/unsup/45084_0.txt\n",
            "aclImdb/train/unsup/45083_0.txt\n",
            "aclImdb/train/unsup/45082_0.txt\n",
            "aclImdb/train/unsup/45081_0.txt\n",
            "aclImdb/train/unsup/45080_0.txt\n",
            "aclImdb/train/unsup/45079_0.txt\n",
            "aclImdb/train/unsup/45078_0.txt\n",
            "aclImdb/train/unsup/45077_0.txt\n",
            "aclImdb/train/unsup/45076_0.txt\n",
            "aclImdb/train/unsup/45075_0.txt\n",
            "aclImdb/train/unsup/45074_0.txt\n",
            "aclImdb/train/unsup/45073_0.txt\n",
            "aclImdb/train/unsup/45072_0.txt\n",
            "aclImdb/train/unsup/45071_0.txt\n",
            "aclImdb/train/unsup/45070_0.txt\n",
            "aclImdb/train/unsup/45069_0.txt\n",
            "aclImdb/train/unsup/45068_0.txt\n",
            "aclImdb/train/unsup/45067_0.txt\n",
            "aclImdb/train/unsup/45066_0.txt\n",
            "aclImdb/train/unsup/45065_0.txt\n",
            "aclImdb/train/unsup/45064_0.txt\n",
            "aclImdb/train/unsup/45063_0.txt\n",
            "aclImdb/train/unsup/45062_0.txt\n",
            "aclImdb/train/unsup/45061_0.txt\n",
            "aclImdb/train/unsup/45060_0.txt\n",
            "aclImdb/train/unsup/45059_0.txt\n",
            "aclImdb/train/unsup/45058_0.txt\n",
            "aclImdb/train/unsup/45057_0.txt\n",
            "aclImdb/train/unsup/45056_0.txt\n",
            "aclImdb/train/unsup/45311_0.txt\n",
            "aclImdb/train/unsup/45310_0.txt\n",
            "aclImdb/train/unsup/45309_0.txt\n",
            "aclImdb/train/unsup/45308_0.txt\n",
            "aclImdb/train/unsup/45307_0.txt\n",
            "aclImdb/train/unsup/45306_0.txt\n",
            "aclImdb/train/unsup/45305_0.txt\n",
            "aclImdb/train/unsup/45304_0.txt\n",
            "aclImdb/train/unsup/45303_0.txt\n",
            "aclImdb/train/unsup/45302_0.txt\n",
            "aclImdb/train/unsup/45301_0.txt\n",
            "aclImdb/train/unsup/45300_0.txt\n",
            "aclImdb/train/unsup/45299_0.txt\n",
            "aclImdb/train/unsup/45298_0.txt\n",
            "aclImdb/train/unsup/45297_0.txt\n",
            "aclImdb/train/unsup/45296_0.txt\n",
            "aclImdb/train/unsup/45295_0.txt\n",
            "aclImdb/train/unsup/45294_0.txt\n",
            "aclImdb/train/unsup/45293_0.txt\n",
            "aclImdb/train/unsup/45292_0.txt\n",
            "aclImdb/train/unsup/45291_0.txt\n",
            "aclImdb/train/unsup/45290_0.txt\n",
            "aclImdb/train/unsup/45289_0.txt\n",
            "aclImdb/train/unsup/45288_0.txt\n",
            "aclImdb/train/unsup/45287_0.txt\n",
            "aclImdb/train/unsup/45286_0.txt\n",
            "aclImdb/train/unsup/45285_0.txt\n",
            "aclImdb/train/unsup/45284_0.txt\n",
            "aclImdb/train/unsup/45283_0.txt\n",
            "aclImdb/train/unsup/45282_0.txt\n",
            "aclImdb/train/unsup/45281_0.txt\n",
            "aclImdb/train/unsup/45280_0.txt\n",
            "aclImdb/train/unsup/45279_0.txt\n",
            "aclImdb/train/unsup/45278_0.txt\n",
            "aclImdb/train/unsup/45277_0.txt\n",
            "aclImdb/train/unsup/45276_0.txt\n",
            "aclImdb/train/unsup/45275_0.txt\n",
            "aclImdb/train/unsup/45274_0.txt\n",
            "aclImdb/train/unsup/45273_0.txt\n",
            "aclImdb/train/unsup/45272_0.txt\n",
            "aclImdb/train/unsup/45271_0.txt\n",
            "aclImdb/train/unsup/45270_0.txt\n",
            "aclImdb/train/unsup/45269_0.txt\n",
            "aclImdb/train/unsup/45268_0.txt\n",
            "aclImdb/train/unsup/45267_0.txt\n",
            "aclImdb/train/unsup/45266_0.txt\n",
            "aclImdb/train/unsup/45265_0.txt\n",
            "aclImdb/train/unsup/45264_0.txt\n",
            "aclImdb/train/unsup/45263_0.txt\n",
            "aclImdb/train/unsup/45262_0.txt\n",
            "aclImdb/train/unsup/45261_0.txt\n",
            "aclImdb/train/unsup/45260_0.txt\n",
            "aclImdb/train/unsup/45259_0.txt\n",
            "aclImdb/train/unsup/45258_0.txt\n",
            "aclImdb/train/unsup/45257_0.txt\n",
            "aclImdb/train/unsup/45256_0.txt\n",
            "aclImdb/train/unsup/45255_0.txt\n",
            "aclImdb/train/unsup/45254_0.txt\n",
            "aclImdb/train/unsup/45253_0.txt\n",
            "aclImdb/train/unsup/45252_0.txt\n",
            "aclImdb/train/unsup/45251_0.txt\n",
            "aclImdb/train/unsup/45250_0.txt\n",
            "aclImdb/train/unsup/45249_0.txt\n",
            "aclImdb/train/unsup/45248_0.txt\n",
            "aclImdb/train/unsup/45247_0.txt\n",
            "aclImdb/train/unsup/45246_0.txt\n",
            "aclImdb/train/unsup/45245_0.txt\n",
            "aclImdb/train/unsup/45244_0.txt\n",
            "aclImdb/train/unsup/45243_0.txt\n",
            "aclImdb/train/unsup/45242_0.txt\n",
            "aclImdb/train/unsup/45241_0.txt\n",
            "aclImdb/train/unsup/45240_0.txt\n",
            "aclImdb/train/unsup/45239_0.txt\n",
            "aclImdb/train/unsup/45238_0.txt\n",
            "aclImdb/train/unsup/45237_0.txt\n",
            "aclImdb/train/unsup/45236_0.txt\n",
            "aclImdb/train/unsup/45235_0.txt\n",
            "aclImdb/train/unsup/45234_0.txt\n",
            "aclImdb/train/unsup/45233_0.txt\n",
            "aclImdb/train/unsup/45232_0.txt\n",
            "aclImdb/train/unsup/45231_0.txt\n",
            "aclImdb/train/unsup/45230_0.txt\n",
            "aclImdb/train/unsup/45229_0.txt\n",
            "aclImdb/train/unsup/45228_0.txt\n",
            "aclImdb/train/unsup/45227_0.txt\n",
            "aclImdb/train/unsup/45226_0.txt\n",
            "aclImdb/train/unsup/45225_0.txt\n",
            "aclImdb/train/unsup/45224_0.txt\n",
            "aclImdb/train/unsup/45223_0.txt\n",
            "aclImdb/train/unsup/45222_0.txt\n",
            "aclImdb/train/unsup/45221_0.txt\n",
            "aclImdb/train/unsup/45220_0.txt\n",
            "aclImdb/train/unsup/45219_0.txt\n",
            "aclImdb/train/unsup/45218_0.txt\n",
            "aclImdb/train/unsup/45217_0.txt\n",
            "aclImdb/train/unsup/45216_0.txt\n",
            "aclImdb/train/unsup/45215_0.txt\n",
            "aclImdb/train/unsup/45214_0.txt\n",
            "aclImdb/train/unsup/45213_0.txt\n",
            "aclImdb/train/unsup/45212_0.txt\n",
            "aclImdb/train/unsup/45211_0.txt\n",
            "aclImdb/train/unsup/45210_0.txt\n",
            "aclImdb/train/unsup/45209_0.txt\n",
            "aclImdb/train/unsup/45208_0.txt\n",
            "aclImdb/train/unsup/45207_0.txt\n",
            "aclImdb/train/unsup/45206_0.txt\n",
            "aclImdb/train/unsup/45205_0.txt\n",
            "aclImdb/train/unsup/45204_0.txt\n",
            "aclImdb/train/unsup/45203_0.txt\n",
            "aclImdb/train/unsup/45202_0.txt\n",
            "aclImdb/train/unsup/45201_0.txt\n",
            "aclImdb/train/unsup/45200_0.txt\n",
            "aclImdb/train/unsup/45199_0.txt\n",
            "aclImdb/train/unsup/45198_0.txt\n",
            "aclImdb/train/unsup/45197_0.txt\n",
            "aclImdb/train/unsup/45196_0.txt\n",
            "aclImdb/train/unsup/45195_0.txt\n",
            "aclImdb/train/unsup/45194_0.txt\n",
            "aclImdb/train/unsup/45193_0.txt\n",
            "aclImdb/train/unsup/45192_0.txt\n",
            "aclImdb/train/unsup/45191_0.txt\n",
            "aclImdb/train/unsup/45190_0.txt\n",
            "aclImdb/train/unsup/45189_0.txt\n",
            "aclImdb/train/unsup/45188_0.txt\n",
            "aclImdb/train/unsup/45187_0.txt\n",
            "aclImdb/train/unsup/45186_0.txt\n",
            "aclImdb/train/unsup/45185_0.txt\n",
            "aclImdb/train/unsup/45184_0.txt\n",
            "aclImdb/train/unsup/45439_0.txt\n",
            "aclImdb/train/unsup/45438_0.txt\n",
            "aclImdb/train/unsup/45437_0.txt\n",
            "aclImdb/train/unsup/45436_0.txt\n",
            "aclImdb/train/unsup/45435_0.txt\n",
            "aclImdb/train/unsup/45434_0.txt\n",
            "aclImdb/train/unsup/45433_0.txt\n",
            "aclImdb/train/unsup/45432_0.txt\n",
            "aclImdb/train/unsup/45431_0.txt\n",
            "aclImdb/train/unsup/45430_0.txt\n",
            "aclImdb/train/unsup/45429_0.txt\n",
            "aclImdb/train/unsup/45428_0.txt\n",
            "aclImdb/train/unsup/45427_0.txt\n",
            "aclImdb/train/unsup/45426_0.txt\n",
            "aclImdb/train/unsup/45425_0.txt\n",
            "aclImdb/train/unsup/45424_0.txt\n",
            "aclImdb/train/unsup/45423_0.txt\n",
            "aclImdb/train/unsup/45422_0.txt\n",
            "aclImdb/train/unsup/45421_0.txt\n",
            "aclImdb/train/unsup/45420_0.txt\n",
            "aclImdb/train/unsup/45419_0.txt\n",
            "aclImdb/train/unsup/45418_0.txt\n",
            "aclImdb/train/unsup/45417_0.txt\n",
            "aclImdb/train/unsup/45416_0.txt\n",
            "aclImdb/train/unsup/45415_0.txt\n",
            "aclImdb/train/unsup/45414_0.txt\n",
            "aclImdb/train/unsup/45413_0.txt\n",
            "aclImdb/train/unsup/45412_0.txt\n",
            "aclImdb/train/unsup/45411_0.txt\n",
            "aclImdb/train/unsup/45410_0.txt\n",
            "aclImdb/train/unsup/45409_0.txt\n",
            "aclImdb/train/unsup/45408_0.txt\n",
            "aclImdb/train/unsup/45407_0.txt\n",
            "aclImdb/train/unsup/45406_0.txt\n",
            "aclImdb/train/unsup/45405_0.txt\n",
            "aclImdb/train/unsup/45404_0.txt\n",
            "aclImdb/train/unsup/45403_0.txt\n",
            "aclImdb/train/unsup/45402_0.txt\n",
            "aclImdb/train/unsup/45401_0.txt\n",
            "aclImdb/train/unsup/45400_0.txt\n",
            "aclImdb/train/unsup/45399_0.txt\n",
            "aclImdb/train/unsup/45398_0.txt\n",
            "aclImdb/train/unsup/45397_0.txt\n",
            "aclImdb/train/unsup/45396_0.txt\n",
            "aclImdb/train/unsup/45395_0.txt\n",
            "aclImdb/train/unsup/45394_0.txt\n",
            "aclImdb/train/unsup/45393_0.txt\n",
            "aclImdb/train/unsup/45392_0.txt\n",
            "aclImdb/train/unsup/45391_0.txt\n",
            "aclImdb/train/unsup/45390_0.txt\n",
            "aclImdb/train/unsup/45389_0.txt\n",
            "aclImdb/train/unsup/45388_0.txt\n",
            "aclImdb/train/unsup/45387_0.txt\n",
            "aclImdb/train/unsup/45386_0.txt\n",
            "aclImdb/train/unsup/45385_0.txt\n",
            "aclImdb/train/unsup/45384_0.txt\n",
            "aclImdb/train/unsup/45383_0.txt\n",
            "aclImdb/train/unsup/45382_0.txt\n",
            "aclImdb/train/unsup/45381_0.txt\n",
            "aclImdb/train/unsup/45380_0.txt\n",
            "aclImdb/train/unsup/45379_0.txt\n",
            "aclImdb/train/unsup/45378_0.txt\n",
            "aclImdb/train/unsup/45377_0.txt\n",
            "aclImdb/train/unsup/45376_0.txt\n",
            "aclImdb/train/unsup/45375_0.txt\n",
            "aclImdb/train/unsup/45374_0.txt\n",
            "aclImdb/train/unsup/45373_0.txt\n",
            "aclImdb/train/unsup/45372_0.txt\n",
            "aclImdb/train/unsup/45371_0.txt\n",
            "aclImdb/train/unsup/45370_0.txt\n",
            "aclImdb/train/unsup/45369_0.txt\n",
            "aclImdb/train/unsup/45368_0.txt\n",
            "aclImdb/train/unsup/45367_0.txt\n",
            "aclImdb/train/unsup/45366_0.txt\n",
            "aclImdb/train/unsup/45365_0.txt\n",
            "aclImdb/train/unsup/45364_0.txt\n",
            "aclImdb/train/unsup/45363_0.txt\n",
            "aclImdb/train/unsup/45362_0.txt\n",
            "aclImdb/train/unsup/45361_0.txt\n",
            "aclImdb/train/unsup/45360_0.txt\n",
            "aclImdb/train/unsup/45359_0.txt\n",
            "aclImdb/train/unsup/45358_0.txt\n",
            "aclImdb/train/unsup/45357_0.txt\n",
            "aclImdb/train/unsup/45356_0.txt\n",
            "aclImdb/train/unsup/45355_0.txt\n",
            "aclImdb/train/unsup/45354_0.txt\n",
            "aclImdb/train/unsup/45353_0.txt\n",
            "aclImdb/train/unsup/45352_0.txt\n",
            "aclImdb/train/unsup/45351_0.txt\n",
            "aclImdb/train/unsup/45350_0.txt\n",
            "aclImdb/train/unsup/45349_0.txt\n",
            "aclImdb/train/unsup/45348_0.txt\n",
            "aclImdb/train/unsup/45347_0.txt\n",
            "aclImdb/train/unsup/45346_0.txt\n",
            "aclImdb/train/unsup/45345_0.txt\n",
            "aclImdb/train/unsup/45344_0.txt\n",
            "aclImdb/train/unsup/45343_0.txt\n",
            "aclImdb/train/unsup/45342_0.txt\n",
            "aclImdb/train/unsup/45341_0.txt\n",
            "aclImdb/train/unsup/45340_0.txt\n",
            "aclImdb/train/unsup/45339_0.txt\n",
            "aclImdb/train/unsup/45338_0.txt\n",
            "aclImdb/train/unsup/45337_0.txt\n",
            "aclImdb/train/unsup/45336_0.txt\n",
            "aclImdb/train/unsup/45335_0.txt\n",
            "aclImdb/train/unsup/45334_0.txt\n",
            "aclImdb/train/unsup/45333_0.txt\n",
            "aclImdb/train/unsup/45332_0.txt\n",
            "aclImdb/train/unsup/45331_0.txt\n",
            "aclImdb/train/unsup/45330_0.txt\n",
            "aclImdb/train/unsup/45329_0.txt\n",
            "aclImdb/train/unsup/45328_0.txt\n",
            "aclImdb/train/unsup/45327_0.txt\n",
            "aclImdb/train/unsup/45326_0.txt\n",
            "aclImdb/train/unsup/45325_0.txt\n",
            "aclImdb/train/unsup/45324_0.txt\n",
            "aclImdb/train/unsup/45323_0.txt\n",
            "aclImdb/train/unsup/45322_0.txt\n",
            "aclImdb/train/unsup/45321_0.txt\n",
            "aclImdb/train/unsup/45320_0.txt\n",
            "aclImdb/train/unsup/45319_0.txt\n",
            "aclImdb/train/unsup/45318_0.txt\n",
            "aclImdb/train/unsup/45317_0.txt\n",
            "aclImdb/train/unsup/45316_0.txt\n",
            "aclImdb/train/unsup/45315_0.txt\n",
            "aclImdb/train/unsup/45314_0.txt\n",
            "aclImdb/train/unsup/45313_0.txt\n",
            "aclImdb/train/unsup/45312_0.txt\n",
            "aclImdb/train/unsup/45567_0.txt\n",
            "aclImdb/train/unsup/45566_0.txt\n",
            "aclImdb/train/unsup/45565_0.txt\n",
            "aclImdb/train/unsup/45564_0.txt\n",
            "aclImdb/train/unsup/45563_0.txt\n",
            "aclImdb/train/unsup/45562_0.txt\n",
            "aclImdb/train/unsup/45561_0.txt\n",
            "aclImdb/train/unsup/45560_0.txt\n",
            "aclImdb/train/unsup/45559_0.txt\n",
            "aclImdb/train/unsup/45558_0.txt\n",
            "aclImdb/train/unsup/45557_0.txt\n",
            "aclImdb/train/unsup/45556_0.txt\n",
            "aclImdb/train/unsup/45555_0.txt\n",
            "aclImdb/train/unsup/45554_0.txt\n",
            "aclImdb/train/unsup/45553_0.txt\n",
            "aclImdb/train/unsup/45552_0.txt\n",
            "aclImdb/train/unsup/45551_0.txt\n",
            "aclImdb/train/unsup/45550_0.txt\n",
            "aclImdb/train/unsup/45549_0.txt\n",
            "aclImdb/train/unsup/45548_0.txt\n",
            "aclImdb/train/unsup/45547_0.txt\n",
            "aclImdb/train/unsup/45546_0.txt\n",
            "aclImdb/train/unsup/45545_0.txt\n",
            "aclImdb/train/unsup/45544_0.txt\n",
            "aclImdb/train/unsup/45543_0.txt\n",
            "aclImdb/train/unsup/45542_0.txt\n",
            "aclImdb/train/unsup/45541_0.txt\n",
            "aclImdb/train/unsup/45540_0.txt\n",
            "aclImdb/train/unsup/45539_0.txt\n",
            "aclImdb/train/unsup/45538_0.txt\n",
            "aclImdb/train/unsup/45537_0.txt\n",
            "aclImdb/train/unsup/45536_0.txt\n",
            "aclImdb/train/unsup/45535_0.txt\n",
            "aclImdb/train/unsup/45534_0.txt\n",
            "aclImdb/train/unsup/45533_0.txt\n",
            "aclImdb/train/unsup/45532_0.txt\n",
            "aclImdb/train/unsup/45531_0.txt\n",
            "aclImdb/train/unsup/45530_0.txt\n",
            "aclImdb/train/unsup/45529_0.txt\n",
            "aclImdb/train/unsup/45528_0.txt\n",
            "aclImdb/train/unsup/45527_0.txt\n",
            "aclImdb/train/unsup/45526_0.txt\n",
            "aclImdb/train/unsup/45525_0.txt\n",
            "aclImdb/train/unsup/45524_0.txt\n",
            "aclImdb/train/unsup/45523_0.txt\n",
            "aclImdb/train/unsup/45522_0.txt\n",
            "aclImdb/train/unsup/45521_0.txt\n",
            "aclImdb/train/unsup/45520_0.txt\n",
            "aclImdb/train/unsup/45519_0.txt\n",
            "aclImdb/train/unsup/45518_0.txt\n",
            "aclImdb/train/unsup/45517_0.txt\n",
            "aclImdb/train/unsup/45516_0.txt\n",
            "aclImdb/train/unsup/45515_0.txt\n",
            "aclImdb/train/unsup/45514_0.txt\n",
            "aclImdb/train/unsup/45513_0.txt\n",
            "aclImdb/train/unsup/45512_0.txt\n",
            "aclImdb/train/unsup/45511_0.txt\n",
            "aclImdb/train/unsup/45510_0.txt\n",
            "aclImdb/train/unsup/45509_0.txt\n",
            "aclImdb/train/unsup/45508_0.txt\n",
            "aclImdb/train/unsup/45507_0.txt\n",
            "aclImdb/train/unsup/45506_0.txt\n",
            "aclImdb/train/unsup/45505_0.txt\n",
            "aclImdb/train/unsup/45504_0.txt\n",
            "aclImdb/train/unsup/45503_0.txt\n",
            "aclImdb/train/unsup/45502_0.txt\n",
            "aclImdb/train/unsup/45501_0.txt\n",
            "aclImdb/train/unsup/45500_0.txt\n",
            "aclImdb/train/unsup/45499_0.txt\n",
            "aclImdb/train/unsup/45498_0.txt\n",
            "aclImdb/train/unsup/45497_0.txt\n",
            "aclImdb/train/unsup/45496_0.txt\n",
            "aclImdb/train/unsup/45495_0.txt\n",
            "aclImdb/train/unsup/45494_0.txt\n",
            "aclImdb/train/unsup/45493_0.txt\n",
            "aclImdb/train/unsup/45492_0.txt\n",
            "aclImdb/train/unsup/45491_0.txt\n",
            "aclImdb/train/unsup/45490_0.txt\n",
            "aclImdb/train/unsup/45489_0.txt\n",
            "aclImdb/train/unsup/45488_0.txt\n",
            "aclImdb/train/unsup/45487_0.txt\n",
            "aclImdb/train/unsup/45486_0.txt\n",
            "aclImdb/train/unsup/45485_0.txt\n",
            "aclImdb/train/unsup/45484_0.txt\n",
            "aclImdb/train/unsup/45483_0.txt\n",
            "aclImdb/train/unsup/45482_0.txt\n",
            "aclImdb/train/unsup/45481_0.txt\n",
            "aclImdb/train/unsup/45480_0.txt\n",
            "aclImdb/train/unsup/45479_0.txt\n",
            "aclImdb/train/unsup/45478_0.txt\n",
            "aclImdb/train/unsup/45477_0.txt\n",
            "aclImdb/train/unsup/45476_0.txt\n",
            "aclImdb/train/unsup/45475_0.txt\n",
            "aclImdb/train/unsup/45474_0.txt\n",
            "aclImdb/train/unsup/45473_0.txt\n",
            "aclImdb/train/unsup/45472_0.txt\n",
            "aclImdb/train/unsup/45471_0.txt\n",
            "aclImdb/train/unsup/45470_0.txt\n",
            "aclImdb/train/unsup/45469_0.txt\n",
            "aclImdb/train/unsup/45468_0.txt\n",
            "aclImdb/train/unsup/45467_0.txt\n",
            "aclImdb/train/unsup/45466_0.txt\n",
            "aclImdb/train/unsup/45465_0.txt\n",
            "aclImdb/train/unsup/45464_0.txt\n",
            "aclImdb/train/unsup/45463_0.txt\n",
            "aclImdb/train/unsup/45462_0.txt\n",
            "aclImdb/train/unsup/45461_0.txt\n",
            "aclImdb/train/unsup/45460_0.txt\n",
            "aclImdb/train/unsup/45459_0.txt\n",
            "aclImdb/train/unsup/45458_0.txt\n",
            "aclImdb/train/unsup/45457_0.txt\n",
            "aclImdb/train/unsup/45456_0.txt\n",
            "aclImdb/train/unsup/45455_0.txt\n",
            "aclImdb/train/unsup/45454_0.txt\n",
            "aclImdb/train/unsup/45453_0.txt\n",
            "aclImdb/train/unsup/45452_0.txt\n",
            "aclImdb/train/unsup/45451_0.txt\n",
            "aclImdb/train/unsup/45450_0.txt\n",
            "aclImdb/train/unsup/45449_0.txt\n",
            "aclImdb/train/unsup/45448_0.txt\n",
            "aclImdb/train/unsup/45447_0.txt\n",
            "aclImdb/train/unsup/45446_0.txt\n",
            "aclImdb/train/unsup/45445_0.txt\n",
            "aclImdb/train/unsup/45444_0.txt\n",
            "aclImdb/train/unsup/45443_0.txt\n",
            "aclImdb/train/unsup/45442_0.txt\n",
            "aclImdb/train/unsup/45441_0.txt\n",
            "aclImdb/train/unsup/45440_0.txt\n",
            "aclImdb/train/unsup/45695_0.txt\n",
            "aclImdb/train/unsup/45694_0.txt\n",
            "aclImdb/train/unsup/45693_0.txt\n",
            "aclImdb/train/unsup/45692_0.txt\n",
            "aclImdb/train/unsup/45691_0.txt\n",
            "aclImdb/train/unsup/45690_0.txt\n",
            "aclImdb/train/unsup/45689_0.txt\n",
            "aclImdb/train/unsup/45688_0.txt\n",
            "aclImdb/train/unsup/45687_0.txt\n",
            "aclImdb/train/unsup/45686_0.txt\n",
            "aclImdb/train/unsup/45685_0.txt\n",
            "aclImdb/train/unsup/45684_0.txt\n",
            "aclImdb/train/unsup/45683_0.txt\n",
            "aclImdb/train/unsup/45682_0.txt\n",
            "aclImdb/train/unsup/45681_0.txt\n",
            "aclImdb/train/unsup/45680_0.txt\n",
            "aclImdb/train/unsup/45679_0.txt\n",
            "aclImdb/train/unsup/45678_0.txt\n",
            "aclImdb/train/unsup/45677_0.txt\n",
            "aclImdb/train/unsup/45676_0.txt\n",
            "aclImdb/train/unsup/45675_0.txt\n",
            "aclImdb/train/unsup/45674_0.txt\n",
            "aclImdb/train/unsup/45673_0.txt\n",
            "aclImdb/train/unsup/45672_0.txt\n",
            "aclImdb/train/unsup/45671_0.txt\n",
            "aclImdb/train/unsup/45670_0.txt\n",
            "aclImdb/train/unsup/45669_0.txt\n",
            "aclImdb/train/unsup/45668_0.txt\n",
            "aclImdb/train/unsup/45667_0.txt\n",
            "aclImdb/train/unsup/45666_0.txt\n",
            "aclImdb/train/unsup/45665_0.txt\n",
            "aclImdb/train/unsup/45664_0.txt\n",
            "aclImdb/train/unsup/45663_0.txt\n",
            "aclImdb/train/unsup/45662_0.txt\n",
            "aclImdb/train/unsup/45661_0.txt\n",
            "aclImdb/train/unsup/45660_0.txt\n",
            "aclImdb/train/unsup/45659_0.txt\n",
            "aclImdb/train/unsup/45658_0.txt\n",
            "aclImdb/train/unsup/45657_0.txt\n",
            "aclImdb/train/unsup/45656_0.txt\n",
            "aclImdb/train/unsup/45655_0.txt\n",
            "aclImdb/train/unsup/45654_0.txt\n",
            "aclImdb/train/unsup/45653_0.txt\n",
            "aclImdb/train/unsup/45652_0.txt\n",
            "aclImdb/train/unsup/45651_0.txt\n",
            "aclImdb/train/unsup/45650_0.txt\n",
            "aclImdb/train/unsup/45649_0.txt\n",
            "aclImdb/train/unsup/45648_0.txt\n",
            "aclImdb/train/unsup/45647_0.txt\n",
            "aclImdb/train/unsup/45646_0.txt\n",
            "aclImdb/train/unsup/45645_0.txt\n",
            "aclImdb/train/unsup/45644_0.txt\n",
            "aclImdb/train/unsup/45643_0.txt\n",
            "aclImdb/train/unsup/45642_0.txt\n",
            "aclImdb/train/unsup/45641_0.txt\n",
            "aclImdb/train/unsup/45640_0.txt\n",
            "aclImdb/train/unsup/45639_0.txt\n",
            "aclImdb/train/unsup/45638_0.txt\n",
            "aclImdb/train/unsup/45637_0.txt\n",
            "aclImdb/train/unsup/45636_0.txt\n",
            "aclImdb/train/unsup/45635_0.txt\n",
            "aclImdb/train/unsup/45634_0.txt\n",
            "aclImdb/train/unsup/45633_0.txt\n",
            "aclImdb/train/unsup/45632_0.txt\n",
            "aclImdb/train/unsup/45631_0.txt\n",
            "aclImdb/train/unsup/45630_0.txt\n",
            "aclImdb/train/unsup/45629_0.txt\n",
            "aclImdb/train/unsup/45628_0.txt\n",
            "aclImdb/train/unsup/45627_0.txt\n",
            "aclImdb/train/unsup/45626_0.txt\n",
            "aclImdb/train/unsup/45625_0.txt\n",
            "aclImdb/train/unsup/45624_0.txt\n",
            "aclImdb/train/unsup/45623_0.txt\n",
            "aclImdb/train/unsup/45622_0.txt\n",
            "aclImdb/train/unsup/45621_0.txt\n",
            "aclImdb/train/unsup/45620_0.txt\n",
            "aclImdb/train/unsup/45619_0.txt\n",
            "aclImdb/train/unsup/45618_0.txt\n",
            "aclImdb/train/unsup/45617_0.txt\n",
            "aclImdb/train/unsup/45616_0.txt\n",
            "aclImdb/train/unsup/45615_0.txt\n",
            "aclImdb/train/unsup/45614_0.txt\n",
            "aclImdb/train/unsup/45613_0.txt\n",
            "aclImdb/train/unsup/45612_0.txt\n",
            "aclImdb/train/unsup/45611_0.txt\n",
            "aclImdb/train/unsup/45610_0.txt\n",
            "aclImdb/train/unsup/45609_0.txt\n",
            "aclImdb/train/unsup/45608_0.txt\n",
            "aclImdb/train/unsup/45607_0.txt\n",
            "aclImdb/train/unsup/45606_0.txt\n",
            "aclImdb/train/unsup/45605_0.txt\n",
            "aclImdb/train/unsup/45604_0.txt\n",
            "aclImdb/train/unsup/45603_0.txt\n",
            "aclImdb/train/unsup/45602_0.txt\n",
            "aclImdb/train/unsup/45601_0.txt\n",
            "aclImdb/train/unsup/45600_0.txt\n",
            "aclImdb/train/unsup/45599_0.txt\n",
            "aclImdb/train/unsup/45598_0.txt\n",
            "aclImdb/train/unsup/45597_0.txt\n",
            "aclImdb/train/unsup/45596_0.txt\n",
            "aclImdb/train/unsup/45595_0.txt\n",
            "aclImdb/train/unsup/45594_0.txt\n",
            "aclImdb/train/unsup/45593_0.txt\n",
            "aclImdb/train/unsup/45592_0.txt\n",
            "aclImdb/train/unsup/45591_0.txt\n",
            "aclImdb/train/unsup/45590_0.txt\n",
            "aclImdb/train/unsup/45589_0.txt\n",
            "aclImdb/train/unsup/45588_0.txt\n",
            "aclImdb/train/unsup/45587_0.txt\n",
            "aclImdb/train/unsup/45586_0.txt\n",
            "aclImdb/train/unsup/45585_0.txt\n",
            "aclImdb/train/unsup/45584_0.txt\n",
            "aclImdb/train/unsup/45583_0.txt\n",
            "aclImdb/train/unsup/45582_0.txt\n",
            "aclImdb/train/unsup/45581_0.txt\n",
            "aclImdb/train/unsup/45580_0.txt\n",
            "aclImdb/train/unsup/45579_0.txt\n",
            "aclImdb/train/unsup/45578_0.txt\n",
            "aclImdb/train/unsup/45577_0.txt\n",
            "aclImdb/train/unsup/45576_0.txt\n",
            "aclImdb/train/unsup/45575_0.txt\n",
            "aclImdb/train/unsup/45574_0.txt\n",
            "aclImdb/train/unsup/45573_0.txt\n",
            "aclImdb/train/unsup/45572_0.txt\n",
            "aclImdb/train/unsup/45571_0.txt\n",
            "aclImdb/train/unsup/45570_0.txt\n",
            "aclImdb/train/unsup/45569_0.txt\n",
            "aclImdb/train/unsup/45568_0.txt\n",
            "aclImdb/train/unsup/45823_0.txt\n",
            "aclImdb/train/unsup/45822_0.txt\n",
            "aclImdb/train/unsup/45821_0.txt\n",
            "aclImdb/train/unsup/45820_0.txt\n",
            "aclImdb/train/unsup/45819_0.txt\n",
            "aclImdb/train/unsup/45818_0.txt\n",
            "aclImdb/train/unsup/45817_0.txt\n",
            "aclImdb/train/unsup/45816_0.txt\n",
            "aclImdb/train/unsup/45815_0.txt\n",
            "aclImdb/train/unsup/45814_0.txt\n",
            "aclImdb/train/unsup/45813_0.txt\n",
            "aclImdb/train/unsup/45812_0.txt\n",
            "aclImdb/train/unsup/45811_0.txt\n",
            "aclImdb/train/unsup/45810_0.txt\n",
            "aclImdb/train/unsup/45809_0.txt\n",
            "aclImdb/train/unsup/45808_0.txt\n",
            "aclImdb/train/unsup/45807_0.txt\n",
            "aclImdb/train/unsup/45806_0.txt\n",
            "aclImdb/train/unsup/45805_0.txt\n",
            "aclImdb/train/unsup/45804_0.txt\n",
            "aclImdb/train/unsup/45803_0.txt\n",
            "aclImdb/train/unsup/45802_0.txt\n",
            "aclImdb/train/unsup/45801_0.txt\n",
            "aclImdb/train/unsup/45800_0.txt\n",
            "aclImdb/train/unsup/45799_0.txt\n",
            "aclImdb/train/unsup/45798_0.txt\n",
            "aclImdb/train/unsup/45797_0.txt\n",
            "aclImdb/train/unsup/45796_0.txt\n",
            "aclImdb/train/unsup/45795_0.txt\n",
            "aclImdb/train/unsup/45794_0.txt\n",
            "aclImdb/train/unsup/45793_0.txt\n",
            "aclImdb/train/unsup/45792_0.txt\n",
            "aclImdb/train/unsup/45791_0.txt\n",
            "aclImdb/train/unsup/45790_0.txt\n",
            "aclImdb/train/unsup/45789_0.txt\n",
            "aclImdb/train/unsup/45788_0.txt\n",
            "aclImdb/train/unsup/45787_0.txt\n",
            "aclImdb/train/unsup/45786_0.txt\n",
            "aclImdb/train/unsup/45785_0.txt\n",
            "aclImdb/train/unsup/45784_0.txt\n",
            "aclImdb/train/unsup/45783_0.txt\n",
            "aclImdb/train/unsup/45782_0.txt\n",
            "aclImdb/train/unsup/45781_0.txt\n",
            "aclImdb/train/unsup/45780_0.txt\n",
            "aclImdb/train/unsup/45779_0.txt\n",
            "aclImdb/train/unsup/45778_0.txt\n",
            "aclImdb/train/unsup/45777_0.txt\n",
            "aclImdb/train/unsup/45776_0.txt\n",
            "aclImdb/train/unsup/45775_0.txt\n",
            "aclImdb/train/unsup/45774_0.txt\n",
            "aclImdb/train/unsup/45773_0.txt\n",
            "aclImdb/train/unsup/45772_0.txt\n",
            "aclImdb/train/unsup/45771_0.txt\n",
            "aclImdb/train/unsup/45770_0.txt\n",
            "aclImdb/train/unsup/45769_0.txt\n",
            "aclImdb/train/unsup/45768_0.txt\n",
            "aclImdb/train/unsup/45767_0.txt\n",
            "aclImdb/train/unsup/45766_0.txt\n",
            "aclImdb/train/unsup/45765_0.txt\n",
            "aclImdb/train/unsup/45764_0.txt\n",
            "aclImdb/train/unsup/45763_0.txt\n",
            "aclImdb/train/unsup/45762_0.txt\n",
            "aclImdb/train/unsup/45761_0.txt\n",
            "aclImdb/train/unsup/45760_0.txt\n",
            "aclImdb/train/unsup/45759_0.txt\n",
            "aclImdb/train/unsup/45758_0.txt\n",
            "aclImdb/train/unsup/45757_0.txt\n",
            "aclImdb/train/unsup/45756_0.txt\n",
            "aclImdb/train/unsup/45755_0.txt\n",
            "aclImdb/train/unsup/45754_0.txt\n",
            "aclImdb/train/unsup/45753_0.txt\n",
            "aclImdb/train/unsup/45752_0.txt\n",
            "aclImdb/train/unsup/45751_0.txt\n",
            "aclImdb/train/unsup/45750_0.txt\n",
            "aclImdb/train/unsup/45749_0.txt\n",
            "aclImdb/train/unsup/45748_0.txt\n",
            "aclImdb/train/unsup/45747_0.txt\n",
            "aclImdb/train/unsup/45746_0.txt\n",
            "aclImdb/train/unsup/45745_0.txt\n",
            "aclImdb/train/unsup/45744_0.txt\n",
            "aclImdb/train/unsup/45743_0.txt\n",
            "aclImdb/train/unsup/45742_0.txt\n",
            "aclImdb/train/unsup/45741_0.txt\n",
            "aclImdb/train/unsup/45740_0.txt\n",
            "aclImdb/train/unsup/45739_0.txt\n",
            "aclImdb/train/unsup/45738_0.txt\n",
            "aclImdb/train/unsup/45737_0.txt\n",
            "aclImdb/train/unsup/45736_0.txt\n",
            "aclImdb/train/unsup/45735_0.txt\n",
            "aclImdb/train/unsup/45734_0.txt\n",
            "aclImdb/train/unsup/45733_0.txt\n",
            "aclImdb/train/unsup/45732_0.txt\n",
            "aclImdb/train/unsup/45731_0.txt\n",
            "aclImdb/train/unsup/45730_0.txt\n",
            "aclImdb/train/unsup/45729_0.txt\n",
            "aclImdb/train/unsup/45728_0.txt\n",
            "aclImdb/train/unsup/45727_0.txt\n",
            "aclImdb/train/unsup/45726_0.txt\n",
            "aclImdb/train/unsup/45725_0.txt\n",
            "aclImdb/train/unsup/45724_0.txt\n",
            "aclImdb/train/unsup/45723_0.txt\n",
            "aclImdb/train/unsup/45722_0.txt\n",
            "aclImdb/train/unsup/45721_0.txt\n",
            "aclImdb/train/unsup/45720_0.txt\n",
            "aclImdb/train/unsup/45719_0.txt\n",
            "aclImdb/train/unsup/45718_0.txt\n",
            "aclImdb/train/unsup/45717_0.txt\n",
            "aclImdb/train/unsup/45716_0.txt\n",
            "aclImdb/train/unsup/45715_0.txt\n",
            "aclImdb/train/unsup/45714_0.txt\n",
            "aclImdb/train/unsup/45713_0.txt\n",
            "aclImdb/train/unsup/45712_0.txt\n",
            "aclImdb/train/unsup/45711_0.txt\n",
            "aclImdb/train/unsup/45710_0.txt\n",
            "aclImdb/train/unsup/45709_0.txt\n",
            "aclImdb/train/unsup/45708_0.txt\n",
            "aclImdb/train/unsup/45707_0.txt\n",
            "aclImdb/train/unsup/45706_0.txt\n",
            "aclImdb/train/unsup/45705_0.txt\n",
            "aclImdb/train/unsup/45704_0.txt\n",
            "aclImdb/train/unsup/45703_0.txt\n",
            "aclImdb/train/unsup/45702_0.txt\n",
            "aclImdb/train/unsup/45701_0.txt\n",
            "aclImdb/train/unsup/45700_0.txt\n",
            "aclImdb/train/unsup/45699_0.txt\n",
            "aclImdb/train/unsup/45698_0.txt\n",
            "aclImdb/train/unsup/45697_0.txt\n",
            "aclImdb/train/unsup/45696_0.txt\n",
            "aclImdb/train/unsup/45951_0.txt\n",
            "aclImdb/train/unsup/45950_0.txt\n",
            "aclImdb/train/unsup/45949_0.txt\n",
            "aclImdb/train/unsup/45948_0.txt\n",
            "aclImdb/train/unsup/45947_0.txt\n",
            "aclImdb/train/unsup/45946_0.txt\n",
            "aclImdb/train/unsup/45945_0.txt\n",
            "aclImdb/train/unsup/45944_0.txt\n",
            "aclImdb/train/unsup/45943_0.txt\n",
            "aclImdb/train/unsup/45942_0.txt\n",
            "aclImdb/train/unsup/45941_0.txt\n",
            "aclImdb/train/unsup/45940_0.txt\n",
            "aclImdb/train/unsup/45939_0.txt\n",
            "aclImdb/train/unsup/45938_0.txt\n",
            "aclImdb/train/unsup/45937_0.txt\n",
            "aclImdb/train/unsup/45936_0.txt\n",
            "aclImdb/train/unsup/45935_0.txt\n",
            "aclImdb/train/unsup/45934_0.txt\n",
            "aclImdb/train/unsup/45933_0.txt\n",
            "aclImdb/train/unsup/45932_0.txt\n",
            "aclImdb/train/unsup/45931_0.txt\n",
            "aclImdb/train/unsup/45930_0.txt\n",
            "aclImdb/train/unsup/45929_0.txt\n",
            "aclImdb/train/unsup/45928_0.txt\n",
            "aclImdb/train/unsup/45927_0.txt\n",
            "aclImdb/train/unsup/45926_0.txt\n",
            "aclImdb/train/unsup/45925_0.txt\n",
            "aclImdb/train/unsup/45924_0.txt\n",
            "aclImdb/train/unsup/45923_0.txt\n",
            "aclImdb/train/unsup/45922_0.txt\n",
            "aclImdb/train/unsup/45921_0.txt\n",
            "aclImdb/train/unsup/45920_0.txt\n",
            "aclImdb/train/unsup/45919_0.txt\n",
            "aclImdb/train/unsup/45918_0.txt\n",
            "aclImdb/train/unsup/45917_0.txt\n",
            "aclImdb/train/unsup/45916_0.txt\n",
            "aclImdb/train/unsup/45915_0.txt\n",
            "aclImdb/train/unsup/45914_0.txt\n",
            "aclImdb/train/unsup/45913_0.txt\n",
            "aclImdb/train/unsup/45912_0.txt\n",
            "aclImdb/train/unsup/45911_0.txt\n",
            "aclImdb/train/unsup/45910_0.txt\n",
            "aclImdb/train/unsup/45909_0.txt\n",
            "aclImdb/train/unsup/45908_0.txt\n",
            "aclImdb/train/unsup/45907_0.txt\n",
            "aclImdb/train/unsup/45906_0.txt\n",
            "aclImdb/train/unsup/45905_0.txt\n",
            "aclImdb/train/unsup/45904_0.txt\n",
            "aclImdb/train/unsup/45903_0.txt\n",
            "aclImdb/train/unsup/45902_0.txt\n",
            "aclImdb/train/unsup/45901_0.txt\n",
            "aclImdb/train/unsup/45900_0.txt\n",
            "aclImdb/train/unsup/45899_0.txt\n",
            "aclImdb/train/unsup/45898_0.txt\n",
            "aclImdb/train/unsup/45897_0.txt\n",
            "aclImdb/train/unsup/45896_0.txt\n",
            "aclImdb/train/unsup/45895_0.txt\n",
            "aclImdb/train/unsup/45894_0.txt\n",
            "aclImdb/train/unsup/45893_0.txt\n",
            "aclImdb/train/unsup/45892_0.txt\n",
            "aclImdb/train/unsup/45891_0.txt\n",
            "aclImdb/train/unsup/45890_0.txt\n",
            "aclImdb/train/unsup/45889_0.txt\n",
            "aclImdb/train/unsup/45888_0.txt\n",
            "aclImdb/train/unsup/45887_0.txt\n",
            "aclImdb/train/unsup/45886_0.txt\n",
            "aclImdb/train/unsup/45885_0.txt\n",
            "aclImdb/train/unsup/45884_0.txt\n",
            "aclImdb/train/unsup/45883_0.txt\n",
            "aclImdb/train/unsup/45882_0.txt\n",
            "aclImdb/train/unsup/45881_0.txt\n",
            "aclImdb/train/unsup/45880_0.txt\n",
            "aclImdb/train/unsup/45879_0.txt\n",
            "aclImdb/train/unsup/45878_0.txt\n",
            "aclImdb/train/unsup/45877_0.txt\n",
            "aclImdb/train/unsup/45876_0.txt\n",
            "aclImdb/train/unsup/45875_0.txt\n",
            "aclImdb/train/unsup/45874_0.txt\n",
            "aclImdb/train/unsup/45873_0.txt\n",
            "aclImdb/train/unsup/45872_0.txt\n",
            "aclImdb/train/unsup/45871_0.txt\n",
            "aclImdb/train/unsup/45870_0.txt\n",
            "aclImdb/train/unsup/45869_0.txt\n",
            "aclImdb/train/unsup/45868_0.txt\n",
            "aclImdb/train/unsup/45867_0.txt\n",
            "aclImdb/train/unsup/45866_0.txt\n",
            "aclImdb/train/unsup/45865_0.txt\n",
            "aclImdb/train/unsup/45864_0.txt\n",
            "aclImdb/train/unsup/45863_0.txt\n",
            "aclImdb/train/unsup/45862_0.txt\n",
            "aclImdb/train/unsup/45861_0.txt\n",
            "aclImdb/train/unsup/45860_0.txt\n",
            "aclImdb/train/unsup/45859_0.txt\n",
            "aclImdb/train/unsup/45858_0.txt\n",
            "aclImdb/train/unsup/45857_0.txt\n",
            "aclImdb/train/unsup/45856_0.txt\n",
            "aclImdb/train/unsup/45855_0.txt\n",
            "aclImdb/train/unsup/45854_0.txt\n",
            "aclImdb/train/unsup/45853_0.txt\n",
            "aclImdb/train/unsup/45852_0.txt\n",
            "aclImdb/train/unsup/45851_0.txt\n",
            "aclImdb/train/unsup/45850_0.txt\n",
            "aclImdb/train/unsup/45849_0.txt\n",
            "aclImdb/train/unsup/45848_0.txt\n",
            "aclImdb/train/unsup/45847_0.txt\n",
            "aclImdb/train/unsup/45846_0.txt\n",
            "aclImdb/train/unsup/45845_0.txt\n",
            "aclImdb/train/unsup/45844_0.txt\n",
            "aclImdb/train/unsup/45843_0.txt\n",
            "aclImdb/train/unsup/45842_0.txt\n",
            "aclImdb/train/unsup/45841_0.txt\n",
            "aclImdb/train/unsup/45840_0.txt\n",
            "aclImdb/train/unsup/45839_0.txt\n",
            "aclImdb/train/unsup/45838_0.txt\n",
            "aclImdb/train/unsup/45837_0.txt\n",
            "aclImdb/train/unsup/45836_0.txt\n",
            "aclImdb/train/unsup/45835_0.txt\n",
            "aclImdb/train/unsup/45834_0.txt\n",
            "aclImdb/train/unsup/45833_0.txt\n",
            "aclImdb/train/unsup/45832_0.txt\n",
            "aclImdb/train/unsup/45831_0.txt\n",
            "aclImdb/train/unsup/45830_0.txt\n",
            "aclImdb/train/unsup/45829_0.txt\n",
            "aclImdb/train/unsup/45828_0.txt\n",
            "aclImdb/train/unsup/45827_0.txt\n",
            "aclImdb/train/unsup/45826_0.txt\n",
            "aclImdb/train/unsup/45825_0.txt\n",
            "aclImdb/train/unsup/45824_0.txt\n",
            "aclImdb/train/unsup/46079_0.txt\n",
            "aclImdb/train/unsup/46078_0.txt\n",
            "aclImdb/train/unsup/46077_0.txt\n",
            "aclImdb/train/unsup/46076_0.txt\n",
            "aclImdb/train/unsup/46075_0.txt\n",
            "aclImdb/train/unsup/46074_0.txt\n",
            "aclImdb/train/unsup/46073_0.txt\n",
            "aclImdb/train/unsup/46072_0.txt\n",
            "aclImdb/train/unsup/46071_0.txt\n",
            "aclImdb/train/unsup/46070_0.txt\n",
            "aclImdb/train/unsup/46069_0.txt\n",
            "aclImdb/train/unsup/46068_0.txt\n",
            "aclImdb/train/unsup/46067_0.txt\n",
            "aclImdb/train/unsup/46066_0.txt\n",
            "aclImdb/train/unsup/46065_0.txt\n",
            "aclImdb/train/unsup/46064_0.txt\n",
            "aclImdb/train/unsup/46063_0.txt\n",
            "aclImdb/train/unsup/46062_0.txt\n",
            "aclImdb/train/unsup/46061_0.txt\n",
            "aclImdb/train/unsup/46060_0.txt\n",
            "aclImdb/train/unsup/46059_0.txt\n",
            "aclImdb/train/unsup/46058_0.txt\n",
            "aclImdb/train/unsup/46057_0.txt\n",
            "aclImdb/train/unsup/46056_0.txt\n",
            "aclImdb/train/unsup/46055_0.txt\n",
            "aclImdb/train/unsup/46054_0.txt\n",
            "aclImdb/train/unsup/46053_0.txt\n",
            "aclImdb/train/unsup/46052_0.txt\n",
            "aclImdb/train/unsup/46051_0.txt\n",
            "aclImdb/train/unsup/46050_0.txt\n",
            "aclImdb/train/unsup/46049_0.txt\n",
            "aclImdb/train/unsup/46048_0.txt\n",
            "aclImdb/train/unsup/46047_0.txt\n",
            "aclImdb/train/unsup/46046_0.txt\n",
            "aclImdb/train/unsup/46045_0.txt\n",
            "aclImdb/train/unsup/46044_0.txt\n",
            "aclImdb/train/unsup/46043_0.txt\n",
            "aclImdb/train/unsup/46042_0.txt\n",
            "aclImdb/train/unsup/46041_0.txt\n",
            "aclImdb/train/unsup/46040_0.txt\n",
            "aclImdb/train/unsup/46039_0.txt\n",
            "aclImdb/train/unsup/46038_0.txt\n",
            "aclImdb/train/unsup/46037_0.txt\n",
            "aclImdb/train/unsup/46036_0.txt\n",
            "aclImdb/train/unsup/46035_0.txt\n",
            "aclImdb/train/unsup/46034_0.txt\n",
            "aclImdb/train/unsup/46033_0.txt\n",
            "aclImdb/train/unsup/46032_0.txt\n",
            "aclImdb/train/unsup/46031_0.txt\n",
            "aclImdb/train/unsup/46030_0.txt\n",
            "aclImdb/train/unsup/46029_0.txt\n",
            "aclImdb/train/unsup/46028_0.txt\n",
            "aclImdb/train/unsup/46027_0.txt\n",
            "aclImdb/train/unsup/46026_0.txt\n",
            "aclImdb/train/unsup/46025_0.txt\n",
            "aclImdb/train/unsup/46024_0.txt\n",
            "aclImdb/train/unsup/46023_0.txt\n",
            "aclImdb/train/unsup/46022_0.txt\n",
            "aclImdb/train/unsup/46021_0.txt\n",
            "aclImdb/train/unsup/46020_0.txt\n",
            "aclImdb/train/unsup/46019_0.txt\n",
            "aclImdb/train/unsup/46018_0.txt\n",
            "aclImdb/train/unsup/46017_0.txt\n",
            "aclImdb/train/unsup/46016_0.txt\n",
            "aclImdb/train/unsup/46015_0.txt\n",
            "aclImdb/train/unsup/46014_0.txt\n",
            "aclImdb/train/unsup/46013_0.txt\n",
            "aclImdb/train/unsup/46012_0.txt\n",
            "aclImdb/train/unsup/46011_0.txt\n",
            "aclImdb/train/unsup/46010_0.txt\n",
            "aclImdb/train/unsup/46009_0.txt\n",
            "aclImdb/train/unsup/46008_0.txt\n",
            "aclImdb/train/unsup/46007_0.txt\n",
            "aclImdb/train/unsup/46006_0.txt\n",
            "aclImdb/train/unsup/46005_0.txt\n",
            "aclImdb/train/unsup/46004_0.txt\n",
            "aclImdb/train/unsup/46003_0.txt\n",
            "aclImdb/train/unsup/46002_0.txt\n",
            "aclImdb/train/unsup/46001_0.txt\n",
            "aclImdb/train/unsup/46000_0.txt\n",
            "aclImdb/train/unsup/45999_0.txt\n",
            "aclImdb/train/unsup/45998_0.txt\n",
            "aclImdb/train/unsup/45997_0.txt\n",
            "aclImdb/train/unsup/45996_0.txt\n",
            "aclImdb/train/unsup/45995_0.txt\n",
            "aclImdb/train/unsup/45994_0.txt\n",
            "aclImdb/train/unsup/45993_0.txt\n",
            "aclImdb/train/unsup/45992_0.txt\n",
            "aclImdb/train/unsup/45991_0.txt\n",
            "aclImdb/train/unsup/45990_0.txt\n",
            "aclImdb/train/unsup/45989_0.txt\n",
            "aclImdb/train/unsup/45988_0.txt\n",
            "aclImdb/train/unsup/45987_0.txt\n",
            "aclImdb/train/unsup/45986_0.txt\n",
            "aclImdb/train/unsup/45985_0.txt\n",
            "aclImdb/train/unsup/45984_0.txt\n",
            "aclImdb/train/unsup/45983_0.txt\n",
            "aclImdb/train/unsup/45982_0.txt\n",
            "aclImdb/train/unsup/45981_0.txt\n",
            "aclImdb/train/unsup/45980_0.txt\n",
            "aclImdb/train/unsup/45979_0.txt\n",
            "aclImdb/train/unsup/45978_0.txt\n",
            "aclImdb/train/unsup/45977_0.txt\n",
            "aclImdb/train/unsup/45976_0.txt\n",
            "aclImdb/train/unsup/45975_0.txt\n",
            "aclImdb/train/unsup/45974_0.txt\n",
            "aclImdb/train/unsup/45973_0.txt\n",
            "aclImdb/train/unsup/45972_0.txt\n",
            "aclImdb/train/unsup/45971_0.txt\n",
            "aclImdb/train/unsup/45970_0.txt\n",
            "aclImdb/train/unsup/45969_0.txt\n",
            "aclImdb/train/unsup/45968_0.txt\n",
            "aclImdb/train/unsup/45967_0.txt\n",
            "aclImdb/train/unsup/45966_0.txt\n",
            "aclImdb/train/unsup/45965_0.txt\n",
            "aclImdb/train/unsup/45964_0.txt\n",
            "aclImdb/train/unsup/45963_0.txt\n",
            "aclImdb/train/unsup/45962_0.txt\n",
            "aclImdb/train/unsup/45961_0.txt\n",
            "aclImdb/train/unsup/45960_0.txt\n",
            "aclImdb/train/unsup/45959_0.txt\n",
            "aclImdb/train/unsup/45958_0.txt\n",
            "aclImdb/train/unsup/45957_0.txt\n",
            "aclImdb/train/unsup/45956_0.txt\n",
            "aclImdb/train/unsup/45955_0.txt\n",
            "aclImdb/train/unsup/45954_0.txt\n",
            "aclImdb/train/unsup/45953_0.txt\n",
            "aclImdb/train/unsup/45952_0.txt\n",
            "aclImdb/train/unsup/46207_0.txt\n",
            "aclImdb/train/unsup/46206_0.txt\n",
            "aclImdb/train/unsup/46205_0.txt\n",
            "aclImdb/train/unsup/46204_0.txt\n",
            "aclImdb/train/unsup/46203_0.txt\n",
            "aclImdb/train/unsup/46202_0.txt\n",
            "aclImdb/train/unsup/46201_0.txt\n",
            "aclImdb/train/unsup/46200_0.txt\n",
            "aclImdb/train/unsup/46199_0.txt\n",
            "aclImdb/train/unsup/46198_0.txt\n",
            "aclImdb/train/unsup/46197_0.txt\n",
            "aclImdb/train/unsup/46196_0.txt\n",
            "aclImdb/train/unsup/46195_0.txt\n",
            "aclImdb/train/unsup/46194_0.txt\n",
            "aclImdb/train/unsup/46193_0.txt\n",
            "aclImdb/train/unsup/46192_0.txt\n",
            "aclImdb/train/unsup/46191_0.txt\n",
            "aclImdb/train/unsup/46190_0.txt\n",
            "aclImdb/train/unsup/46189_0.txt\n",
            "aclImdb/train/unsup/46188_0.txt\n",
            "aclImdb/train/unsup/46187_0.txt\n",
            "aclImdb/train/unsup/46186_0.txt\n",
            "aclImdb/train/unsup/46185_0.txt\n",
            "aclImdb/train/unsup/46184_0.txt\n",
            "aclImdb/train/unsup/46183_0.txt\n",
            "aclImdb/train/unsup/46182_0.txt\n",
            "aclImdb/train/unsup/46181_0.txt\n",
            "aclImdb/train/unsup/46180_0.txt\n",
            "aclImdb/train/unsup/46179_0.txt\n",
            "aclImdb/train/unsup/46178_0.txt\n",
            "aclImdb/train/unsup/46177_0.txt\n",
            "aclImdb/train/unsup/46176_0.txt\n",
            "aclImdb/train/unsup/46175_0.txt\n",
            "aclImdb/train/unsup/46174_0.txt\n",
            "aclImdb/train/unsup/46173_0.txt\n",
            "aclImdb/train/unsup/46172_0.txt\n",
            "aclImdb/train/unsup/46171_0.txt\n",
            "aclImdb/train/unsup/46170_0.txt\n",
            "aclImdb/train/unsup/46169_0.txt\n",
            "aclImdb/train/unsup/46168_0.txt\n",
            "aclImdb/train/unsup/46167_0.txt\n",
            "aclImdb/train/unsup/46166_0.txt\n",
            "aclImdb/train/unsup/46165_0.txt\n",
            "aclImdb/train/unsup/46164_0.txt\n",
            "aclImdb/train/unsup/46163_0.txt\n",
            "aclImdb/train/unsup/46162_0.txt\n",
            "aclImdb/train/unsup/46161_0.txt\n",
            "aclImdb/train/unsup/46160_0.txt\n",
            "aclImdb/train/unsup/46159_0.txt\n",
            "aclImdb/train/unsup/46158_0.txt\n",
            "aclImdb/train/unsup/46157_0.txt\n",
            "aclImdb/train/unsup/46156_0.txt\n",
            "aclImdb/train/unsup/46155_0.txt\n",
            "aclImdb/train/unsup/46154_0.txt\n",
            "aclImdb/train/unsup/46153_0.txt\n",
            "aclImdb/train/unsup/46152_0.txt\n",
            "aclImdb/train/unsup/46151_0.txt\n",
            "aclImdb/train/unsup/46150_0.txt\n",
            "aclImdb/train/unsup/46149_0.txt\n",
            "aclImdb/train/unsup/46148_0.txt\n",
            "aclImdb/train/unsup/46147_0.txt\n",
            "aclImdb/train/unsup/46146_0.txt\n",
            "aclImdb/train/unsup/46145_0.txt\n",
            "aclImdb/train/unsup/46144_0.txt\n",
            "aclImdb/train/unsup/46143_0.txt\n",
            "aclImdb/train/unsup/46142_0.txt\n",
            "aclImdb/train/unsup/46141_0.txt\n",
            "aclImdb/train/unsup/46140_0.txt\n",
            "aclImdb/train/unsup/46139_0.txt\n",
            "aclImdb/train/unsup/46138_0.txt\n",
            "aclImdb/train/unsup/46137_0.txt\n",
            "aclImdb/train/unsup/46136_0.txt\n",
            "aclImdb/train/unsup/46135_0.txt\n",
            "aclImdb/train/unsup/46134_0.txt\n",
            "aclImdb/train/unsup/46133_0.txt\n",
            "aclImdb/train/unsup/46132_0.txt\n",
            "aclImdb/train/unsup/46131_0.txt\n",
            "aclImdb/train/unsup/46130_0.txt\n",
            "aclImdb/train/unsup/46129_0.txt\n",
            "aclImdb/train/unsup/46128_0.txt\n",
            "aclImdb/train/unsup/46127_0.txt\n",
            "aclImdb/train/unsup/46126_0.txt\n",
            "aclImdb/train/unsup/46125_0.txt\n",
            "aclImdb/train/unsup/46124_0.txt\n",
            "aclImdb/train/unsup/46123_0.txt\n",
            "aclImdb/train/unsup/46122_0.txt\n",
            "aclImdb/train/unsup/46121_0.txt\n",
            "aclImdb/train/unsup/46120_0.txt\n",
            "aclImdb/train/unsup/46119_0.txt\n",
            "aclImdb/train/unsup/46118_0.txt\n",
            "aclImdb/train/unsup/46117_0.txt\n",
            "aclImdb/train/unsup/46116_0.txt\n",
            "aclImdb/train/unsup/46115_0.txt\n",
            "aclImdb/train/unsup/46114_0.txt\n",
            "aclImdb/train/unsup/46113_0.txt\n",
            "aclImdb/train/unsup/46112_0.txt\n",
            "aclImdb/train/unsup/46111_0.txt\n",
            "aclImdb/train/unsup/46110_0.txt\n",
            "aclImdb/train/unsup/46109_0.txt\n",
            "aclImdb/train/unsup/46108_0.txt\n",
            "aclImdb/train/unsup/46107_0.txt\n",
            "aclImdb/train/unsup/46106_0.txt\n",
            "aclImdb/train/unsup/46105_0.txt\n",
            "aclImdb/train/unsup/46104_0.txt\n",
            "aclImdb/train/unsup/46103_0.txt\n",
            "aclImdb/train/unsup/46102_0.txt\n",
            "aclImdb/train/unsup/46101_0.txt\n",
            "aclImdb/train/unsup/46100_0.txt\n",
            "aclImdb/train/unsup/46099_0.txt\n",
            "aclImdb/train/unsup/46098_0.txt\n",
            "aclImdb/train/unsup/46097_0.txt\n",
            "aclImdb/train/unsup/46096_0.txt\n",
            "aclImdb/train/unsup/46095_0.txt\n",
            "aclImdb/train/unsup/46094_0.txt\n",
            "aclImdb/train/unsup/46093_0.txt\n",
            "aclImdb/train/unsup/46092_0.txt\n",
            "aclImdb/train/unsup/46091_0.txt\n",
            "aclImdb/train/unsup/46090_0.txt\n",
            "aclImdb/train/unsup/46089_0.txt\n",
            "aclImdb/train/unsup/46088_0.txt\n",
            "aclImdb/train/unsup/46087_0.txt\n",
            "aclImdb/train/unsup/46086_0.txt\n",
            "aclImdb/train/unsup/46085_0.txt\n",
            "aclImdb/train/unsup/46084_0.txt\n",
            "aclImdb/train/unsup/46083_0.txt\n",
            "aclImdb/train/unsup/46082_0.txt\n",
            "aclImdb/train/unsup/46081_0.txt\n",
            "aclImdb/train/unsup/46080_0.txt\n",
            "aclImdb/train/unsup/46335_0.txt\n",
            "aclImdb/train/unsup/46334_0.txt\n",
            "aclImdb/train/unsup/46333_0.txt\n",
            "aclImdb/train/unsup/46332_0.txt\n",
            "aclImdb/train/unsup/46331_0.txt\n",
            "aclImdb/train/unsup/46330_0.txt\n",
            "aclImdb/train/unsup/46329_0.txt\n",
            "aclImdb/train/unsup/46328_0.txt\n",
            "aclImdb/train/unsup/46327_0.txt\n",
            "aclImdb/train/unsup/46326_0.txt\n",
            "aclImdb/train/unsup/46325_0.txt\n",
            "aclImdb/train/unsup/46324_0.txt\n",
            "aclImdb/train/unsup/46323_0.txt\n",
            "aclImdb/train/unsup/46322_0.txt\n",
            "aclImdb/train/unsup/46321_0.txt\n",
            "aclImdb/train/unsup/46320_0.txt\n",
            "aclImdb/train/unsup/46319_0.txt\n",
            "aclImdb/train/unsup/46318_0.txt\n",
            "aclImdb/train/unsup/46317_0.txt\n",
            "aclImdb/train/unsup/46316_0.txt\n",
            "aclImdb/train/unsup/46315_0.txt\n",
            "aclImdb/train/unsup/46314_0.txt\n",
            "aclImdb/train/unsup/46313_0.txt\n",
            "aclImdb/train/unsup/46312_0.txt\n",
            "aclImdb/train/unsup/46311_0.txt\n",
            "aclImdb/train/unsup/46310_0.txt\n",
            "aclImdb/train/unsup/46309_0.txt\n",
            "aclImdb/train/unsup/46308_0.txt\n",
            "aclImdb/train/unsup/46307_0.txt\n",
            "aclImdb/train/unsup/46306_0.txt\n",
            "aclImdb/train/unsup/46305_0.txt\n",
            "aclImdb/train/unsup/46304_0.txt\n",
            "aclImdb/train/unsup/46303_0.txt\n",
            "aclImdb/train/unsup/46302_0.txt\n",
            "aclImdb/train/unsup/46301_0.txt\n",
            "aclImdb/train/unsup/46300_0.txt\n",
            "aclImdb/train/unsup/46299_0.txt\n",
            "aclImdb/train/unsup/46298_0.txt\n",
            "aclImdb/train/unsup/46297_0.txt\n",
            "aclImdb/train/unsup/46296_0.txt\n",
            "aclImdb/train/unsup/46295_0.txt\n",
            "aclImdb/train/unsup/46294_0.txt\n",
            "aclImdb/train/unsup/46293_0.txt\n",
            "aclImdb/train/unsup/46292_0.txt\n",
            "aclImdb/train/unsup/46291_0.txt\n",
            "aclImdb/train/unsup/46290_0.txt\n",
            "aclImdb/train/unsup/46289_0.txt\n",
            "aclImdb/train/unsup/46288_0.txt\n",
            "aclImdb/train/unsup/46287_0.txt\n",
            "aclImdb/train/unsup/46286_0.txt\n",
            "aclImdb/train/unsup/46285_0.txt\n",
            "aclImdb/train/unsup/46284_0.txt\n",
            "aclImdb/train/unsup/46283_0.txt\n",
            "aclImdb/train/unsup/46282_0.txt\n",
            "aclImdb/train/unsup/46281_0.txt\n",
            "aclImdb/train/unsup/46280_0.txt\n",
            "aclImdb/train/unsup/46279_0.txt\n",
            "aclImdb/train/unsup/46278_0.txt\n",
            "aclImdb/train/unsup/46277_0.txt\n",
            "aclImdb/train/unsup/46276_0.txt\n",
            "aclImdb/train/unsup/46275_0.txt\n",
            "aclImdb/train/unsup/46274_0.txt\n",
            "aclImdb/train/unsup/46273_0.txt\n",
            "aclImdb/train/unsup/46272_0.txt\n",
            "aclImdb/train/unsup/46271_0.txt\n",
            "aclImdb/train/unsup/46270_0.txt\n",
            "aclImdb/train/unsup/46269_0.txt\n",
            "aclImdb/train/unsup/46268_0.txt\n",
            "aclImdb/train/unsup/46267_0.txt\n",
            "aclImdb/train/unsup/46266_0.txt\n",
            "aclImdb/train/unsup/46265_0.txt\n",
            "aclImdb/train/unsup/46264_0.txt\n",
            "aclImdb/train/unsup/46263_0.txt\n",
            "aclImdb/train/unsup/46262_0.txt\n",
            "aclImdb/train/unsup/46261_0.txt\n",
            "aclImdb/train/unsup/46260_0.txt\n",
            "aclImdb/train/unsup/46259_0.txt\n",
            "aclImdb/train/unsup/46258_0.txt\n",
            "aclImdb/train/unsup/46257_0.txt\n",
            "aclImdb/train/unsup/46256_0.txt\n",
            "aclImdb/train/unsup/46255_0.txt\n",
            "aclImdb/train/unsup/46254_0.txt\n",
            "aclImdb/train/unsup/46253_0.txt\n",
            "aclImdb/train/unsup/46252_0.txt\n",
            "aclImdb/train/unsup/46251_0.txt\n",
            "aclImdb/train/unsup/46250_0.txt\n",
            "aclImdb/train/unsup/46249_0.txt\n",
            "aclImdb/train/unsup/46248_0.txt\n",
            "aclImdb/train/unsup/46247_0.txt\n",
            "aclImdb/train/unsup/46246_0.txt\n",
            "aclImdb/train/unsup/46245_0.txt\n",
            "aclImdb/train/unsup/46244_0.txt\n",
            "aclImdb/train/unsup/46243_0.txt\n",
            "aclImdb/train/unsup/46242_0.txt\n",
            "aclImdb/train/unsup/46241_0.txt\n",
            "aclImdb/train/unsup/46240_0.txt\n",
            "aclImdb/train/unsup/46239_0.txt\n",
            "aclImdb/train/unsup/46238_0.txt\n",
            "aclImdb/train/unsup/46237_0.txt\n",
            "aclImdb/train/unsup/46236_0.txt\n",
            "aclImdb/train/unsup/46235_0.txt\n",
            "aclImdb/train/unsup/46234_0.txt\n",
            "aclImdb/train/unsup/46233_0.txt\n",
            "aclImdb/train/unsup/46232_0.txt\n",
            "aclImdb/train/unsup/46231_0.txt\n",
            "aclImdb/train/unsup/46230_0.txt\n",
            "aclImdb/train/unsup/46229_0.txt\n",
            "aclImdb/train/unsup/46228_0.txt\n",
            "aclImdb/train/unsup/46227_0.txt\n",
            "aclImdb/train/unsup/46226_0.txt\n",
            "aclImdb/train/unsup/46225_0.txt\n",
            "aclImdb/train/unsup/46224_0.txt\n",
            "aclImdb/train/unsup/46223_0.txt\n",
            "aclImdb/train/unsup/46222_0.txt\n",
            "aclImdb/train/unsup/46221_0.txt\n",
            "aclImdb/train/unsup/46220_0.txt\n",
            "aclImdb/train/unsup/46219_0.txt\n",
            "aclImdb/train/unsup/46218_0.txt\n",
            "aclImdb/train/unsup/46217_0.txt\n",
            "aclImdb/train/unsup/46216_0.txt\n",
            "aclImdb/train/unsup/46215_0.txt\n",
            "aclImdb/train/unsup/46214_0.txt\n",
            "aclImdb/train/unsup/46213_0.txt\n",
            "aclImdb/train/unsup/46212_0.txt\n",
            "aclImdb/train/unsup/46211_0.txt\n",
            "aclImdb/train/unsup/46210_0.txt\n",
            "aclImdb/train/unsup/46209_0.txt\n",
            "aclImdb/train/unsup/46208_0.txt\n",
            "aclImdb/train/unsup/46463_0.txt\n",
            "aclImdb/train/unsup/46462_0.txt\n",
            "aclImdb/train/unsup/46461_0.txt\n",
            "aclImdb/train/unsup/46460_0.txt\n",
            "aclImdb/train/unsup/46459_0.txt\n",
            "aclImdb/train/unsup/46458_0.txt\n",
            "aclImdb/train/unsup/46457_0.txt\n",
            "aclImdb/train/unsup/46456_0.txt\n",
            "aclImdb/train/unsup/46455_0.txt\n",
            "aclImdb/train/unsup/46454_0.txt\n",
            "aclImdb/train/unsup/46453_0.txt\n",
            "aclImdb/train/unsup/46452_0.txt\n",
            "aclImdb/train/unsup/46451_0.txt\n",
            "aclImdb/train/unsup/46450_0.txt\n",
            "aclImdb/train/unsup/46449_0.txt\n",
            "aclImdb/train/unsup/46448_0.txt\n",
            "aclImdb/train/unsup/46447_0.txt\n",
            "aclImdb/train/unsup/46446_0.txt\n",
            "aclImdb/train/unsup/46445_0.txt\n",
            "aclImdb/train/unsup/46444_0.txt\n",
            "aclImdb/train/unsup/46443_0.txt\n",
            "aclImdb/train/unsup/46442_0.txt\n",
            "aclImdb/train/unsup/46441_0.txt\n",
            "aclImdb/train/unsup/46440_0.txt\n",
            "aclImdb/train/unsup/46439_0.txt\n",
            "aclImdb/train/unsup/46438_0.txt\n",
            "aclImdb/train/unsup/46437_0.txt\n",
            "aclImdb/train/unsup/46436_0.txt\n",
            "aclImdb/train/unsup/46435_0.txt\n",
            "aclImdb/train/unsup/46434_0.txt\n",
            "aclImdb/train/unsup/46433_0.txt\n",
            "aclImdb/train/unsup/46432_0.txt\n",
            "aclImdb/train/unsup/46431_0.txt\n",
            "aclImdb/train/unsup/46430_0.txt\n",
            "aclImdb/train/unsup/46429_0.txt\n",
            "aclImdb/train/unsup/46428_0.txt\n",
            "aclImdb/train/unsup/46427_0.txt\n",
            "aclImdb/train/unsup/46426_0.txt\n",
            "aclImdb/train/unsup/46425_0.txt\n",
            "aclImdb/train/unsup/46424_0.txt\n",
            "aclImdb/train/unsup/46423_0.txt\n",
            "aclImdb/train/unsup/46422_0.txt\n",
            "aclImdb/train/unsup/46421_0.txt\n",
            "aclImdb/train/unsup/46420_0.txt\n",
            "aclImdb/train/unsup/46419_0.txt\n",
            "aclImdb/train/unsup/46418_0.txt\n",
            "aclImdb/train/unsup/46417_0.txt\n",
            "aclImdb/train/unsup/46416_0.txt\n",
            "aclImdb/train/unsup/46415_0.txt\n",
            "aclImdb/train/unsup/46414_0.txt\n",
            "aclImdb/train/unsup/46413_0.txt\n",
            "aclImdb/train/unsup/46412_0.txt\n",
            "aclImdb/train/unsup/46411_0.txt\n",
            "aclImdb/train/unsup/46410_0.txt\n",
            "aclImdb/train/unsup/46409_0.txt\n",
            "aclImdb/train/unsup/46408_0.txt\n",
            "aclImdb/train/unsup/46407_0.txt\n",
            "aclImdb/train/unsup/46406_0.txt\n",
            "aclImdb/train/unsup/46405_0.txt\n",
            "aclImdb/train/unsup/46404_0.txt\n",
            "aclImdb/train/unsup/46403_0.txt\n",
            "aclImdb/train/unsup/46402_0.txt\n",
            "aclImdb/train/unsup/46401_0.txt\n",
            "aclImdb/train/unsup/46400_0.txt\n",
            "aclImdb/train/unsup/46399_0.txt\n",
            "aclImdb/train/unsup/46398_0.txt\n",
            "aclImdb/train/unsup/46397_0.txt\n",
            "aclImdb/train/unsup/46396_0.txt\n",
            "aclImdb/train/unsup/46395_0.txt\n",
            "aclImdb/train/unsup/46394_0.txt\n",
            "aclImdb/train/unsup/46393_0.txt\n",
            "aclImdb/train/unsup/46392_0.txt\n",
            "aclImdb/train/unsup/46391_0.txt\n",
            "aclImdb/train/unsup/46390_0.txt\n",
            "aclImdb/train/unsup/46389_0.txt\n",
            "aclImdb/train/unsup/46388_0.txt\n",
            "aclImdb/train/unsup/46387_0.txt\n",
            "aclImdb/train/unsup/46386_0.txt\n",
            "aclImdb/train/unsup/46385_0.txt\n",
            "aclImdb/train/unsup/46384_0.txt\n",
            "aclImdb/train/unsup/46383_0.txt\n",
            "aclImdb/train/unsup/46382_0.txt\n",
            "aclImdb/train/unsup/46381_0.txt\n",
            "aclImdb/train/unsup/46380_0.txt\n",
            "aclImdb/train/unsup/46379_0.txt\n",
            "aclImdb/train/unsup/46378_0.txt\n",
            "aclImdb/train/unsup/46377_0.txt\n",
            "aclImdb/train/unsup/46376_0.txt\n",
            "aclImdb/train/unsup/46375_0.txt\n",
            "aclImdb/train/unsup/46374_0.txt\n",
            "aclImdb/train/unsup/46373_0.txt\n",
            "aclImdb/train/unsup/46372_0.txt\n",
            "aclImdb/train/unsup/46371_0.txt\n",
            "aclImdb/train/unsup/46370_0.txt\n",
            "aclImdb/train/unsup/46369_0.txt\n",
            "aclImdb/train/unsup/46368_0.txt\n",
            "aclImdb/train/unsup/46367_0.txt\n",
            "aclImdb/train/unsup/46366_0.txt\n",
            "aclImdb/train/unsup/46365_0.txt\n",
            "aclImdb/train/unsup/46364_0.txt\n",
            "aclImdb/train/unsup/46363_0.txt\n",
            "aclImdb/train/unsup/46362_0.txt\n",
            "aclImdb/train/unsup/46361_0.txt\n",
            "aclImdb/train/unsup/46360_0.txt\n",
            "aclImdb/train/unsup/46359_0.txt\n",
            "aclImdb/train/unsup/46358_0.txt\n",
            "aclImdb/train/unsup/46357_0.txt\n",
            "aclImdb/train/unsup/46356_0.txt\n",
            "aclImdb/train/unsup/46355_0.txt\n",
            "aclImdb/train/unsup/46354_0.txt\n",
            "aclImdb/train/unsup/46353_0.txt\n",
            "aclImdb/train/unsup/46352_0.txt\n",
            "aclImdb/train/unsup/46351_0.txt\n",
            "aclImdb/train/unsup/46350_0.txt\n",
            "aclImdb/train/unsup/46349_0.txt\n",
            "aclImdb/train/unsup/46348_0.txt\n",
            "aclImdb/train/unsup/46347_0.txt\n",
            "aclImdb/train/unsup/46346_0.txt\n",
            "aclImdb/train/unsup/46345_0.txt\n",
            "aclImdb/train/unsup/46344_0.txt\n",
            "aclImdb/train/unsup/46343_0.txt\n",
            "aclImdb/train/unsup/46342_0.txt\n",
            "aclImdb/train/unsup/46341_0.txt\n",
            "aclImdb/train/unsup/46340_0.txt\n",
            "aclImdb/train/unsup/46339_0.txt\n",
            "aclImdb/train/unsup/46338_0.txt\n",
            "aclImdb/train/unsup/46337_0.txt\n",
            "aclImdb/train/unsup/46336_0.txt\n",
            "aclImdb/train/unsup/46591_0.txt\n",
            "aclImdb/train/unsup/46590_0.txt\n",
            "aclImdb/train/unsup/46589_0.txt\n",
            "aclImdb/train/unsup/46588_0.txt\n",
            "aclImdb/train/unsup/46587_0.txt\n",
            "aclImdb/train/unsup/46586_0.txt\n",
            "aclImdb/train/unsup/46585_0.txt\n",
            "aclImdb/train/unsup/46584_0.txt\n",
            "aclImdb/train/unsup/46583_0.txt\n",
            "aclImdb/train/unsup/46582_0.txt\n",
            "aclImdb/train/unsup/46581_0.txt\n",
            "aclImdb/train/unsup/46580_0.txt\n",
            "aclImdb/train/unsup/46579_0.txt\n",
            "aclImdb/train/unsup/46578_0.txt\n",
            "aclImdb/train/unsup/46577_0.txt\n",
            "aclImdb/train/unsup/46576_0.txt\n",
            "aclImdb/train/unsup/46575_0.txt\n",
            "aclImdb/train/unsup/46574_0.txt\n",
            "aclImdb/train/unsup/46573_0.txt\n",
            "aclImdb/train/unsup/46572_0.txt\n",
            "aclImdb/train/unsup/46571_0.txt\n",
            "aclImdb/train/unsup/46570_0.txt\n",
            "aclImdb/train/unsup/46569_0.txt\n",
            "aclImdb/train/unsup/46568_0.txt\n",
            "aclImdb/train/unsup/46567_0.txt\n",
            "aclImdb/train/unsup/46566_0.txt\n",
            "aclImdb/train/unsup/46565_0.txt\n",
            "aclImdb/train/unsup/46564_0.txt\n",
            "aclImdb/train/unsup/46563_0.txt\n",
            "aclImdb/train/unsup/46562_0.txt\n",
            "aclImdb/train/unsup/46561_0.txt\n",
            "aclImdb/train/unsup/46560_0.txt\n",
            "aclImdb/train/unsup/46559_0.txt\n",
            "aclImdb/train/unsup/46558_0.txt\n",
            "aclImdb/train/unsup/46557_0.txt\n",
            "aclImdb/train/unsup/46556_0.txt\n",
            "aclImdb/train/unsup/46555_0.txt\n",
            "aclImdb/train/unsup/46554_0.txt\n",
            "aclImdb/train/unsup/46553_0.txt\n",
            "aclImdb/train/unsup/46552_0.txt\n",
            "aclImdb/train/unsup/46551_0.txt\n",
            "aclImdb/train/unsup/46550_0.txt\n",
            "aclImdb/train/unsup/46549_0.txt\n",
            "aclImdb/train/unsup/46548_0.txt\n",
            "aclImdb/train/unsup/46547_0.txt\n",
            "aclImdb/train/unsup/46546_0.txt\n",
            "aclImdb/train/unsup/46545_0.txt\n",
            "aclImdb/train/unsup/46544_0.txt\n",
            "aclImdb/train/unsup/46543_0.txt\n",
            "aclImdb/train/unsup/46542_0.txt\n",
            "aclImdb/train/unsup/46541_0.txt\n",
            "aclImdb/train/unsup/46540_0.txt\n",
            "aclImdb/train/unsup/46539_0.txt\n",
            "aclImdb/train/unsup/46538_0.txt\n",
            "aclImdb/train/unsup/46537_0.txt\n",
            "aclImdb/train/unsup/46536_0.txt\n",
            "aclImdb/train/unsup/46535_0.txt\n",
            "aclImdb/train/unsup/46534_0.txt\n",
            "aclImdb/train/unsup/46533_0.txt\n",
            "aclImdb/train/unsup/46532_0.txt\n",
            "aclImdb/train/unsup/46531_0.txt\n",
            "aclImdb/train/unsup/46530_0.txt\n",
            "aclImdb/train/unsup/46529_0.txt\n",
            "aclImdb/train/unsup/46528_0.txt\n",
            "aclImdb/train/unsup/46527_0.txt\n",
            "aclImdb/train/unsup/46526_0.txt\n",
            "aclImdb/train/unsup/46525_0.txt\n",
            "aclImdb/train/unsup/46524_0.txt\n",
            "aclImdb/train/unsup/46523_0.txt\n",
            "aclImdb/train/unsup/46522_0.txt\n",
            "aclImdb/train/unsup/46521_0.txt\n",
            "aclImdb/train/unsup/46520_0.txt\n",
            "aclImdb/train/unsup/46519_0.txt\n",
            "aclImdb/train/unsup/46518_0.txt\n",
            "aclImdb/train/unsup/46517_0.txt\n",
            "aclImdb/train/unsup/46516_0.txt\n",
            "aclImdb/train/unsup/46515_0.txt\n",
            "aclImdb/train/unsup/46514_0.txt\n",
            "aclImdb/train/unsup/46513_0.txt\n",
            "aclImdb/train/unsup/46512_0.txt\n",
            "aclImdb/train/unsup/46511_0.txt\n",
            "aclImdb/train/unsup/46510_0.txt\n",
            "aclImdb/train/unsup/46509_0.txt\n",
            "aclImdb/train/unsup/46508_0.txt\n",
            "aclImdb/train/unsup/46507_0.txt\n",
            "aclImdb/train/unsup/46506_0.txt\n",
            "aclImdb/train/unsup/46505_0.txt\n",
            "aclImdb/train/unsup/46504_0.txt\n",
            "aclImdb/train/unsup/46503_0.txt\n",
            "aclImdb/train/unsup/46502_0.txt\n",
            "aclImdb/train/unsup/46501_0.txt\n",
            "aclImdb/train/unsup/46500_0.txt\n",
            "aclImdb/train/unsup/46499_0.txt\n",
            "aclImdb/train/unsup/46498_0.txt\n",
            "aclImdb/train/unsup/46497_0.txt\n",
            "aclImdb/train/unsup/46496_0.txt\n",
            "aclImdb/train/unsup/46495_0.txt\n",
            "aclImdb/train/unsup/46494_0.txt\n",
            "aclImdb/train/unsup/46493_0.txt\n",
            "aclImdb/train/unsup/46492_0.txt\n",
            "aclImdb/train/unsup/46491_0.txt\n",
            "aclImdb/train/unsup/46490_0.txt\n",
            "aclImdb/train/unsup/46489_0.txt\n",
            "aclImdb/train/unsup/46488_0.txt\n",
            "aclImdb/train/unsup/46487_0.txt\n",
            "aclImdb/train/unsup/46486_0.txt\n",
            "aclImdb/train/unsup/46485_0.txt\n",
            "aclImdb/train/unsup/46484_0.txt\n",
            "aclImdb/train/unsup/46483_0.txt\n",
            "aclImdb/train/unsup/46482_0.txt\n",
            "aclImdb/train/unsup/46481_0.txt\n",
            "aclImdb/train/unsup/46480_0.txt\n",
            "aclImdb/train/unsup/46479_0.txt\n",
            "aclImdb/train/unsup/46478_0.txt\n",
            "aclImdb/train/unsup/46477_0.txt\n",
            "aclImdb/train/unsup/46476_0.txt\n",
            "aclImdb/train/unsup/46475_0.txt\n",
            "aclImdb/train/unsup/46474_0.txt\n",
            "aclImdb/train/unsup/46473_0.txt\n",
            "aclImdb/train/unsup/46472_0.txt\n",
            "aclImdb/train/unsup/46471_0.txt\n",
            "aclImdb/train/unsup/46470_0.txt\n",
            "aclImdb/train/unsup/46469_0.txt\n",
            "aclImdb/train/unsup/46468_0.txt\n",
            "aclImdb/train/unsup/46467_0.txt\n",
            "aclImdb/train/unsup/46466_0.txt\n",
            "aclImdb/train/unsup/46465_0.txt\n",
            "aclImdb/train/unsup/46464_0.txt\n",
            "aclImdb/train/unsup/46719_0.txt\n",
            "aclImdb/train/unsup/46718_0.txt\n",
            "aclImdb/train/unsup/46717_0.txt\n",
            "aclImdb/train/unsup/46716_0.txt\n",
            "aclImdb/train/unsup/46715_0.txt\n",
            "aclImdb/train/unsup/46714_0.txt\n",
            "aclImdb/train/unsup/46713_0.txt\n",
            "aclImdb/train/unsup/46712_0.txt\n",
            "aclImdb/train/unsup/46711_0.txt\n",
            "aclImdb/train/unsup/46710_0.txt\n",
            "aclImdb/train/unsup/46709_0.txt\n",
            "aclImdb/train/unsup/46708_0.txt\n",
            "aclImdb/train/unsup/46707_0.txt\n",
            "aclImdb/train/unsup/46706_0.txt\n",
            "aclImdb/train/unsup/46705_0.txt\n",
            "aclImdb/train/unsup/46704_0.txt\n",
            "aclImdb/train/unsup/46703_0.txt\n",
            "aclImdb/train/unsup/46702_0.txt\n",
            "aclImdb/train/unsup/46701_0.txt\n",
            "aclImdb/train/unsup/46700_0.txt\n",
            "aclImdb/train/unsup/46699_0.txt\n",
            "aclImdb/train/unsup/46698_0.txt\n",
            "aclImdb/train/unsup/46697_0.txt\n",
            "aclImdb/train/unsup/46696_0.txt\n",
            "aclImdb/train/unsup/46695_0.txt\n",
            "aclImdb/train/unsup/46694_0.txt\n",
            "aclImdb/train/unsup/46693_0.txt\n",
            "aclImdb/train/unsup/46692_0.txt\n",
            "aclImdb/train/unsup/46691_0.txt\n",
            "aclImdb/train/unsup/46690_0.txt\n",
            "aclImdb/train/unsup/46689_0.txt\n",
            "aclImdb/train/unsup/46688_0.txt\n",
            "aclImdb/train/unsup/46687_0.txt\n",
            "aclImdb/train/unsup/46686_0.txt\n",
            "aclImdb/train/unsup/46685_0.txt\n",
            "aclImdb/train/unsup/46684_0.txt\n",
            "aclImdb/train/unsup/46683_0.txt\n",
            "aclImdb/train/unsup/46682_0.txt\n",
            "aclImdb/train/unsup/46681_0.txt\n",
            "aclImdb/train/unsup/46680_0.txt\n",
            "aclImdb/train/unsup/46679_0.txt\n",
            "aclImdb/train/unsup/46678_0.txt\n",
            "aclImdb/train/unsup/46677_0.txt\n",
            "aclImdb/train/unsup/46676_0.txt\n",
            "aclImdb/train/unsup/46675_0.txt\n",
            "aclImdb/train/unsup/46674_0.txt\n",
            "aclImdb/train/unsup/46673_0.txt\n",
            "aclImdb/train/unsup/46672_0.txt\n",
            "aclImdb/train/unsup/46671_0.txt\n",
            "aclImdb/train/unsup/46670_0.txt\n",
            "aclImdb/train/unsup/46669_0.txt\n",
            "aclImdb/train/unsup/46668_0.txt\n",
            "aclImdb/train/unsup/46667_0.txt\n",
            "aclImdb/train/unsup/46666_0.txt\n",
            "aclImdb/train/unsup/46665_0.txt\n",
            "aclImdb/train/unsup/46664_0.txt\n",
            "aclImdb/train/unsup/46663_0.txt\n",
            "aclImdb/train/unsup/46662_0.txt\n",
            "aclImdb/train/unsup/46661_0.txt\n",
            "aclImdb/train/unsup/46660_0.txt\n",
            "aclImdb/train/unsup/46659_0.txt\n",
            "aclImdb/train/unsup/46658_0.txt\n",
            "aclImdb/train/unsup/46657_0.txt\n",
            "aclImdb/train/unsup/46656_0.txt\n",
            "aclImdb/train/unsup/46655_0.txt\n",
            "aclImdb/train/unsup/46654_0.txt\n",
            "aclImdb/train/unsup/46653_0.txt\n",
            "aclImdb/train/unsup/46652_0.txt\n",
            "aclImdb/train/unsup/46651_0.txt\n",
            "aclImdb/train/unsup/46650_0.txt\n",
            "aclImdb/train/unsup/46649_0.txt\n",
            "aclImdb/train/unsup/46648_0.txt\n",
            "aclImdb/train/unsup/46647_0.txt\n",
            "aclImdb/train/unsup/46646_0.txt\n",
            "aclImdb/train/unsup/46645_0.txt\n",
            "aclImdb/train/unsup/46644_0.txt\n",
            "aclImdb/train/unsup/46643_0.txt\n",
            "aclImdb/train/unsup/46642_0.txt\n",
            "aclImdb/train/unsup/46641_0.txt\n",
            "aclImdb/train/unsup/46640_0.txt\n",
            "aclImdb/train/unsup/46639_0.txt\n",
            "aclImdb/train/unsup/46638_0.txt\n",
            "aclImdb/train/unsup/46637_0.txt\n",
            "aclImdb/train/unsup/46636_0.txt\n",
            "aclImdb/train/unsup/46635_0.txt\n",
            "aclImdb/train/unsup/46634_0.txt\n",
            "aclImdb/train/unsup/46633_0.txt\n",
            "aclImdb/train/unsup/46632_0.txt\n",
            "aclImdb/train/unsup/46631_0.txt\n",
            "aclImdb/train/unsup/46630_0.txt\n",
            "aclImdb/train/unsup/46629_0.txt\n",
            "aclImdb/train/unsup/46628_0.txt\n",
            "aclImdb/train/unsup/46627_0.txt\n",
            "aclImdb/train/unsup/46626_0.txt\n",
            "aclImdb/train/unsup/46625_0.txt\n",
            "aclImdb/train/unsup/46624_0.txt\n",
            "aclImdb/train/unsup/46623_0.txt\n",
            "aclImdb/train/unsup/46622_0.txt\n",
            "aclImdb/train/unsup/46621_0.txt\n",
            "aclImdb/train/unsup/46620_0.txt\n",
            "aclImdb/train/unsup/46619_0.txt\n",
            "aclImdb/train/unsup/46618_0.txt\n",
            "aclImdb/train/unsup/46617_0.txt\n",
            "aclImdb/train/unsup/46616_0.txt\n",
            "aclImdb/train/unsup/46615_0.txt\n",
            "aclImdb/train/unsup/46614_0.txt\n",
            "aclImdb/train/unsup/46613_0.txt\n",
            "aclImdb/train/unsup/46612_0.txt\n",
            "aclImdb/train/unsup/46611_0.txt\n",
            "aclImdb/train/unsup/46610_0.txt\n",
            "aclImdb/train/unsup/46609_0.txt\n",
            "aclImdb/train/unsup/46608_0.txt\n",
            "aclImdb/train/unsup/46607_0.txt\n",
            "aclImdb/train/unsup/46606_0.txt\n",
            "aclImdb/train/unsup/46605_0.txt\n",
            "aclImdb/train/unsup/46604_0.txt\n",
            "aclImdb/train/unsup/46603_0.txt\n",
            "aclImdb/train/unsup/46602_0.txt\n",
            "aclImdb/train/unsup/46601_0.txt\n",
            "aclImdb/train/unsup/46600_0.txt\n",
            "aclImdb/train/unsup/46599_0.txt\n",
            "aclImdb/train/unsup/46598_0.txt\n",
            "aclImdb/train/unsup/46597_0.txt\n",
            "aclImdb/train/unsup/46596_0.txt\n",
            "aclImdb/train/unsup/46595_0.txt\n",
            "aclImdb/train/unsup/46594_0.txt\n",
            "aclImdb/train/unsup/46593_0.txt\n",
            "aclImdb/train/unsup/46592_0.txt\n",
            "aclImdb/train/unsup/46847_0.txt\n",
            "aclImdb/train/unsup/46846_0.txt\n",
            "aclImdb/train/unsup/46845_0.txt\n",
            "aclImdb/train/unsup/46844_0.txt\n",
            "aclImdb/train/unsup/46843_0.txt\n",
            "aclImdb/train/unsup/46842_0.txt\n",
            "aclImdb/train/unsup/46841_0.txt\n",
            "aclImdb/train/unsup/46840_0.txt\n",
            "aclImdb/train/unsup/46839_0.txt\n",
            "aclImdb/train/unsup/46838_0.txt\n",
            "aclImdb/train/unsup/46837_0.txt\n",
            "aclImdb/train/unsup/46836_0.txt\n",
            "aclImdb/train/unsup/46835_0.txt\n",
            "aclImdb/train/unsup/46834_0.txt\n",
            "aclImdb/train/unsup/46833_0.txt\n",
            "aclImdb/train/unsup/46832_0.txt\n",
            "aclImdb/train/unsup/46831_0.txt\n",
            "aclImdb/train/unsup/46830_0.txt\n",
            "aclImdb/train/unsup/46829_0.txt\n",
            "aclImdb/train/unsup/46828_0.txt\n",
            "aclImdb/train/unsup/46827_0.txt\n",
            "aclImdb/train/unsup/46826_0.txt\n",
            "aclImdb/train/unsup/46825_0.txt\n",
            "aclImdb/train/unsup/46824_0.txt\n",
            "aclImdb/train/unsup/46823_0.txt\n",
            "aclImdb/train/unsup/46822_0.txt\n",
            "aclImdb/train/unsup/46821_0.txt\n",
            "aclImdb/train/unsup/46820_0.txt\n",
            "aclImdb/train/unsup/46819_0.txt\n",
            "aclImdb/train/unsup/46818_0.txt\n",
            "aclImdb/train/unsup/46817_0.txt\n",
            "aclImdb/train/unsup/46816_0.txt\n",
            "aclImdb/train/unsup/46815_0.txt\n",
            "aclImdb/train/unsup/46814_0.txt\n",
            "aclImdb/train/unsup/46813_0.txt\n",
            "aclImdb/train/unsup/46812_0.txt\n",
            "aclImdb/train/unsup/46811_0.txt\n",
            "aclImdb/train/unsup/46810_0.txt\n",
            "aclImdb/train/unsup/46809_0.txt\n",
            "aclImdb/train/unsup/46808_0.txt\n",
            "aclImdb/train/unsup/46807_0.txt\n",
            "aclImdb/train/unsup/46806_0.txt\n",
            "aclImdb/train/unsup/46805_0.txt\n",
            "aclImdb/train/unsup/46804_0.txt\n",
            "aclImdb/train/unsup/46803_0.txt\n",
            "aclImdb/train/unsup/46802_0.txt\n",
            "aclImdb/train/unsup/46801_0.txt\n",
            "aclImdb/train/unsup/46800_0.txt\n",
            "aclImdb/train/unsup/46799_0.txt\n",
            "aclImdb/train/unsup/46798_0.txt\n",
            "aclImdb/train/unsup/46797_0.txt\n",
            "aclImdb/train/unsup/46796_0.txt\n",
            "aclImdb/train/unsup/46795_0.txt\n",
            "aclImdb/train/unsup/46794_0.txt\n",
            "aclImdb/train/unsup/46793_0.txt\n",
            "aclImdb/train/unsup/46792_0.txt\n",
            "aclImdb/train/unsup/46791_0.txt\n",
            "aclImdb/train/unsup/46790_0.txt\n",
            "aclImdb/train/unsup/46789_0.txt\n",
            "aclImdb/train/unsup/46788_0.txt\n",
            "aclImdb/train/unsup/46787_0.txt\n",
            "aclImdb/train/unsup/46786_0.txt\n",
            "aclImdb/train/unsup/46785_0.txt\n",
            "aclImdb/train/unsup/46784_0.txt\n",
            "aclImdb/train/unsup/46783_0.txt\n",
            "aclImdb/train/unsup/46782_0.txt\n",
            "aclImdb/train/unsup/46781_0.txt\n",
            "aclImdb/train/unsup/46780_0.txt\n",
            "aclImdb/train/unsup/46779_0.txt\n",
            "aclImdb/train/unsup/46778_0.txt\n",
            "aclImdb/train/unsup/46777_0.txt\n",
            "aclImdb/train/unsup/46776_0.txt\n",
            "aclImdb/train/unsup/46775_0.txt\n",
            "aclImdb/train/unsup/46774_0.txt\n",
            "aclImdb/train/unsup/46773_0.txt\n",
            "aclImdb/train/unsup/46772_0.txt\n",
            "aclImdb/train/unsup/46771_0.txt\n",
            "aclImdb/train/unsup/46770_0.txt\n",
            "aclImdb/train/unsup/46769_0.txt\n",
            "aclImdb/train/unsup/46768_0.txt\n",
            "aclImdb/train/unsup/46767_0.txt\n",
            "aclImdb/train/unsup/46766_0.txt\n",
            "aclImdb/train/unsup/46765_0.txt\n",
            "aclImdb/train/unsup/46764_0.txt\n",
            "aclImdb/train/unsup/46763_0.txt\n",
            "aclImdb/train/unsup/46762_0.txt\n",
            "aclImdb/train/unsup/46761_0.txt\n",
            "aclImdb/train/unsup/46760_0.txt\n",
            "aclImdb/train/unsup/46759_0.txt\n",
            "aclImdb/train/unsup/46758_0.txt\n",
            "aclImdb/train/unsup/46757_0.txt\n",
            "aclImdb/train/unsup/46756_0.txt\n",
            "aclImdb/train/unsup/46755_0.txt\n",
            "aclImdb/train/unsup/46754_0.txt\n",
            "aclImdb/train/unsup/46753_0.txt\n",
            "aclImdb/train/unsup/46752_0.txt\n",
            "aclImdb/train/unsup/46751_0.txt\n",
            "aclImdb/train/unsup/46750_0.txt\n",
            "aclImdb/train/unsup/46749_0.txt\n",
            "aclImdb/train/unsup/46748_0.txt\n",
            "aclImdb/train/unsup/46747_0.txt\n",
            "aclImdb/train/unsup/46746_0.txt\n",
            "aclImdb/train/unsup/46745_0.txt\n",
            "aclImdb/train/unsup/46744_0.txt\n",
            "aclImdb/train/unsup/46743_0.txt\n",
            "aclImdb/train/unsup/46742_0.txt\n",
            "aclImdb/train/unsup/46741_0.txt\n",
            "aclImdb/train/unsup/46740_0.txt\n",
            "aclImdb/train/unsup/46739_0.txt\n",
            "aclImdb/train/unsup/46738_0.txt\n",
            "aclImdb/train/unsup/46737_0.txt\n",
            "aclImdb/train/unsup/46736_0.txt\n",
            "aclImdb/train/unsup/46735_0.txt\n",
            "aclImdb/train/unsup/46734_0.txt\n",
            "aclImdb/train/unsup/46733_0.txt\n",
            "aclImdb/train/unsup/46732_0.txt\n",
            "aclImdb/train/unsup/46731_0.txt\n",
            "aclImdb/train/unsup/46730_0.txt\n",
            "aclImdb/train/unsup/46729_0.txt\n",
            "aclImdb/train/unsup/46728_0.txt\n",
            "aclImdb/train/unsup/46727_0.txt\n",
            "aclImdb/train/unsup/46726_0.txt\n",
            "aclImdb/train/unsup/46725_0.txt\n",
            "aclImdb/train/unsup/46724_0.txt\n",
            "aclImdb/train/unsup/46723_0.txt\n",
            "aclImdb/train/unsup/46722_0.txt\n",
            "aclImdb/train/unsup/46721_0.txt\n",
            "aclImdb/train/unsup/46720_0.txt\n",
            "aclImdb/train/unsup/46975_0.txt\n",
            "aclImdb/train/unsup/46974_0.txt\n",
            "aclImdb/train/unsup/46973_0.txt\n",
            "aclImdb/train/unsup/46972_0.txt\n",
            "aclImdb/train/unsup/46971_0.txt\n",
            "aclImdb/train/unsup/46970_0.txt\n",
            "aclImdb/train/unsup/46969_0.txt\n",
            "aclImdb/train/unsup/46968_0.txt\n",
            "aclImdb/train/unsup/46967_0.txt\n",
            "aclImdb/train/unsup/46966_0.txt\n",
            "aclImdb/train/unsup/46965_0.txt\n",
            "aclImdb/train/unsup/46964_0.txt\n",
            "aclImdb/train/unsup/46963_0.txt\n",
            "aclImdb/train/unsup/46962_0.txt\n",
            "aclImdb/train/unsup/46961_0.txt\n",
            "aclImdb/train/unsup/46960_0.txt\n",
            "aclImdb/train/unsup/46959_0.txt\n",
            "aclImdb/train/unsup/46958_0.txt\n",
            "aclImdb/train/unsup/46957_0.txt\n",
            "aclImdb/train/unsup/46956_0.txt\n",
            "aclImdb/train/unsup/46955_0.txt\n",
            "aclImdb/train/unsup/46954_0.txt\n",
            "aclImdb/train/unsup/46953_0.txt\n",
            "aclImdb/train/unsup/46952_0.txt\n",
            "aclImdb/train/unsup/46951_0.txt\n",
            "aclImdb/train/unsup/46950_0.txt\n",
            "aclImdb/train/unsup/46949_0.txt\n",
            "aclImdb/train/unsup/46948_0.txt\n",
            "aclImdb/train/unsup/46947_0.txt\n",
            "aclImdb/train/unsup/46946_0.txt\n",
            "aclImdb/train/unsup/46945_0.txt\n",
            "aclImdb/train/unsup/46944_0.txt\n",
            "aclImdb/train/unsup/46943_0.txt\n",
            "aclImdb/train/unsup/46942_0.txt\n",
            "aclImdb/train/unsup/46941_0.txt\n",
            "aclImdb/train/unsup/46940_0.txt\n",
            "aclImdb/train/unsup/46939_0.txt\n",
            "aclImdb/train/unsup/46938_0.txt\n",
            "aclImdb/train/unsup/46937_0.txt\n",
            "aclImdb/train/unsup/46936_0.txt\n",
            "aclImdb/train/unsup/46935_0.txt\n",
            "aclImdb/train/unsup/46934_0.txt\n",
            "aclImdb/train/unsup/46933_0.txt\n",
            "aclImdb/train/unsup/46932_0.txt\n",
            "aclImdb/train/unsup/46931_0.txt\n",
            "aclImdb/train/unsup/46930_0.txt\n",
            "aclImdb/train/unsup/46929_0.txt\n",
            "aclImdb/train/unsup/46928_0.txt\n",
            "aclImdb/train/unsup/46927_0.txt\n",
            "aclImdb/train/unsup/46926_0.txt\n",
            "aclImdb/train/unsup/46925_0.txt\n",
            "aclImdb/train/unsup/46924_0.txt\n",
            "aclImdb/train/unsup/46923_0.txt\n",
            "aclImdb/train/unsup/46922_0.txt\n",
            "aclImdb/train/unsup/46921_0.txt\n",
            "aclImdb/train/unsup/46920_0.txt\n",
            "aclImdb/train/unsup/46919_0.txt\n",
            "aclImdb/train/unsup/46918_0.txt\n",
            "aclImdb/train/unsup/46917_0.txt\n",
            "aclImdb/train/unsup/46916_0.txt\n",
            "aclImdb/train/unsup/46915_0.txt\n",
            "aclImdb/train/unsup/46914_0.txt\n",
            "aclImdb/train/unsup/46913_0.txt\n",
            "aclImdb/train/unsup/46912_0.txt\n",
            "aclImdb/train/unsup/46911_0.txt\n",
            "aclImdb/train/unsup/46910_0.txt\n",
            "aclImdb/train/unsup/46909_0.txt\n",
            "aclImdb/train/unsup/46908_0.txt\n",
            "aclImdb/train/unsup/46907_0.txt\n",
            "aclImdb/train/unsup/46906_0.txt\n",
            "aclImdb/train/unsup/46905_0.txt\n",
            "aclImdb/train/unsup/46904_0.txt\n",
            "aclImdb/train/unsup/46903_0.txt\n",
            "aclImdb/train/unsup/46902_0.txt\n",
            "aclImdb/train/unsup/46901_0.txt\n",
            "aclImdb/train/unsup/46900_0.txt\n",
            "aclImdb/train/unsup/46899_0.txt\n",
            "aclImdb/train/unsup/46898_0.txt\n",
            "aclImdb/train/unsup/46897_0.txt\n",
            "aclImdb/train/unsup/46896_0.txt\n",
            "aclImdb/train/unsup/46895_0.txt\n",
            "aclImdb/train/unsup/46894_0.txt\n",
            "aclImdb/train/unsup/46893_0.txt\n",
            "aclImdb/train/unsup/46892_0.txt\n",
            "aclImdb/train/unsup/46891_0.txt\n",
            "aclImdb/train/unsup/46890_0.txt\n",
            "aclImdb/train/unsup/46889_0.txt\n",
            "aclImdb/train/unsup/46888_0.txt\n",
            "aclImdb/train/unsup/46887_0.txt\n",
            "aclImdb/train/unsup/46886_0.txt\n",
            "aclImdb/train/unsup/46885_0.txt\n",
            "aclImdb/train/unsup/46884_0.txt\n",
            "aclImdb/train/unsup/46883_0.txt\n",
            "aclImdb/train/unsup/46882_0.txt\n",
            "aclImdb/train/unsup/46881_0.txt\n",
            "aclImdb/train/unsup/46880_0.txt\n",
            "aclImdb/train/unsup/46879_0.txt\n",
            "aclImdb/train/unsup/46878_0.txt\n",
            "aclImdb/train/unsup/46877_0.txt\n",
            "aclImdb/train/unsup/46876_0.txt\n",
            "aclImdb/train/unsup/46875_0.txt\n",
            "aclImdb/train/unsup/46874_0.txt\n",
            "aclImdb/train/unsup/46873_0.txt\n",
            "aclImdb/train/unsup/46872_0.txt\n",
            "aclImdb/train/unsup/46871_0.txt\n",
            "aclImdb/train/unsup/46870_0.txt\n",
            "aclImdb/train/unsup/46869_0.txt\n",
            "aclImdb/train/unsup/46868_0.txt\n",
            "aclImdb/train/unsup/46867_0.txt\n",
            "aclImdb/train/unsup/46866_0.txt\n",
            "aclImdb/train/unsup/46865_0.txt\n",
            "aclImdb/train/unsup/46864_0.txt\n",
            "aclImdb/train/unsup/46863_0.txt\n",
            "aclImdb/train/unsup/46862_0.txt\n",
            "aclImdb/train/unsup/46861_0.txt\n",
            "aclImdb/train/unsup/46860_0.txt\n",
            "aclImdb/train/unsup/46859_0.txt\n",
            "aclImdb/train/unsup/46858_0.txt\n",
            "aclImdb/train/unsup/46857_0.txt\n",
            "aclImdb/train/unsup/46856_0.txt\n",
            "aclImdb/train/unsup/46855_0.txt\n",
            "aclImdb/train/unsup/46854_0.txt\n",
            "aclImdb/train/unsup/46853_0.txt\n",
            "aclImdb/train/unsup/46852_0.txt\n",
            "aclImdb/train/unsup/46851_0.txt\n",
            "aclImdb/train/unsup/46850_0.txt\n",
            "aclImdb/train/unsup/46849_0.txt\n",
            "aclImdb/train/unsup/46848_0.txt\n",
            "aclImdb/train/unsup/47103_0.txt\n",
            "aclImdb/train/unsup/47102_0.txt\n",
            "aclImdb/train/unsup/47101_0.txt\n",
            "aclImdb/train/unsup/47100_0.txt\n",
            "aclImdb/train/unsup/47099_0.txt\n",
            "aclImdb/train/unsup/47098_0.txt\n",
            "aclImdb/train/unsup/47097_0.txt\n",
            "aclImdb/train/unsup/47096_0.txt\n",
            "aclImdb/train/unsup/47095_0.txt\n",
            "aclImdb/train/unsup/47094_0.txt\n",
            "aclImdb/train/unsup/47093_0.txt\n",
            "aclImdb/train/unsup/47092_0.txt\n",
            "aclImdb/train/unsup/47091_0.txt\n",
            "aclImdb/train/unsup/47090_0.txt\n",
            "aclImdb/train/unsup/47089_0.txt\n",
            "aclImdb/train/unsup/47088_0.txt\n",
            "aclImdb/train/unsup/47087_0.txt\n",
            "aclImdb/train/unsup/47086_0.txt\n",
            "aclImdb/train/unsup/47085_0.txt\n",
            "aclImdb/train/unsup/47084_0.txt\n",
            "aclImdb/train/unsup/47083_0.txt\n",
            "aclImdb/train/unsup/47082_0.txt\n",
            "aclImdb/train/unsup/47081_0.txt\n",
            "aclImdb/train/unsup/47080_0.txt\n",
            "aclImdb/train/unsup/47079_0.txt\n",
            "aclImdb/train/unsup/47078_0.txt\n",
            "aclImdb/train/unsup/47077_0.txt\n",
            "aclImdb/train/unsup/47076_0.txt\n",
            "aclImdb/train/unsup/47075_0.txt\n",
            "aclImdb/train/unsup/47074_0.txt\n",
            "aclImdb/train/unsup/47073_0.txt\n",
            "aclImdb/train/unsup/47072_0.txt\n",
            "aclImdb/train/unsup/47071_0.txt\n",
            "aclImdb/train/unsup/47070_0.txt\n",
            "aclImdb/train/unsup/47069_0.txt\n",
            "aclImdb/train/unsup/47068_0.txt\n",
            "aclImdb/train/unsup/47067_0.txt\n",
            "aclImdb/train/unsup/47066_0.txt\n",
            "aclImdb/train/unsup/47065_0.txt\n",
            "aclImdb/train/unsup/47064_0.txt\n",
            "aclImdb/train/unsup/47063_0.txt\n",
            "aclImdb/train/unsup/47062_0.txt\n",
            "aclImdb/train/unsup/47061_0.txt\n",
            "aclImdb/train/unsup/47060_0.txt\n",
            "aclImdb/train/unsup/47059_0.txt\n",
            "aclImdb/train/unsup/47058_0.txt\n",
            "aclImdb/train/unsup/47057_0.txt\n",
            "aclImdb/train/unsup/47056_0.txt\n",
            "aclImdb/train/unsup/47055_0.txt\n",
            "aclImdb/train/unsup/47054_0.txt\n",
            "aclImdb/train/unsup/47053_0.txt\n",
            "aclImdb/train/unsup/47052_0.txt\n",
            "aclImdb/train/unsup/47051_0.txt\n",
            "aclImdb/train/unsup/47050_0.txt\n",
            "aclImdb/train/unsup/47049_0.txt\n",
            "aclImdb/train/unsup/47048_0.txt\n",
            "aclImdb/train/unsup/47047_0.txt\n",
            "aclImdb/train/unsup/47046_0.txt\n",
            "aclImdb/train/unsup/47045_0.txt\n",
            "aclImdb/train/unsup/47044_0.txt\n",
            "aclImdb/train/unsup/47043_0.txt\n",
            "aclImdb/train/unsup/47042_0.txt\n",
            "aclImdb/train/unsup/47041_0.txt\n",
            "aclImdb/train/unsup/47040_0.txt\n",
            "aclImdb/train/unsup/47039_0.txt\n",
            "aclImdb/train/unsup/47038_0.txt\n",
            "aclImdb/train/unsup/47037_0.txt\n",
            "aclImdb/train/unsup/47036_0.txt\n",
            "aclImdb/train/unsup/47035_0.txt\n",
            "aclImdb/train/unsup/47034_0.txt\n",
            "aclImdb/train/unsup/47033_0.txt\n",
            "aclImdb/train/unsup/47032_0.txt\n",
            "aclImdb/train/unsup/47031_0.txt\n",
            "aclImdb/train/unsup/47030_0.txt\n",
            "aclImdb/train/unsup/47029_0.txt\n",
            "aclImdb/train/unsup/47028_0.txt\n",
            "aclImdb/train/unsup/47027_0.txt\n",
            "aclImdb/train/unsup/47026_0.txt\n",
            "aclImdb/train/unsup/47025_0.txt\n",
            "aclImdb/train/unsup/47024_0.txt\n",
            "aclImdb/train/unsup/47023_0.txt\n",
            "aclImdb/train/unsup/47022_0.txt\n",
            "aclImdb/train/unsup/47021_0.txt\n",
            "aclImdb/train/unsup/47020_0.txt\n",
            "aclImdb/train/unsup/47019_0.txt\n",
            "aclImdb/train/unsup/47018_0.txt\n",
            "aclImdb/train/unsup/47017_0.txt\n",
            "aclImdb/train/unsup/47016_0.txt\n",
            "aclImdb/train/unsup/47015_0.txt\n",
            "aclImdb/train/unsup/47014_0.txt\n",
            "aclImdb/train/unsup/47013_0.txt\n",
            "aclImdb/train/unsup/47012_0.txt\n",
            "aclImdb/train/unsup/47011_0.txt\n",
            "aclImdb/train/unsup/47010_0.txt\n",
            "aclImdb/train/unsup/47009_0.txt\n",
            "aclImdb/train/unsup/47008_0.txt\n",
            "aclImdb/train/unsup/47007_0.txt\n",
            "aclImdb/train/unsup/47006_0.txt\n",
            "aclImdb/train/unsup/47005_0.txt\n",
            "aclImdb/train/unsup/47004_0.txt\n",
            "aclImdb/train/unsup/47003_0.txt\n",
            "aclImdb/train/unsup/47002_0.txt\n",
            "aclImdb/train/unsup/47001_0.txt\n",
            "aclImdb/train/unsup/47000_0.txt\n",
            "aclImdb/train/unsup/46999_0.txt\n",
            "aclImdb/train/unsup/46998_0.txt\n",
            "aclImdb/train/unsup/46997_0.txt\n",
            "aclImdb/train/unsup/46996_0.txt\n",
            "aclImdb/train/unsup/46995_0.txt\n",
            "aclImdb/train/unsup/46994_0.txt\n",
            "aclImdb/train/unsup/46993_0.txt\n",
            "aclImdb/train/unsup/46992_0.txt\n",
            "aclImdb/train/unsup/46991_0.txt\n",
            "aclImdb/train/unsup/46990_0.txt\n",
            "aclImdb/train/unsup/46989_0.txt\n",
            "aclImdb/train/unsup/46988_0.txt\n",
            "aclImdb/train/unsup/46987_0.txt\n",
            "aclImdb/train/unsup/46986_0.txt\n",
            "aclImdb/train/unsup/46985_0.txt\n",
            "aclImdb/train/unsup/46984_0.txt\n",
            "aclImdb/train/unsup/46983_0.txt\n",
            "aclImdb/train/unsup/46982_0.txt\n",
            "aclImdb/train/unsup/46981_0.txt\n",
            "aclImdb/train/unsup/46980_0.txt\n",
            "aclImdb/train/unsup/46979_0.txt\n",
            "aclImdb/train/unsup/46978_0.txt\n",
            "aclImdb/train/unsup/46977_0.txt\n",
            "aclImdb/train/unsup/46976_0.txt\n",
            "aclImdb/train/unsup/47231_0.txt\n",
            "aclImdb/train/unsup/47230_0.txt\n",
            "aclImdb/train/unsup/47229_0.txt\n",
            "aclImdb/train/unsup/47228_0.txt\n",
            "aclImdb/train/unsup/47227_0.txt\n",
            "aclImdb/train/unsup/47226_0.txt\n",
            "aclImdb/train/unsup/47225_0.txt\n",
            "aclImdb/train/unsup/47224_0.txt\n",
            "aclImdb/train/unsup/47223_0.txt\n",
            "aclImdb/train/unsup/47222_0.txt\n",
            "aclImdb/train/unsup/47221_0.txt\n",
            "aclImdb/train/unsup/47220_0.txt\n",
            "aclImdb/train/unsup/47219_0.txt\n",
            "aclImdb/train/unsup/47218_0.txt\n",
            "aclImdb/train/unsup/47217_0.txt\n",
            "aclImdb/train/unsup/47216_0.txt\n",
            "aclImdb/train/unsup/47215_0.txt\n",
            "aclImdb/train/unsup/47214_0.txt\n",
            "aclImdb/train/unsup/47213_0.txt\n",
            "aclImdb/train/unsup/47212_0.txt\n",
            "aclImdb/train/unsup/47211_0.txt\n",
            "aclImdb/train/unsup/47210_0.txt\n",
            "aclImdb/train/unsup/47209_0.txt\n",
            "aclImdb/train/unsup/47208_0.txt\n",
            "aclImdb/train/unsup/47207_0.txt\n",
            "aclImdb/train/unsup/47206_0.txt\n",
            "aclImdb/train/unsup/47205_0.txt\n",
            "aclImdb/train/unsup/47204_0.txt\n",
            "aclImdb/train/unsup/47203_0.txt\n",
            "aclImdb/train/unsup/47202_0.txt\n",
            "aclImdb/train/unsup/47201_0.txt\n",
            "aclImdb/train/unsup/47200_0.txt\n",
            "aclImdb/train/unsup/47199_0.txt\n",
            "aclImdb/train/unsup/47198_0.txt\n",
            "aclImdb/train/unsup/47197_0.txt\n",
            "aclImdb/train/unsup/47196_0.txt\n",
            "aclImdb/train/unsup/47195_0.txt\n",
            "aclImdb/train/unsup/47194_0.txt\n",
            "aclImdb/train/unsup/47193_0.txt\n",
            "aclImdb/train/unsup/47192_0.txt\n",
            "aclImdb/train/unsup/47191_0.txt\n",
            "aclImdb/train/unsup/47190_0.txt\n",
            "aclImdb/train/unsup/47189_0.txt\n",
            "aclImdb/train/unsup/47188_0.txt\n",
            "aclImdb/train/unsup/47187_0.txt\n",
            "aclImdb/train/unsup/47186_0.txt\n",
            "aclImdb/train/unsup/47185_0.txt\n",
            "aclImdb/train/unsup/47184_0.txt\n",
            "aclImdb/train/unsup/47183_0.txt\n",
            "aclImdb/train/unsup/47182_0.txt\n",
            "aclImdb/train/unsup/47181_0.txt\n",
            "aclImdb/train/unsup/47180_0.txt\n",
            "aclImdb/train/unsup/47179_0.txt\n",
            "aclImdb/train/unsup/47178_0.txt\n",
            "aclImdb/train/unsup/47177_0.txt\n",
            "aclImdb/train/unsup/47176_0.txt\n",
            "aclImdb/train/unsup/47175_0.txt\n",
            "aclImdb/train/unsup/47174_0.txt\n",
            "aclImdb/train/unsup/47173_0.txt\n",
            "aclImdb/train/unsup/47172_0.txt\n",
            "aclImdb/train/unsup/47171_0.txt\n",
            "aclImdb/train/unsup/47170_0.txt\n",
            "aclImdb/train/unsup/47169_0.txt\n",
            "aclImdb/train/unsup/47168_0.txt\n",
            "aclImdb/train/unsup/47167_0.txt\n",
            "aclImdb/train/unsup/47166_0.txt\n",
            "aclImdb/train/unsup/47165_0.txt\n",
            "aclImdb/train/unsup/47164_0.txt\n",
            "aclImdb/train/unsup/47163_0.txt\n",
            "aclImdb/train/unsup/47162_0.txt\n",
            "aclImdb/train/unsup/47161_0.txt\n",
            "aclImdb/train/unsup/47160_0.txt\n",
            "aclImdb/train/unsup/47159_0.txt\n",
            "aclImdb/train/unsup/47158_0.txt\n",
            "aclImdb/train/unsup/47157_0.txt\n",
            "aclImdb/train/unsup/47156_0.txt\n",
            "aclImdb/train/unsup/47155_0.txt\n",
            "aclImdb/train/unsup/47154_0.txt\n",
            "aclImdb/train/unsup/47153_0.txt\n",
            "aclImdb/train/unsup/47152_0.txt\n",
            "aclImdb/train/unsup/47151_0.txt\n",
            "aclImdb/train/unsup/47150_0.txt\n",
            "aclImdb/train/unsup/47149_0.txt\n",
            "aclImdb/train/unsup/47148_0.txt\n",
            "aclImdb/train/unsup/47147_0.txt\n",
            "aclImdb/train/unsup/47146_0.txt\n",
            "aclImdb/train/unsup/47145_0.txt\n",
            "aclImdb/train/unsup/47144_0.txt\n",
            "aclImdb/train/unsup/47143_0.txt\n",
            "aclImdb/train/unsup/47142_0.txt\n",
            "aclImdb/train/unsup/47141_0.txt\n",
            "aclImdb/train/unsup/47140_0.txt\n",
            "aclImdb/train/unsup/47139_0.txt\n",
            "aclImdb/train/unsup/47138_0.txt\n",
            "aclImdb/train/unsup/47137_0.txt\n",
            "aclImdb/train/unsup/47136_0.txt\n",
            "aclImdb/train/unsup/47135_0.txt\n",
            "aclImdb/train/unsup/47134_0.txt\n",
            "aclImdb/train/unsup/47133_0.txt\n",
            "aclImdb/train/unsup/47132_0.txt\n",
            "aclImdb/train/unsup/47131_0.txt\n",
            "aclImdb/train/unsup/47130_0.txt\n",
            "aclImdb/train/unsup/47129_0.txt\n",
            "aclImdb/train/unsup/47128_0.txt\n",
            "aclImdb/train/unsup/47127_0.txt\n",
            "aclImdb/train/unsup/47126_0.txt\n",
            "aclImdb/train/unsup/47125_0.txt\n",
            "aclImdb/train/unsup/47124_0.txt\n",
            "aclImdb/train/unsup/47123_0.txt\n",
            "aclImdb/train/unsup/47122_0.txt\n",
            "aclImdb/train/unsup/47121_0.txt\n",
            "aclImdb/train/unsup/47120_0.txt\n",
            "aclImdb/train/unsup/47119_0.txt\n",
            "aclImdb/train/unsup/47118_0.txt\n",
            "aclImdb/train/unsup/47117_0.txt\n",
            "aclImdb/train/unsup/47116_0.txt\n",
            "aclImdb/train/unsup/47115_0.txt\n",
            "aclImdb/train/unsup/47114_0.txt\n",
            "aclImdb/train/unsup/47113_0.txt\n",
            "aclImdb/train/unsup/47112_0.txt\n",
            "aclImdb/train/unsup/47111_0.txt\n",
            "aclImdb/train/unsup/47110_0.txt\n",
            "aclImdb/train/unsup/47109_0.txt\n",
            "aclImdb/train/unsup/47108_0.txt\n",
            "aclImdb/train/unsup/47107_0.txt\n",
            "aclImdb/train/unsup/47106_0.txt\n",
            "aclImdb/train/unsup/47105_0.txt\n",
            "aclImdb/train/unsup/47104_0.txt\n",
            "aclImdb/train/unsup/47359_0.txt\n",
            "aclImdb/train/unsup/47358_0.txt\n",
            "aclImdb/train/unsup/47357_0.txt\n",
            "aclImdb/train/unsup/47356_0.txt\n",
            "aclImdb/train/unsup/47355_0.txt\n",
            "aclImdb/train/unsup/47354_0.txt\n",
            "aclImdb/train/unsup/47353_0.txt\n",
            "aclImdb/train/unsup/47352_0.txt\n",
            "aclImdb/train/unsup/47351_0.txt\n",
            "aclImdb/train/unsup/47350_0.txt\n",
            "aclImdb/train/unsup/47349_0.txt\n",
            "aclImdb/train/unsup/47348_0.txt\n",
            "aclImdb/train/unsup/47347_0.txt\n",
            "aclImdb/train/unsup/47346_0.txt\n",
            "aclImdb/train/unsup/47345_0.txt\n",
            "aclImdb/train/unsup/47344_0.txt\n",
            "aclImdb/train/unsup/47343_0.txt\n",
            "aclImdb/train/unsup/47342_0.txt\n",
            "aclImdb/train/unsup/47341_0.txt\n",
            "aclImdb/train/unsup/47340_0.txt\n",
            "aclImdb/train/unsup/47339_0.txt\n",
            "aclImdb/train/unsup/47338_0.txt\n",
            "aclImdb/train/unsup/47337_0.txt\n",
            "aclImdb/train/unsup/47336_0.txt\n",
            "aclImdb/train/unsup/47335_0.txt\n",
            "aclImdb/train/unsup/47334_0.txt\n",
            "aclImdb/train/unsup/47333_0.txt\n",
            "aclImdb/train/unsup/47332_0.txt\n",
            "aclImdb/train/unsup/47331_0.txt\n",
            "aclImdb/train/unsup/47330_0.txt\n",
            "aclImdb/train/unsup/47329_0.txt\n",
            "aclImdb/train/unsup/47328_0.txt\n",
            "aclImdb/train/unsup/47327_0.txt\n",
            "aclImdb/train/unsup/47326_0.txt\n",
            "aclImdb/train/unsup/47325_0.txt\n",
            "aclImdb/train/unsup/47324_0.txt\n",
            "aclImdb/train/unsup/47323_0.txt\n",
            "aclImdb/train/unsup/47322_0.txt\n",
            "aclImdb/train/unsup/47321_0.txt\n",
            "aclImdb/train/unsup/47320_0.txt\n",
            "aclImdb/train/unsup/47319_0.txt\n",
            "aclImdb/train/unsup/47318_0.txt\n",
            "aclImdb/train/unsup/47317_0.txt\n",
            "aclImdb/train/unsup/47316_0.txt\n",
            "aclImdb/train/unsup/47315_0.txt\n",
            "aclImdb/train/unsup/47314_0.txt\n",
            "aclImdb/train/unsup/47313_0.txt\n",
            "aclImdb/train/unsup/47312_0.txt\n",
            "aclImdb/train/unsup/47311_0.txt\n",
            "aclImdb/train/unsup/47310_0.txt\n",
            "aclImdb/train/unsup/47309_0.txt\n",
            "aclImdb/train/unsup/47308_0.txt\n",
            "aclImdb/train/unsup/47307_0.txt\n",
            "aclImdb/train/unsup/47306_0.txt\n",
            "aclImdb/train/unsup/47305_0.txt\n",
            "aclImdb/train/unsup/47304_0.txt\n",
            "aclImdb/train/unsup/47303_0.txt\n",
            "aclImdb/train/unsup/47302_0.txt\n",
            "aclImdb/train/unsup/47301_0.txt\n",
            "aclImdb/train/unsup/47300_0.txt\n",
            "aclImdb/train/unsup/47299_0.txt\n",
            "aclImdb/train/unsup/47298_0.txt\n",
            "aclImdb/train/unsup/47297_0.txt\n",
            "aclImdb/train/unsup/47296_0.txt\n",
            "aclImdb/train/unsup/47295_0.txt\n",
            "aclImdb/train/unsup/47294_0.txt\n",
            "aclImdb/train/unsup/47293_0.txt\n",
            "aclImdb/train/unsup/47292_0.txt\n",
            "aclImdb/train/unsup/47291_0.txt\n",
            "aclImdb/train/unsup/47290_0.txt\n",
            "aclImdb/train/unsup/47289_0.txt\n",
            "aclImdb/train/unsup/47288_0.txt\n",
            "aclImdb/train/unsup/47287_0.txt\n",
            "aclImdb/train/unsup/47286_0.txt\n",
            "aclImdb/train/unsup/47285_0.txt\n",
            "aclImdb/train/unsup/47284_0.txt\n",
            "aclImdb/train/unsup/47283_0.txt\n",
            "aclImdb/train/unsup/47282_0.txt\n",
            "aclImdb/train/unsup/47281_0.txt\n",
            "aclImdb/train/unsup/47280_0.txt\n",
            "aclImdb/train/unsup/47279_0.txt\n",
            "aclImdb/train/unsup/47278_0.txt\n",
            "aclImdb/train/unsup/47277_0.txt\n",
            "aclImdb/train/unsup/47276_0.txt\n",
            "aclImdb/train/unsup/47275_0.txt\n",
            "aclImdb/train/unsup/47274_0.txt\n",
            "aclImdb/train/unsup/47273_0.txt\n",
            "aclImdb/train/unsup/47272_0.txt\n",
            "aclImdb/train/unsup/47271_0.txt\n",
            "aclImdb/train/unsup/47270_0.txt\n",
            "aclImdb/train/unsup/47269_0.txt\n",
            "aclImdb/train/unsup/47268_0.txt\n",
            "aclImdb/train/unsup/47267_0.txt\n",
            "aclImdb/train/unsup/47266_0.txt\n",
            "aclImdb/train/unsup/47265_0.txt\n",
            "aclImdb/train/unsup/47264_0.txt\n",
            "aclImdb/train/unsup/47263_0.txt\n",
            "aclImdb/train/unsup/47262_0.txt\n",
            "aclImdb/train/unsup/47261_0.txt\n",
            "aclImdb/train/unsup/47260_0.txt\n",
            "aclImdb/train/unsup/47259_0.txt\n",
            "aclImdb/train/unsup/47258_0.txt\n",
            "aclImdb/train/unsup/47257_0.txt\n",
            "aclImdb/train/unsup/47256_0.txt\n",
            "aclImdb/train/unsup/47255_0.txt\n",
            "aclImdb/train/unsup/47254_0.txt\n",
            "aclImdb/train/unsup/47253_0.txt\n",
            "aclImdb/train/unsup/47252_0.txt\n",
            "aclImdb/train/unsup/47251_0.txt\n",
            "aclImdb/train/unsup/47250_0.txt\n",
            "aclImdb/train/unsup/47249_0.txt\n",
            "aclImdb/train/unsup/47248_0.txt\n",
            "aclImdb/train/unsup/47247_0.txt\n",
            "aclImdb/train/unsup/47246_0.txt\n",
            "aclImdb/train/unsup/47245_0.txt\n",
            "aclImdb/train/unsup/47244_0.txt\n",
            "aclImdb/train/unsup/47243_0.txt\n",
            "aclImdb/train/unsup/47242_0.txt\n",
            "aclImdb/train/unsup/47241_0.txt\n",
            "aclImdb/train/unsup/47240_0.txt\n",
            "aclImdb/train/unsup/47239_0.txt\n",
            "aclImdb/train/unsup/47238_0.txt\n",
            "aclImdb/train/unsup/47237_0.txt\n",
            "aclImdb/train/unsup/47236_0.txt\n",
            "aclImdb/train/unsup/47235_0.txt\n",
            "aclImdb/train/unsup/47234_0.txt\n",
            "aclImdb/train/unsup/47233_0.txt\n",
            "aclImdb/train/unsup/47232_0.txt\n",
            "aclImdb/train/unsup/47487_0.txt\n",
            "aclImdb/train/unsup/47486_0.txt\n",
            "aclImdb/train/unsup/47485_0.txt\n",
            "aclImdb/train/unsup/47484_0.txt\n",
            "aclImdb/train/unsup/47483_0.txt\n",
            "aclImdb/train/unsup/47482_0.txt\n",
            "aclImdb/train/unsup/47481_0.txt\n",
            "aclImdb/train/unsup/47480_0.txt\n",
            "aclImdb/train/unsup/47479_0.txt\n",
            "aclImdb/train/unsup/47478_0.txt\n",
            "aclImdb/train/unsup/47477_0.txt\n",
            "aclImdb/train/unsup/47476_0.txt\n",
            "aclImdb/train/unsup/47475_0.txt\n",
            "aclImdb/train/unsup/47474_0.txt\n",
            "aclImdb/train/unsup/47473_0.txt\n",
            "aclImdb/train/unsup/47472_0.txt\n",
            "aclImdb/train/unsup/47471_0.txt\n",
            "aclImdb/train/unsup/47470_0.txt\n",
            "aclImdb/train/unsup/47469_0.txt\n",
            "aclImdb/train/unsup/47468_0.txt\n",
            "aclImdb/train/unsup/47467_0.txt\n",
            "aclImdb/train/unsup/47466_0.txt\n",
            "aclImdb/train/unsup/47465_0.txt\n",
            "aclImdb/train/unsup/47464_0.txt\n",
            "aclImdb/train/unsup/47463_0.txt\n",
            "aclImdb/train/unsup/47462_0.txt\n",
            "aclImdb/train/unsup/47461_0.txt\n",
            "aclImdb/train/unsup/47460_0.txt\n",
            "aclImdb/train/unsup/47459_0.txt\n",
            "aclImdb/train/unsup/47458_0.txt\n",
            "aclImdb/train/unsup/47457_0.txt\n",
            "aclImdb/train/unsup/47456_0.txt\n",
            "aclImdb/train/unsup/47455_0.txt\n",
            "aclImdb/train/unsup/47454_0.txt\n",
            "aclImdb/train/unsup/47453_0.txt\n",
            "aclImdb/train/unsup/47452_0.txt\n",
            "aclImdb/train/unsup/47451_0.txt\n",
            "aclImdb/train/unsup/47450_0.txt\n",
            "aclImdb/train/unsup/47449_0.txt\n",
            "aclImdb/train/unsup/47448_0.txt\n",
            "aclImdb/train/unsup/47447_0.txt\n",
            "aclImdb/train/unsup/47446_0.txt\n",
            "aclImdb/train/unsup/47445_0.txt\n",
            "aclImdb/train/unsup/47444_0.txt\n",
            "aclImdb/train/unsup/47443_0.txt\n",
            "aclImdb/train/unsup/47442_0.txt\n",
            "aclImdb/train/unsup/47441_0.txt\n",
            "aclImdb/train/unsup/47440_0.txt\n",
            "aclImdb/train/unsup/47439_0.txt\n",
            "aclImdb/train/unsup/47438_0.txt\n",
            "aclImdb/train/unsup/47437_0.txt\n",
            "aclImdb/train/unsup/47436_0.txt\n",
            "aclImdb/train/unsup/47435_0.txt\n",
            "aclImdb/train/unsup/47434_0.txt\n",
            "aclImdb/train/unsup/47433_0.txt\n",
            "aclImdb/train/unsup/47432_0.txt\n",
            "aclImdb/train/unsup/47431_0.txt\n",
            "aclImdb/train/unsup/47430_0.txt\n",
            "aclImdb/train/unsup/47429_0.txt\n",
            "aclImdb/train/unsup/47428_0.txt\n",
            "aclImdb/train/unsup/47427_0.txt\n",
            "aclImdb/train/unsup/47426_0.txt\n",
            "aclImdb/train/unsup/47425_0.txt\n",
            "aclImdb/train/unsup/47424_0.txt\n",
            "aclImdb/train/unsup/47423_0.txt\n",
            "aclImdb/train/unsup/47422_0.txt\n",
            "aclImdb/train/unsup/47421_0.txt\n",
            "aclImdb/train/unsup/47420_0.txt\n",
            "aclImdb/train/unsup/47419_0.txt\n",
            "aclImdb/train/unsup/47418_0.txt\n",
            "aclImdb/train/unsup/47417_0.txt\n",
            "aclImdb/train/unsup/47416_0.txt\n",
            "aclImdb/train/unsup/47415_0.txt\n",
            "aclImdb/train/unsup/47414_0.txt\n",
            "aclImdb/train/unsup/47413_0.txt\n",
            "aclImdb/train/unsup/47412_0.txt\n",
            "aclImdb/train/unsup/47411_0.txt\n",
            "aclImdb/train/unsup/47410_0.txt\n",
            "aclImdb/train/unsup/47409_0.txt\n",
            "aclImdb/train/unsup/47408_0.txt\n",
            "aclImdb/train/unsup/47407_0.txt\n",
            "aclImdb/train/unsup/47406_0.txt\n",
            "aclImdb/train/unsup/47405_0.txt\n",
            "aclImdb/train/unsup/47404_0.txt\n",
            "aclImdb/train/unsup/47403_0.txt\n",
            "aclImdb/train/unsup/47402_0.txt\n",
            "aclImdb/train/unsup/47401_0.txt\n",
            "aclImdb/train/unsup/47400_0.txt\n",
            "aclImdb/train/unsup/47399_0.txt\n",
            "aclImdb/train/unsup/47398_0.txt\n",
            "aclImdb/train/unsup/47397_0.txt\n",
            "aclImdb/train/unsup/47396_0.txt\n",
            "aclImdb/train/unsup/47395_0.txt\n",
            "aclImdb/train/unsup/47394_0.txt\n",
            "aclImdb/train/unsup/47393_0.txt\n",
            "aclImdb/train/unsup/47392_0.txt\n",
            "aclImdb/train/unsup/47391_0.txt\n",
            "aclImdb/train/unsup/47390_0.txt\n",
            "aclImdb/train/unsup/47389_0.txt\n",
            "aclImdb/train/unsup/47388_0.txt\n",
            "aclImdb/train/unsup/47387_0.txt\n",
            "aclImdb/train/unsup/47386_0.txt\n",
            "aclImdb/train/unsup/47385_0.txt\n",
            "aclImdb/train/unsup/47384_0.txt\n",
            "aclImdb/train/unsup/47383_0.txt\n",
            "aclImdb/train/unsup/47382_0.txt\n",
            "aclImdb/train/unsup/47381_0.txt\n",
            "aclImdb/train/unsup/47380_0.txt\n",
            "aclImdb/train/unsup/47379_0.txt\n",
            "aclImdb/train/unsup/47378_0.txt\n",
            "aclImdb/train/unsup/47377_0.txt\n",
            "aclImdb/train/unsup/47376_0.txt\n",
            "aclImdb/train/unsup/47375_0.txt\n",
            "aclImdb/train/unsup/47374_0.txt\n",
            "aclImdb/train/unsup/47373_0.txt\n",
            "aclImdb/train/unsup/47372_0.txt\n",
            "aclImdb/train/unsup/47371_0.txt\n",
            "aclImdb/train/unsup/47370_0.txt\n",
            "aclImdb/train/unsup/47369_0.txt\n",
            "aclImdb/train/unsup/47368_0.txt\n",
            "aclImdb/train/unsup/47367_0.txt\n",
            "aclImdb/train/unsup/47366_0.txt\n",
            "aclImdb/train/unsup/47365_0.txt\n",
            "aclImdb/train/unsup/47364_0.txt\n",
            "aclImdb/train/unsup/47363_0.txt\n",
            "aclImdb/train/unsup/47362_0.txt\n",
            "aclImdb/train/unsup/47361_0.txt\n",
            "aclImdb/train/unsup/47360_0.txt\n",
            "aclImdb/train/unsup/47615_0.txt\n",
            "aclImdb/train/unsup/47614_0.txt\n",
            "aclImdb/train/unsup/47613_0.txt\n",
            "aclImdb/train/unsup/47612_0.txt\n",
            "aclImdb/train/unsup/47611_0.txt\n",
            "aclImdb/train/unsup/47610_0.txt\n",
            "aclImdb/train/unsup/47609_0.txt\n",
            "aclImdb/train/unsup/47608_0.txt\n",
            "aclImdb/train/unsup/47607_0.txt\n",
            "aclImdb/train/unsup/47606_0.txt\n",
            "aclImdb/train/unsup/47605_0.txt\n",
            "aclImdb/train/unsup/47604_0.txt\n",
            "aclImdb/train/unsup/47603_0.txt\n",
            "aclImdb/train/unsup/47602_0.txt\n",
            "aclImdb/train/unsup/47601_0.txt\n",
            "aclImdb/train/unsup/47600_0.txt\n",
            "aclImdb/train/unsup/47599_0.txt\n",
            "aclImdb/train/unsup/47598_0.txt\n",
            "aclImdb/train/unsup/47597_0.txt\n",
            "aclImdb/train/unsup/47596_0.txt\n",
            "aclImdb/train/unsup/47595_0.txt\n",
            "aclImdb/train/unsup/47594_0.txt\n",
            "aclImdb/train/unsup/47593_0.txt\n",
            "aclImdb/train/unsup/47592_0.txt\n",
            "aclImdb/train/unsup/47591_0.txt\n",
            "aclImdb/train/unsup/47590_0.txt\n",
            "aclImdb/train/unsup/47589_0.txt\n",
            "aclImdb/train/unsup/47588_0.txt\n",
            "aclImdb/train/unsup/47587_0.txt\n",
            "aclImdb/train/unsup/47586_0.txt\n",
            "aclImdb/train/unsup/47585_0.txt\n",
            "aclImdb/train/unsup/47584_0.txt\n",
            "aclImdb/train/unsup/47583_0.txt\n",
            "aclImdb/train/unsup/47582_0.txt\n",
            "aclImdb/train/unsup/47581_0.txt\n",
            "aclImdb/train/unsup/47580_0.txt\n",
            "aclImdb/train/unsup/47579_0.txt\n",
            "aclImdb/train/unsup/47578_0.txt\n",
            "aclImdb/train/unsup/47577_0.txt\n",
            "aclImdb/train/unsup/47576_0.txt\n",
            "aclImdb/train/unsup/47575_0.txt\n",
            "aclImdb/train/unsup/47574_0.txt\n",
            "aclImdb/train/unsup/47573_0.txt\n",
            "aclImdb/train/unsup/47572_0.txt\n",
            "aclImdb/train/unsup/47571_0.txt\n",
            "aclImdb/train/unsup/47570_0.txt\n",
            "aclImdb/train/unsup/47569_0.txt\n",
            "aclImdb/train/unsup/47568_0.txt\n",
            "aclImdb/train/unsup/47567_0.txt\n",
            "aclImdb/train/unsup/47566_0.txt\n",
            "aclImdb/train/unsup/47565_0.txt\n",
            "aclImdb/train/unsup/47564_0.txt\n",
            "aclImdb/train/unsup/47563_0.txt\n",
            "aclImdb/train/unsup/47562_0.txt\n",
            "aclImdb/train/unsup/47561_0.txt\n",
            "aclImdb/train/unsup/47560_0.txt\n",
            "aclImdb/train/unsup/47559_0.txt\n",
            "aclImdb/train/unsup/47558_0.txt\n",
            "aclImdb/train/unsup/47557_0.txt\n",
            "aclImdb/train/unsup/47556_0.txt\n",
            "aclImdb/train/unsup/47555_0.txt\n",
            "aclImdb/train/unsup/47554_0.txt\n",
            "aclImdb/train/unsup/47553_0.txt\n",
            "aclImdb/train/unsup/47552_0.txt\n",
            "aclImdb/train/unsup/47551_0.txt\n",
            "aclImdb/train/unsup/47550_0.txt\n",
            "aclImdb/train/unsup/47549_0.txt\n",
            "aclImdb/train/unsup/47548_0.txt\n",
            "aclImdb/train/unsup/47547_0.txt\n",
            "aclImdb/train/unsup/47546_0.txt\n",
            "aclImdb/train/unsup/47545_0.txt\n",
            "aclImdb/train/unsup/47544_0.txt\n",
            "aclImdb/train/unsup/47543_0.txt\n",
            "aclImdb/train/unsup/47542_0.txt\n",
            "aclImdb/train/unsup/47541_0.txt\n",
            "aclImdb/train/unsup/47540_0.txt\n",
            "aclImdb/train/unsup/47539_0.txt\n",
            "aclImdb/train/unsup/47538_0.txt\n",
            "aclImdb/train/unsup/47537_0.txt\n",
            "aclImdb/train/unsup/47536_0.txt\n",
            "aclImdb/train/unsup/47535_0.txt\n",
            "aclImdb/train/unsup/47534_0.txt\n",
            "aclImdb/train/unsup/47533_0.txt\n",
            "aclImdb/train/unsup/47532_0.txt\n",
            "aclImdb/train/unsup/47531_0.txt\n",
            "aclImdb/train/unsup/47530_0.txt\n",
            "aclImdb/train/unsup/47529_0.txt\n",
            "aclImdb/train/unsup/47528_0.txt\n",
            "aclImdb/train/unsup/47527_0.txt\n",
            "aclImdb/train/unsup/47526_0.txt\n",
            "aclImdb/train/unsup/47525_0.txt\n",
            "aclImdb/train/unsup/47524_0.txt\n",
            "aclImdb/train/unsup/47523_0.txt\n",
            "aclImdb/train/unsup/47522_0.txt\n",
            "aclImdb/train/unsup/47521_0.txt\n",
            "aclImdb/train/unsup/47520_0.txt\n",
            "aclImdb/train/unsup/47519_0.txt\n",
            "aclImdb/train/unsup/47518_0.txt\n",
            "aclImdb/train/unsup/47517_0.txt\n",
            "aclImdb/train/unsup/47516_0.txt\n",
            "aclImdb/train/unsup/47515_0.txt\n",
            "aclImdb/train/unsup/47514_0.txt\n",
            "aclImdb/train/unsup/47513_0.txt\n",
            "aclImdb/train/unsup/47512_0.txt\n",
            "aclImdb/train/unsup/47511_0.txt\n",
            "aclImdb/train/unsup/47510_0.txt\n",
            "aclImdb/train/unsup/47509_0.txt\n",
            "aclImdb/train/unsup/47508_0.txt\n",
            "aclImdb/train/unsup/47507_0.txt\n",
            "aclImdb/train/unsup/47506_0.txt\n",
            "aclImdb/train/unsup/47505_0.txt\n",
            "aclImdb/train/unsup/47504_0.txt\n",
            "aclImdb/train/unsup/47503_0.txt\n",
            "aclImdb/train/unsup/47502_0.txt\n",
            "aclImdb/train/unsup/47501_0.txt\n",
            "aclImdb/train/unsup/47500_0.txt\n",
            "aclImdb/train/unsup/47499_0.txt\n",
            "aclImdb/train/unsup/47498_0.txt\n",
            "aclImdb/train/unsup/47497_0.txt\n",
            "aclImdb/train/unsup/47496_0.txt\n",
            "aclImdb/train/unsup/47495_0.txt\n",
            "aclImdb/train/unsup/47494_0.txt\n",
            "aclImdb/train/unsup/47493_0.txt\n",
            "aclImdb/train/unsup/47492_0.txt\n",
            "aclImdb/train/unsup/47491_0.txt\n",
            "aclImdb/train/unsup/47490_0.txt\n",
            "aclImdb/train/unsup/47489_0.txt\n",
            "aclImdb/train/unsup/47488_0.txt\n",
            "aclImdb/train/unsup/47743_0.txt\n",
            "aclImdb/train/unsup/47742_0.txt\n",
            "aclImdb/train/unsup/47741_0.txt\n",
            "aclImdb/train/unsup/47740_0.txt\n",
            "aclImdb/train/unsup/47739_0.txt\n",
            "aclImdb/train/unsup/47738_0.txt\n",
            "aclImdb/train/unsup/47737_0.txt\n",
            "aclImdb/train/unsup/47736_0.txt\n",
            "aclImdb/train/unsup/47735_0.txt\n",
            "aclImdb/train/unsup/47734_0.txt\n",
            "aclImdb/train/unsup/47733_0.txt\n",
            "aclImdb/train/unsup/47732_0.txt\n",
            "aclImdb/train/unsup/47731_0.txt\n",
            "aclImdb/train/unsup/47730_0.txt\n",
            "aclImdb/train/unsup/47729_0.txt\n",
            "aclImdb/train/unsup/47728_0.txt\n",
            "aclImdb/train/unsup/47727_0.txt\n",
            "aclImdb/train/unsup/47726_0.txt\n",
            "aclImdb/train/unsup/47725_0.txt\n",
            "aclImdb/train/unsup/47724_0.txt\n",
            "aclImdb/train/unsup/47723_0.txt\n",
            "aclImdb/train/unsup/47722_0.txt\n",
            "aclImdb/train/unsup/47721_0.txt\n",
            "aclImdb/train/unsup/47720_0.txt\n",
            "aclImdb/train/unsup/47719_0.txt\n",
            "aclImdb/train/unsup/47718_0.txt\n",
            "aclImdb/train/unsup/47717_0.txt\n",
            "aclImdb/train/unsup/47716_0.txt\n",
            "aclImdb/train/unsup/47715_0.txt\n",
            "aclImdb/train/unsup/47714_0.txt\n",
            "aclImdb/train/unsup/47713_0.txt\n",
            "aclImdb/train/unsup/47712_0.txt\n",
            "aclImdb/train/unsup/47711_0.txt\n",
            "aclImdb/train/unsup/47710_0.txt\n",
            "aclImdb/train/unsup/47709_0.txt\n",
            "aclImdb/train/unsup/47708_0.txt\n",
            "aclImdb/train/unsup/47707_0.txt\n",
            "aclImdb/train/unsup/47706_0.txt\n",
            "aclImdb/train/unsup/47705_0.txt\n",
            "aclImdb/train/unsup/47704_0.txt\n",
            "aclImdb/train/unsup/47703_0.txt\n",
            "aclImdb/train/unsup/47702_0.txt\n",
            "aclImdb/train/unsup/47701_0.txt\n",
            "aclImdb/train/unsup/47700_0.txt\n",
            "aclImdb/train/unsup/47699_0.txt\n",
            "aclImdb/train/unsup/47698_0.txt\n",
            "aclImdb/train/unsup/47697_0.txt\n",
            "aclImdb/train/unsup/47696_0.txt\n",
            "aclImdb/train/unsup/47695_0.txt\n",
            "aclImdb/train/unsup/47694_0.txt\n",
            "aclImdb/train/unsup/47693_0.txt\n",
            "aclImdb/train/unsup/47692_0.txt\n",
            "aclImdb/train/unsup/47691_0.txt\n",
            "aclImdb/train/unsup/47690_0.txt\n",
            "aclImdb/train/unsup/47689_0.txt\n",
            "aclImdb/train/unsup/47688_0.txt\n",
            "aclImdb/train/unsup/47687_0.txt\n",
            "aclImdb/train/unsup/47686_0.txt\n",
            "aclImdb/train/unsup/47685_0.txt\n",
            "aclImdb/train/unsup/47684_0.txt\n",
            "aclImdb/train/unsup/47683_0.txt\n",
            "aclImdb/train/unsup/47682_0.txt\n",
            "aclImdb/train/unsup/47681_0.txt\n",
            "aclImdb/train/unsup/47680_0.txt\n",
            "aclImdb/train/unsup/47679_0.txt\n",
            "aclImdb/train/unsup/47678_0.txt\n",
            "aclImdb/train/unsup/47677_0.txt\n",
            "aclImdb/train/unsup/47676_0.txt\n",
            "aclImdb/train/unsup/47675_0.txt\n",
            "aclImdb/train/unsup/47674_0.txt\n",
            "aclImdb/train/unsup/47673_0.txt\n",
            "aclImdb/train/unsup/47672_0.txt\n",
            "aclImdb/train/unsup/47671_0.txt\n",
            "aclImdb/train/unsup/47670_0.txt\n",
            "aclImdb/train/unsup/47669_0.txt\n",
            "aclImdb/train/unsup/47668_0.txt\n",
            "aclImdb/train/unsup/47667_0.txt\n",
            "aclImdb/train/unsup/47666_0.txt\n",
            "aclImdb/train/unsup/47665_0.txt\n",
            "aclImdb/train/unsup/47664_0.txt\n",
            "aclImdb/train/unsup/47663_0.txt\n",
            "aclImdb/train/unsup/47662_0.txt\n",
            "aclImdb/train/unsup/47661_0.txt\n",
            "aclImdb/train/unsup/47660_0.txt\n",
            "aclImdb/train/unsup/47659_0.txt\n",
            "aclImdb/train/unsup/47658_0.txt\n",
            "aclImdb/train/unsup/47657_0.txt\n",
            "aclImdb/train/unsup/47656_0.txt\n",
            "aclImdb/train/unsup/47655_0.txt\n",
            "aclImdb/train/unsup/47654_0.txt\n",
            "aclImdb/train/unsup/47653_0.txt\n",
            "aclImdb/train/unsup/47652_0.txt\n",
            "aclImdb/train/unsup/47651_0.txt\n",
            "aclImdb/train/unsup/47650_0.txt\n",
            "aclImdb/train/unsup/47649_0.txt\n",
            "aclImdb/train/unsup/47648_0.txt\n",
            "aclImdb/train/unsup/47647_0.txt\n",
            "aclImdb/train/unsup/47646_0.txt\n",
            "aclImdb/train/unsup/47645_0.txt\n",
            "aclImdb/train/unsup/47644_0.txt\n",
            "aclImdb/train/unsup/47643_0.txt\n",
            "aclImdb/train/unsup/47642_0.txt\n",
            "aclImdb/train/unsup/47641_0.txt\n",
            "aclImdb/train/unsup/47640_0.txt\n",
            "aclImdb/train/unsup/47639_0.txt\n",
            "aclImdb/train/unsup/47638_0.txt\n",
            "aclImdb/train/unsup/47637_0.txt\n",
            "aclImdb/train/unsup/47636_0.txt\n",
            "aclImdb/train/unsup/47635_0.txt\n",
            "aclImdb/train/unsup/47634_0.txt\n",
            "aclImdb/train/unsup/47633_0.txt\n",
            "aclImdb/train/unsup/47632_0.txt\n",
            "aclImdb/train/unsup/47631_0.txt\n",
            "aclImdb/train/unsup/47630_0.txt\n",
            "aclImdb/train/unsup/47629_0.txt\n",
            "aclImdb/train/unsup/47628_0.txt\n",
            "aclImdb/train/unsup/47627_0.txt\n",
            "aclImdb/train/unsup/47626_0.txt\n",
            "aclImdb/train/unsup/47625_0.txt\n",
            "aclImdb/train/unsup/47624_0.txt\n",
            "aclImdb/train/unsup/47623_0.txt\n",
            "aclImdb/train/unsup/47622_0.txt\n",
            "aclImdb/train/unsup/47621_0.txt\n",
            "aclImdb/train/unsup/47620_0.txt\n",
            "aclImdb/train/unsup/47619_0.txt\n",
            "aclImdb/train/unsup/47618_0.txt\n",
            "aclImdb/train/unsup/47617_0.txt\n",
            "aclImdb/train/unsup/47616_0.txt\n",
            "aclImdb/train/unsup/47871_0.txt\n",
            "aclImdb/train/unsup/47870_0.txt\n",
            "aclImdb/train/unsup/47869_0.txt\n",
            "aclImdb/train/unsup/47868_0.txt\n",
            "aclImdb/train/unsup/47867_0.txt\n",
            "aclImdb/train/unsup/47866_0.txt\n",
            "aclImdb/train/unsup/47865_0.txt\n",
            "aclImdb/train/unsup/47864_0.txt\n",
            "aclImdb/train/unsup/47863_0.txt\n",
            "aclImdb/train/unsup/47862_0.txt\n",
            "aclImdb/train/unsup/47861_0.txt\n",
            "aclImdb/train/unsup/47860_0.txt\n",
            "aclImdb/train/unsup/47859_0.txt\n",
            "aclImdb/train/unsup/47858_0.txt\n",
            "aclImdb/train/unsup/47857_0.txt\n",
            "aclImdb/train/unsup/47856_0.txt\n",
            "aclImdb/train/unsup/47855_0.txt\n",
            "aclImdb/train/unsup/47854_0.txt\n",
            "aclImdb/train/unsup/47853_0.txt\n",
            "aclImdb/train/unsup/47852_0.txt\n",
            "aclImdb/train/unsup/47851_0.txt\n",
            "aclImdb/train/unsup/47850_0.txt\n",
            "aclImdb/train/unsup/47849_0.txt\n",
            "aclImdb/train/unsup/47848_0.txt\n",
            "aclImdb/train/unsup/47847_0.txt\n",
            "aclImdb/train/unsup/47846_0.txt\n",
            "aclImdb/train/unsup/47845_0.txt\n",
            "aclImdb/train/unsup/47844_0.txt\n",
            "aclImdb/train/unsup/47843_0.txt\n",
            "aclImdb/train/unsup/47842_0.txt\n",
            "aclImdb/train/unsup/47841_0.txt\n",
            "aclImdb/train/unsup/47840_0.txt\n",
            "aclImdb/train/unsup/47839_0.txt\n",
            "aclImdb/train/unsup/47838_0.txt\n",
            "aclImdb/train/unsup/47837_0.txt\n",
            "aclImdb/train/unsup/47836_0.txt\n",
            "aclImdb/train/unsup/47835_0.txt\n",
            "aclImdb/train/unsup/47834_0.txt\n",
            "aclImdb/train/unsup/47833_0.txt\n",
            "aclImdb/train/unsup/47832_0.txt\n",
            "aclImdb/train/unsup/47831_0.txt\n",
            "aclImdb/train/unsup/47830_0.txt\n",
            "aclImdb/train/unsup/47829_0.txt\n",
            "aclImdb/train/unsup/47828_0.txt\n",
            "aclImdb/train/unsup/47827_0.txt\n",
            "aclImdb/train/unsup/47826_0.txt\n",
            "aclImdb/train/unsup/47825_0.txt\n",
            "aclImdb/train/unsup/47824_0.txt\n",
            "aclImdb/train/unsup/47823_0.txt\n",
            "aclImdb/train/unsup/47822_0.txt\n",
            "aclImdb/train/unsup/47821_0.txt\n",
            "aclImdb/train/unsup/47820_0.txt\n",
            "aclImdb/train/unsup/47819_0.txt\n",
            "aclImdb/train/unsup/47818_0.txt\n",
            "aclImdb/train/unsup/47817_0.txt\n",
            "aclImdb/train/unsup/47816_0.txt\n",
            "aclImdb/train/unsup/47815_0.txt\n",
            "aclImdb/train/unsup/47814_0.txt\n",
            "aclImdb/train/unsup/47813_0.txt\n",
            "aclImdb/train/unsup/47812_0.txt\n",
            "aclImdb/train/unsup/47811_0.txt\n",
            "aclImdb/train/unsup/47810_0.txt\n",
            "aclImdb/train/unsup/47809_0.txt\n",
            "aclImdb/train/unsup/47808_0.txt\n",
            "aclImdb/train/unsup/47807_0.txt\n",
            "aclImdb/train/unsup/47806_0.txt\n",
            "aclImdb/train/unsup/47805_0.txt\n",
            "aclImdb/train/unsup/47804_0.txt\n",
            "aclImdb/train/unsup/47803_0.txt\n",
            "aclImdb/train/unsup/47802_0.txt\n",
            "aclImdb/train/unsup/47801_0.txt\n",
            "aclImdb/train/unsup/47800_0.txt\n",
            "aclImdb/train/unsup/47799_0.txt\n",
            "aclImdb/train/unsup/47798_0.txt\n",
            "aclImdb/train/unsup/47797_0.txt\n",
            "aclImdb/train/unsup/47796_0.txt\n",
            "aclImdb/train/unsup/47795_0.txt\n",
            "aclImdb/train/unsup/47794_0.txt\n",
            "aclImdb/train/unsup/47793_0.txt\n",
            "aclImdb/train/unsup/47792_0.txt\n",
            "aclImdb/train/unsup/47791_0.txt\n",
            "aclImdb/train/unsup/47790_0.txt\n",
            "aclImdb/train/unsup/47789_0.txt\n",
            "aclImdb/train/unsup/47788_0.txt\n",
            "aclImdb/train/unsup/47787_0.txt\n",
            "aclImdb/train/unsup/47786_0.txt\n",
            "aclImdb/train/unsup/47785_0.txt\n",
            "aclImdb/train/unsup/47784_0.txt\n",
            "aclImdb/train/unsup/47783_0.txt\n",
            "aclImdb/train/unsup/47782_0.txt\n",
            "aclImdb/train/unsup/47781_0.txt\n",
            "aclImdb/train/unsup/47780_0.txt\n",
            "aclImdb/train/unsup/47779_0.txt\n",
            "aclImdb/train/unsup/47778_0.txt\n",
            "aclImdb/train/unsup/47777_0.txt\n",
            "aclImdb/train/unsup/47776_0.txt\n",
            "aclImdb/train/unsup/47775_0.txt\n",
            "aclImdb/train/unsup/47774_0.txt\n",
            "aclImdb/train/unsup/47773_0.txt\n",
            "aclImdb/train/unsup/47772_0.txt\n",
            "aclImdb/train/unsup/47771_0.txt\n",
            "aclImdb/train/unsup/47770_0.txt\n",
            "aclImdb/train/unsup/47769_0.txt\n",
            "aclImdb/train/unsup/47768_0.txt\n",
            "aclImdb/train/unsup/47767_0.txt\n",
            "aclImdb/train/unsup/47766_0.txt\n",
            "aclImdb/train/unsup/47765_0.txt\n",
            "aclImdb/train/unsup/47764_0.txt\n",
            "aclImdb/train/unsup/47763_0.txt\n",
            "aclImdb/train/unsup/47762_0.txt\n",
            "aclImdb/train/unsup/47761_0.txt\n",
            "aclImdb/train/unsup/47760_0.txt\n",
            "aclImdb/train/unsup/47759_0.txt\n",
            "aclImdb/train/unsup/47758_0.txt\n",
            "aclImdb/train/unsup/47757_0.txt\n",
            "aclImdb/train/unsup/47756_0.txt\n",
            "aclImdb/train/unsup/47755_0.txt\n",
            "aclImdb/train/unsup/47754_0.txt\n",
            "aclImdb/train/unsup/47753_0.txt\n",
            "aclImdb/train/unsup/47752_0.txt\n",
            "aclImdb/train/unsup/47751_0.txt\n",
            "aclImdb/train/unsup/47750_0.txt\n",
            "aclImdb/train/unsup/47749_0.txt\n",
            "aclImdb/train/unsup/47748_0.txt\n",
            "aclImdb/train/unsup/47747_0.txt\n",
            "aclImdb/train/unsup/47746_0.txt\n",
            "aclImdb/train/unsup/47745_0.txt\n",
            "aclImdb/train/unsup/47744_0.txt\n",
            "aclImdb/train/unsup/47999_0.txt\n",
            "aclImdb/train/unsup/47998_0.txt\n",
            "aclImdb/train/unsup/47997_0.txt\n",
            "aclImdb/train/unsup/47996_0.txt\n",
            "aclImdb/train/unsup/47995_0.txt\n",
            "aclImdb/train/unsup/47994_0.txt\n",
            "aclImdb/train/unsup/47993_0.txt\n",
            "aclImdb/train/unsup/47992_0.txt\n",
            "aclImdb/train/unsup/47991_0.txt\n",
            "aclImdb/train/unsup/47990_0.txt\n",
            "aclImdb/train/unsup/47989_0.txt\n",
            "aclImdb/train/unsup/47988_0.txt\n",
            "aclImdb/train/unsup/47987_0.txt\n",
            "aclImdb/train/unsup/47986_0.txt\n",
            "aclImdb/train/unsup/47985_0.txt\n",
            "aclImdb/train/unsup/47984_0.txt\n",
            "aclImdb/train/unsup/47983_0.txt\n",
            "aclImdb/train/unsup/47982_0.txt\n",
            "aclImdb/train/unsup/47981_0.txt\n",
            "aclImdb/train/unsup/47980_0.txt\n",
            "aclImdb/train/unsup/47979_0.txt\n",
            "aclImdb/train/unsup/47978_0.txt\n",
            "aclImdb/train/unsup/47977_0.txt\n",
            "aclImdb/train/unsup/47976_0.txt\n",
            "aclImdb/train/unsup/47975_0.txt\n",
            "aclImdb/train/unsup/47974_0.txt\n",
            "aclImdb/train/unsup/47973_0.txt\n",
            "aclImdb/train/unsup/47972_0.txt\n",
            "aclImdb/train/unsup/47971_0.txt\n",
            "aclImdb/train/unsup/47970_0.txt\n",
            "aclImdb/train/unsup/47969_0.txt\n",
            "aclImdb/train/unsup/47968_0.txt\n",
            "aclImdb/train/unsup/47967_0.txt\n",
            "aclImdb/train/unsup/47966_0.txt\n",
            "aclImdb/train/unsup/47965_0.txt\n",
            "aclImdb/train/unsup/47964_0.txt\n",
            "aclImdb/train/unsup/47963_0.txt\n",
            "aclImdb/train/unsup/47962_0.txt\n",
            "aclImdb/train/unsup/47961_0.txt\n",
            "aclImdb/train/unsup/47960_0.txt\n",
            "aclImdb/train/unsup/47959_0.txt\n",
            "aclImdb/train/unsup/47958_0.txt\n",
            "aclImdb/train/unsup/47957_0.txt\n",
            "aclImdb/train/unsup/47956_0.txt\n",
            "aclImdb/train/unsup/47955_0.txt\n",
            "aclImdb/train/unsup/47954_0.txt\n",
            "aclImdb/train/unsup/47953_0.txt\n",
            "aclImdb/train/unsup/47952_0.txt\n",
            "aclImdb/train/unsup/47951_0.txt\n",
            "aclImdb/train/unsup/47950_0.txt\n",
            "aclImdb/train/unsup/47949_0.txt\n",
            "aclImdb/train/unsup/47948_0.txt\n",
            "aclImdb/train/unsup/47947_0.txt\n",
            "aclImdb/train/unsup/47946_0.txt\n",
            "aclImdb/train/unsup/47945_0.txt\n",
            "aclImdb/train/unsup/47944_0.txt\n",
            "aclImdb/train/unsup/47943_0.txt\n",
            "aclImdb/train/unsup/47942_0.txt\n",
            "aclImdb/train/unsup/47941_0.txt\n",
            "aclImdb/train/unsup/47940_0.txt\n",
            "aclImdb/train/unsup/47939_0.txt\n",
            "aclImdb/train/unsup/47938_0.txt\n",
            "aclImdb/train/unsup/47937_0.txt\n",
            "aclImdb/train/unsup/47936_0.txt\n",
            "aclImdb/train/unsup/47935_0.txt\n",
            "aclImdb/train/unsup/47934_0.txt\n",
            "aclImdb/train/unsup/47933_0.txt\n",
            "aclImdb/train/unsup/47932_0.txt\n",
            "aclImdb/train/unsup/47931_0.txt\n",
            "aclImdb/train/unsup/47930_0.txt\n",
            "aclImdb/train/unsup/47929_0.txt\n",
            "aclImdb/train/unsup/47928_0.txt\n",
            "aclImdb/train/unsup/47927_0.txt\n",
            "aclImdb/train/unsup/47926_0.txt\n",
            "aclImdb/train/unsup/47925_0.txt\n",
            "aclImdb/train/unsup/47924_0.txt\n",
            "aclImdb/train/unsup/47923_0.txt\n",
            "aclImdb/train/unsup/47922_0.txt\n",
            "aclImdb/train/unsup/47921_0.txt\n",
            "aclImdb/train/unsup/47920_0.txt\n",
            "aclImdb/train/unsup/47919_0.txt\n",
            "aclImdb/train/unsup/47918_0.txt\n",
            "aclImdb/train/unsup/47917_0.txt\n",
            "aclImdb/train/unsup/47916_0.txt\n",
            "aclImdb/train/unsup/47915_0.txt\n",
            "aclImdb/train/unsup/47914_0.txt\n",
            "aclImdb/train/unsup/47913_0.txt\n",
            "aclImdb/train/unsup/47912_0.txt\n",
            "aclImdb/train/unsup/47911_0.txt\n",
            "aclImdb/train/unsup/47910_0.txt\n",
            "aclImdb/train/unsup/47909_0.txt\n",
            "aclImdb/train/unsup/47908_0.txt\n",
            "aclImdb/train/unsup/47907_0.txt\n",
            "aclImdb/train/unsup/47906_0.txt\n",
            "aclImdb/train/unsup/47905_0.txt\n",
            "aclImdb/train/unsup/47904_0.txt\n",
            "aclImdb/train/unsup/47903_0.txt\n",
            "aclImdb/train/unsup/47902_0.txt\n",
            "aclImdb/train/unsup/47901_0.txt\n",
            "aclImdb/train/unsup/47900_0.txt\n",
            "aclImdb/train/unsup/47899_0.txt\n",
            "aclImdb/train/unsup/47898_0.txt\n",
            "aclImdb/train/unsup/47897_0.txt\n",
            "aclImdb/train/unsup/47896_0.txt\n",
            "aclImdb/train/unsup/47895_0.txt\n",
            "aclImdb/train/unsup/47894_0.txt\n",
            "aclImdb/train/unsup/47893_0.txt\n",
            "aclImdb/train/unsup/47892_0.txt\n",
            "aclImdb/train/unsup/47891_0.txt\n",
            "aclImdb/train/unsup/47890_0.txt\n",
            "aclImdb/train/unsup/47889_0.txt\n",
            "aclImdb/train/unsup/47888_0.txt\n",
            "aclImdb/train/unsup/47887_0.txt\n",
            "aclImdb/train/unsup/47886_0.txt\n",
            "aclImdb/train/unsup/47885_0.txt\n",
            "aclImdb/train/unsup/47884_0.txt\n",
            "aclImdb/train/unsup/47883_0.txt\n",
            "aclImdb/train/unsup/47882_0.txt\n",
            "aclImdb/train/unsup/47881_0.txt\n",
            "aclImdb/train/unsup/47880_0.txt\n",
            "aclImdb/train/unsup/47879_0.txt\n",
            "aclImdb/train/unsup/47878_0.txt\n",
            "aclImdb/train/unsup/47877_0.txt\n",
            "aclImdb/train/unsup/47876_0.txt\n",
            "aclImdb/train/unsup/47875_0.txt\n",
            "aclImdb/train/unsup/47874_0.txt\n",
            "aclImdb/train/unsup/47873_0.txt\n",
            "aclImdb/train/unsup/47872_0.txt\n",
            "aclImdb/train/unsup/48127_0.txt\n",
            "aclImdb/train/unsup/48126_0.txt\n",
            "aclImdb/train/unsup/48125_0.txt\n",
            "aclImdb/train/unsup/48124_0.txt\n",
            "aclImdb/train/unsup/48123_0.txt\n",
            "aclImdb/train/unsup/48122_0.txt\n",
            "aclImdb/train/unsup/48121_0.txt\n",
            "aclImdb/train/unsup/48120_0.txt\n",
            "aclImdb/train/unsup/48119_0.txt\n",
            "aclImdb/train/unsup/48118_0.txt\n",
            "aclImdb/train/unsup/48117_0.txt\n",
            "aclImdb/train/unsup/48116_0.txt\n",
            "aclImdb/train/unsup/48115_0.txt\n",
            "aclImdb/train/unsup/48114_0.txt\n",
            "aclImdb/train/unsup/48113_0.txt\n",
            "aclImdb/train/unsup/48112_0.txt\n",
            "aclImdb/train/unsup/48111_0.txt\n",
            "aclImdb/train/unsup/48110_0.txt\n",
            "aclImdb/train/unsup/48109_0.txt\n",
            "aclImdb/train/unsup/48108_0.txt\n",
            "aclImdb/train/unsup/48107_0.txt\n",
            "aclImdb/train/unsup/48106_0.txt\n",
            "aclImdb/train/unsup/48105_0.txt\n",
            "aclImdb/train/unsup/48104_0.txt\n",
            "aclImdb/train/unsup/48103_0.txt\n",
            "aclImdb/train/unsup/48102_0.txt\n",
            "aclImdb/train/unsup/48101_0.txt\n",
            "aclImdb/train/unsup/48100_0.txt\n",
            "aclImdb/train/unsup/48099_0.txt\n",
            "aclImdb/train/unsup/48098_0.txt\n",
            "aclImdb/train/unsup/48097_0.txt\n",
            "aclImdb/train/unsup/48096_0.txt\n",
            "aclImdb/train/unsup/48095_0.txt\n",
            "aclImdb/train/unsup/48094_0.txt\n",
            "aclImdb/train/unsup/48093_0.txt\n",
            "aclImdb/train/unsup/48092_0.txt\n",
            "aclImdb/train/unsup/48091_0.txt\n",
            "aclImdb/train/unsup/48090_0.txt\n",
            "aclImdb/train/unsup/48089_0.txt\n",
            "aclImdb/train/unsup/48088_0.txt\n",
            "aclImdb/train/unsup/48087_0.txt\n",
            "aclImdb/train/unsup/48086_0.txt\n",
            "aclImdb/train/unsup/48085_0.txt\n",
            "aclImdb/train/unsup/48084_0.txt\n",
            "aclImdb/train/unsup/48083_0.txt\n",
            "aclImdb/train/unsup/48082_0.txt\n",
            "aclImdb/train/unsup/48081_0.txt\n",
            "aclImdb/train/unsup/48080_0.txt\n",
            "aclImdb/train/unsup/48079_0.txt\n",
            "aclImdb/train/unsup/48078_0.txt\n",
            "aclImdb/train/unsup/48077_0.txt\n",
            "aclImdb/train/unsup/48076_0.txt\n",
            "aclImdb/train/unsup/48075_0.txt\n",
            "aclImdb/train/unsup/48074_0.txt\n",
            "aclImdb/train/unsup/48073_0.txt\n",
            "aclImdb/train/unsup/48072_0.txt\n",
            "aclImdb/train/unsup/48071_0.txt\n",
            "aclImdb/train/unsup/48070_0.txt\n",
            "aclImdb/train/unsup/48069_0.txt\n",
            "aclImdb/train/unsup/48068_0.txt\n",
            "aclImdb/train/unsup/48067_0.txt\n",
            "aclImdb/train/unsup/48066_0.txt\n",
            "aclImdb/train/unsup/48065_0.txt\n",
            "aclImdb/train/unsup/48064_0.txt\n",
            "aclImdb/train/unsup/48063_0.txt\n",
            "aclImdb/train/unsup/48062_0.txt\n",
            "aclImdb/train/unsup/48061_0.txt\n",
            "aclImdb/train/unsup/48060_0.txt\n",
            "aclImdb/train/unsup/48059_0.txt\n",
            "aclImdb/train/unsup/48058_0.txt\n",
            "aclImdb/train/unsup/48057_0.txt\n",
            "aclImdb/train/unsup/48056_0.txt\n",
            "aclImdb/train/unsup/48055_0.txt\n",
            "aclImdb/train/unsup/48054_0.txt\n",
            "aclImdb/train/unsup/48053_0.txt\n",
            "aclImdb/train/unsup/48052_0.txt\n",
            "aclImdb/train/unsup/48051_0.txt\n",
            "aclImdb/train/unsup/48050_0.txt\n",
            "aclImdb/train/unsup/48049_0.txt\n",
            "aclImdb/train/unsup/48048_0.txt\n",
            "aclImdb/train/unsup/48047_0.txt\n",
            "aclImdb/train/unsup/48046_0.txt\n",
            "aclImdb/train/unsup/48045_0.txt\n",
            "aclImdb/train/unsup/48044_0.txt\n",
            "aclImdb/train/unsup/48043_0.txt\n",
            "aclImdb/train/unsup/48042_0.txt\n",
            "aclImdb/train/unsup/48041_0.txt\n",
            "aclImdb/train/unsup/48040_0.txt\n",
            "aclImdb/train/unsup/48039_0.txt\n",
            "aclImdb/train/unsup/48038_0.txt\n",
            "aclImdb/train/unsup/48037_0.txt\n",
            "aclImdb/train/unsup/48036_0.txt\n",
            "aclImdb/train/unsup/48035_0.txt\n",
            "aclImdb/train/unsup/48034_0.txt\n",
            "aclImdb/train/unsup/48033_0.txt\n",
            "aclImdb/train/unsup/48032_0.txt\n",
            "aclImdb/train/unsup/48031_0.txt\n",
            "aclImdb/train/unsup/48030_0.txt\n",
            "aclImdb/train/unsup/48029_0.txt\n",
            "aclImdb/train/unsup/48028_0.txt\n",
            "aclImdb/train/unsup/48027_0.txt\n",
            "aclImdb/train/unsup/48026_0.txt\n",
            "aclImdb/train/unsup/48025_0.txt\n",
            "aclImdb/train/unsup/48024_0.txt\n",
            "aclImdb/train/unsup/48023_0.txt\n",
            "aclImdb/train/unsup/48022_0.txt\n",
            "aclImdb/train/unsup/48021_0.txt\n",
            "aclImdb/train/unsup/48020_0.txt\n",
            "aclImdb/train/unsup/48019_0.txt\n",
            "aclImdb/train/unsup/48018_0.txt\n",
            "aclImdb/train/unsup/48017_0.txt\n",
            "aclImdb/train/unsup/48016_0.txt\n",
            "aclImdb/train/unsup/48015_0.txt\n",
            "aclImdb/train/unsup/48014_0.txt\n",
            "aclImdb/train/unsup/48013_0.txt\n",
            "aclImdb/train/unsup/48012_0.txt\n",
            "aclImdb/train/unsup/48011_0.txt\n",
            "aclImdb/train/unsup/48010_0.txt\n",
            "aclImdb/train/unsup/48009_0.txt\n",
            "aclImdb/train/unsup/48008_0.txt\n",
            "aclImdb/train/unsup/48007_0.txt\n",
            "aclImdb/train/unsup/48006_0.txt\n",
            "aclImdb/train/unsup/48005_0.txt\n",
            "aclImdb/train/unsup/48004_0.txt\n",
            "aclImdb/train/unsup/48003_0.txt\n",
            "aclImdb/train/unsup/48002_0.txt\n",
            "aclImdb/train/unsup/48001_0.txt\n",
            "aclImdb/train/unsup/48000_0.txt\n",
            "aclImdb/train/unsup/48255_0.txt\n",
            "aclImdb/train/unsup/48254_0.txt\n",
            "aclImdb/train/unsup/48253_0.txt\n",
            "aclImdb/train/unsup/48252_0.txt\n",
            "aclImdb/train/unsup/48251_0.txt\n",
            "aclImdb/train/unsup/48250_0.txt\n",
            "aclImdb/train/unsup/48249_0.txt\n",
            "aclImdb/train/unsup/48248_0.txt\n",
            "aclImdb/train/unsup/48247_0.txt\n",
            "aclImdb/train/unsup/48246_0.txt\n",
            "aclImdb/train/unsup/48245_0.txt\n",
            "aclImdb/train/unsup/48244_0.txt\n",
            "aclImdb/train/unsup/48243_0.txt\n",
            "aclImdb/train/unsup/48242_0.txt\n",
            "aclImdb/train/unsup/48241_0.txt\n",
            "aclImdb/train/unsup/48240_0.txt\n",
            "aclImdb/train/unsup/48239_0.txt\n",
            "aclImdb/train/unsup/48238_0.txt\n",
            "aclImdb/train/unsup/48237_0.txt\n",
            "aclImdb/train/unsup/48236_0.txt\n",
            "aclImdb/train/unsup/48235_0.txt\n",
            "aclImdb/train/unsup/48234_0.txt\n",
            "aclImdb/train/unsup/48233_0.txt\n",
            "aclImdb/train/unsup/48232_0.txt\n",
            "aclImdb/train/unsup/48231_0.txt\n",
            "aclImdb/train/unsup/48230_0.txt\n",
            "aclImdb/train/unsup/48229_0.txt\n",
            "aclImdb/train/unsup/48228_0.txt\n",
            "aclImdb/train/unsup/48227_0.txt\n",
            "aclImdb/train/unsup/48226_0.txt\n",
            "aclImdb/train/unsup/48225_0.txt\n",
            "aclImdb/train/unsup/48224_0.txt\n",
            "aclImdb/train/unsup/48223_0.txt\n",
            "aclImdb/train/unsup/48222_0.txt\n",
            "aclImdb/train/unsup/48221_0.txt\n",
            "aclImdb/train/unsup/48220_0.txt\n",
            "aclImdb/train/unsup/48219_0.txt\n",
            "aclImdb/train/unsup/48218_0.txt\n",
            "aclImdb/train/unsup/48217_0.txt\n",
            "aclImdb/train/unsup/48216_0.txt\n",
            "aclImdb/train/unsup/48215_0.txt\n",
            "aclImdb/train/unsup/48214_0.txt\n",
            "aclImdb/train/unsup/48213_0.txt\n",
            "aclImdb/train/unsup/48212_0.txt\n",
            "aclImdb/train/unsup/48211_0.txt\n",
            "aclImdb/train/unsup/48210_0.txt\n",
            "aclImdb/train/unsup/48209_0.txt\n",
            "aclImdb/train/unsup/48208_0.txt\n",
            "aclImdb/train/unsup/48207_0.txt\n",
            "aclImdb/train/unsup/48206_0.txt\n",
            "aclImdb/train/unsup/48205_0.txt\n",
            "aclImdb/train/unsup/48204_0.txt\n",
            "aclImdb/train/unsup/48203_0.txt\n",
            "aclImdb/train/unsup/48202_0.txt\n",
            "aclImdb/train/unsup/48201_0.txt\n",
            "aclImdb/train/unsup/48200_0.txt\n",
            "aclImdb/train/unsup/48199_0.txt\n",
            "aclImdb/train/unsup/48198_0.txt\n",
            "aclImdb/train/unsup/48197_0.txt\n",
            "aclImdb/train/unsup/48196_0.txt\n",
            "aclImdb/train/unsup/48195_0.txt\n",
            "aclImdb/train/unsup/48194_0.txt\n",
            "aclImdb/train/unsup/48193_0.txt\n",
            "aclImdb/train/unsup/48192_0.txt\n",
            "aclImdb/train/unsup/48191_0.txt\n",
            "aclImdb/train/unsup/48190_0.txt\n",
            "aclImdb/train/unsup/48189_0.txt\n",
            "aclImdb/train/unsup/48188_0.txt\n",
            "aclImdb/train/unsup/48187_0.txt\n",
            "aclImdb/train/unsup/48186_0.txt\n",
            "aclImdb/train/unsup/48185_0.txt\n",
            "aclImdb/train/unsup/48184_0.txt\n",
            "aclImdb/train/unsup/48183_0.txt\n",
            "aclImdb/train/unsup/48182_0.txt\n",
            "aclImdb/train/unsup/48181_0.txt\n",
            "aclImdb/train/unsup/48180_0.txt\n",
            "aclImdb/train/unsup/48179_0.txt\n",
            "aclImdb/train/unsup/48178_0.txt\n",
            "aclImdb/train/unsup/48177_0.txt\n",
            "aclImdb/train/unsup/48176_0.txt\n",
            "aclImdb/train/unsup/48175_0.txt\n",
            "aclImdb/train/unsup/48174_0.txt\n",
            "aclImdb/train/unsup/48173_0.txt\n",
            "aclImdb/train/unsup/48172_0.txt\n",
            "aclImdb/train/unsup/48171_0.txt\n",
            "aclImdb/train/unsup/48170_0.txt\n",
            "aclImdb/train/unsup/48169_0.txt\n",
            "aclImdb/train/unsup/48168_0.txt\n",
            "aclImdb/train/unsup/48167_0.txt\n",
            "aclImdb/train/unsup/48166_0.txt\n",
            "aclImdb/train/unsup/48165_0.txt\n",
            "aclImdb/train/unsup/48164_0.txt\n",
            "aclImdb/train/unsup/48163_0.txt\n",
            "aclImdb/train/unsup/48162_0.txt\n",
            "aclImdb/train/unsup/48161_0.txt\n",
            "aclImdb/train/unsup/48160_0.txt\n",
            "aclImdb/train/unsup/48159_0.txt\n",
            "aclImdb/train/unsup/48158_0.txt\n",
            "aclImdb/train/unsup/48157_0.txt\n",
            "aclImdb/train/unsup/48156_0.txt\n",
            "aclImdb/train/unsup/48155_0.txt\n",
            "aclImdb/train/unsup/48154_0.txt\n",
            "aclImdb/train/unsup/48153_0.txt\n",
            "aclImdb/train/unsup/48152_0.txt\n",
            "aclImdb/train/unsup/48151_0.txt\n",
            "aclImdb/train/unsup/48150_0.txt\n",
            "aclImdb/train/unsup/48149_0.txt\n",
            "aclImdb/train/unsup/48148_0.txt\n",
            "aclImdb/train/unsup/48147_0.txt\n",
            "aclImdb/train/unsup/48146_0.txt\n",
            "aclImdb/train/unsup/48145_0.txt\n",
            "aclImdb/train/unsup/48144_0.txt\n",
            "aclImdb/train/unsup/48143_0.txt\n",
            "aclImdb/train/unsup/48142_0.txt\n",
            "aclImdb/train/unsup/48141_0.txt\n",
            "aclImdb/train/unsup/48140_0.txt\n",
            "aclImdb/train/unsup/48139_0.txt\n",
            "aclImdb/train/unsup/48138_0.txt\n",
            "aclImdb/train/unsup/48137_0.txt\n",
            "aclImdb/train/unsup/48136_0.txt\n",
            "aclImdb/train/unsup/48135_0.txt\n",
            "aclImdb/train/unsup/48134_0.txt\n",
            "aclImdb/train/unsup/48133_0.txt\n",
            "aclImdb/train/unsup/48132_0.txt\n",
            "aclImdb/train/unsup/48131_0.txt\n",
            "aclImdb/train/unsup/48130_0.txt\n",
            "aclImdb/train/unsup/48129_0.txt\n",
            "aclImdb/train/unsup/48128_0.txt\n",
            "aclImdb/train/unsup/48383_0.txt\n",
            "aclImdb/train/unsup/48382_0.txt\n",
            "aclImdb/train/unsup/48381_0.txt\n",
            "aclImdb/train/unsup/48380_0.txt\n",
            "aclImdb/train/unsup/48379_0.txt\n",
            "aclImdb/train/unsup/48378_0.txt\n",
            "aclImdb/train/unsup/48377_0.txt\n",
            "aclImdb/train/unsup/48376_0.txt\n",
            "aclImdb/train/unsup/48375_0.txt\n",
            "aclImdb/train/unsup/48374_0.txt\n",
            "aclImdb/train/unsup/48373_0.txt\n",
            "aclImdb/train/unsup/48372_0.txt\n",
            "aclImdb/train/unsup/48371_0.txt\n",
            "aclImdb/train/unsup/48370_0.txt\n",
            "aclImdb/train/unsup/48369_0.txt\n",
            "aclImdb/train/unsup/48368_0.txt\n",
            "aclImdb/train/unsup/48367_0.txt\n",
            "aclImdb/train/unsup/48366_0.txt\n",
            "aclImdb/train/unsup/48365_0.txt\n",
            "aclImdb/train/unsup/48364_0.txt\n",
            "aclImdb/train/unsup/48363_0.txt\n",
            "aclImdb/train/unsup/48362_0.txt\n",
            "aclImdb/train/unsup/48361_0.txt\n",
            "aclImdb/train/unsup/48360_0.txt\n",
            "aclImdb/train/unsup/48359_0.txt\n",
            "aclImdb/train/unsup/48358_0.txt\n",
            "aclImdb/train/unsup/48357_0.txt\n",
            "aclImdb/train/unsup/48356_0.txt\n",
            "aclImdb/train/unsup/48355_0.txt\n",
            "aclImdb/train/unsup/48354_0.txt\n",
            "aclImdb/train/unsup/48353_0.txt\n",
            "aclImdb/train/unsup/48352_0.txt\n",
            "aclImdb/train/unsup/48351_0.txt\n",
            "aclImdb/train/unsup/48350_0.txt\n",
            "aclImdb/train/unsup/48349_0.txt\n",
            "aclImdb/train/unsup/48348_0.txt\n",
            "aclImdb/train/unsup/48347_0.txt\n",
            "aclImdb/train/unsup/48346_0.txt\n",
            "aclImdb/train/unsup/48345_0.txt\n",
            "aclImdb/train/unsup/48344_0.txt\n",
            "aclImdb/train/unsup/48343_0.txt\n",
            "aclImdb/train/unsup/48342_0.txt\n",
            "aclImdb/train/unsup/48341_0.txt\n",
            "aclImdb/train/unsup/48340_0.txt\n",
            "aclImdb/train/unsup/48339_0.txt\n",
            "aclImdb/train/unsup/48338_0.txt\n",
            "aclImdb/train/unsup/48337_0.txt\n",
            "aclImdb/train/unsup/48336_0.txt\n",
            "aclImdb/train/unsup/48335_0.txt\n",
            "aclImdb/train/unsup/48334_0.txt\n",
            "aclImdb/train/unsup/48333_0.txt\n",
            "aclImdb/train/unsup/48332_0.txt\n",
            "aclImdb/train/unsup/48331_0.txt\n",
            "aclImdb/train/unsup/48330_0.txt\n",
            "aclImdb/train/unsup/48329_0.txt\n",
            "aclImdb/train/unsup/48328_0.txt\n",
            "aclImdb/train/unsup/48327_0.txt\n",
            "aclImdb/train/unsup/48326_0.txt\n",
            "aclImdb/train/unsup/48325_0.txt\n",
            "aclImdb/train/unsup/48324_0.txt\n",
            "aclImdb/train/unsup/48323_0.txt\n",
            "aclImdb/train/unsup/48322_0.txt\n",
            "aclImdb/train/unsup/48321_0.txt\n",
            "aclImdb/train/unsup/48320_0.txt\n",
            "aclImdb/train/unsup/48319_0.txt\n",
            "aclImdb/train/unsup/48318_0.txt\n",
            "aclImdb/train/unsup/48317_0.txt\n",
            "aclImdb/train/unsup/48316_0.txt\n",
            "aclImdb/train/unsup/48315_0.txt\n",
            "aclImdb/train/unsup/48314_0.txt\n",
            "aclImdb/train/unsup/48313_0.txt\n",
            "aclImdb/train/unsup/48312_0.txt\n",
            "aclImdb/train/unsup/48311_0.txt\n",
            "aclImdb/train/unsup/48310_0.txt\n",
            "aclImdb/train/unsup/48309_0.txt\n",
            "aclImdb/train/unsup/48308_0.txt\n",
            "aclImdb/train/unsup/48307_0.txt\n",
            "aclImdb/train/unsup/48306_0.txt\n",
            "aclImdb/train/unsup/48305_0.txt\n",
            "aclImdb/train/unsup/48304_0.txt\n",
            "aclImdb/train/unsup/48303_0.txt\n",
            "aclImdb/train/unsup/48302_0.txt\n",
            "aclImdb/train/unsup/48301_0.txt\n",
            "aclImdb/train/unsup/48300_0.txt\n",
            "aclImdb/train/unsup/48299_0.txt\n",
            "aclImdb/train/unsup/48298_0.txt\n",
            "aclImdb/train/unsup/48297_0.txt\n",
            "aclImdb/train/unsup/48296_0.txt\n",
            "aclImdb/train/unsup/48295_0.txt\n",
            "aclImdb/train/unsup/48294_0.txt\n",
            "aclImdb/train/unsup/48293_0.txt\n",
            "aclImdb/train/unsup/48292_0.txt\n",
            "aclImdb/train/unsup/48291_0.txt\n",
            "aclImdb/train/unsup/48290_0.txt\n",
            "aclImdb/train/unsup/48289_0.txt\n",
            "aclImdb/train/unsup/48288_0.txt\n",
            "aclImdb/train/unsup/48287_0.txt\n",
            "aclImdb/train/unsup/48286_0.txt\n",
            "aclImdb/train/unsup/48285_0.txt\n",
            "aclImdb/train/unsup/48284_0.txt\n",
            "aclImdb/train/unsup/48283_0.txt\n",
            "aclImdb/train/unsup/48282_0.txt\n",
            "aclImdb/train/unsup/48281_0.txt\n",
            "aclImdb/train/unsup/48280_0.txt\n",
            "aclImdb/train/unsup/48279_0.txt\n",
            "aclImdb/train/unsup/48278_0.txt\n",
            "aclImdb/train/unsup/48277_0.txt\n",
            "aclImdb/train/unsup/48276_0.txt\n",
            "aclImdb/train/unsup/48275_0.txt\n",
            "aclImdb/train/unsup/48274_0.txt\n",
            "aclImdb/train/unsup/48273_0.txt\n",
            "aclImdb/train/unsup/48272_0.txt\n",
            "aclImdb/train/unsup/48271_0.txt\n",
            "aclImdb/train/unsup/48270_0.txt\n",
            "aclImdb/train/unsup/48269_0.txt\n",
            "aclImdb/train/unsup/48268_0.txt\n",
            "aclImdb/train/unsup/48267_0.txt\n",
            "aclImdb/train/unsup/48266_0.txt\n",
            "aclImdb/train/unsup/48265_0.txt\n",
            "aclImdb/train/unsup/48264_0.txt\n",
            "aclImdb/train/unsup/48263_0.txt\n",
            "aclImdb/train/unsup/48262_0.txt\n",
            "aclImdb/train/unsup/48261_0.txt\n",
            "aclImdb/train/unsup/48260_0.txt\n",
            "aclImdb/train/unsup/48259_0.txt\n",
            "aclImdb/train/unsup/48258_0.txt\n",
            "aclImdb/train/unsup/48257_0.txt\n",
            "aclImdb/train/unsup/48256_0.txt\n",
            "aclImdb/train/unsup/48511_0.txt\n",
            "aclImdb/train/unsup/48510_0.txt\n",
            "aclImdb/train/unsup/48509_0.txt\n",
            "aclImdb/train/unsup/48508_0.txt\n",
            "aclImdb/train/unsup/48507_0.txt\n",
            "aclImdb/train/unsup/48506_0.txt\n",
            "aclImdb/train/unsup/48505_0.txt\n",
            "aclImdb/train/unsup/48504_0.txt\n",
            "aclImdb/train/unsup/48503_0.txt\n",
            "aclImdb/train/unsup/48502_0.txt\n",
            "aclImdb/train/unsup/48501_0.txt\n",
            "aclImdb/train/unsup/48500_0.txt\n",
            "aclImdb/train/unsup/48499_0.txt\n",
            "aclImdb/train/unsup/48498_0.txt\n",
            "aclImdb/train/unsup/48497_0.txt\n",
            "aclImdb/train/unsup/48496_0.txt\n",
            "aclImdb/train/unsup/48495_0.txt\n",
            "aclImdb/train/unsup/48494_0.txt\n",
            "aclImdb/train/unsup/48493_0.txt\n",
            "aclImdb/train/unsup/48492_0.txt\n",
            "aclImdb/train/unsup/48491_0.txt\n",
            "aclImdb/train/unsup/48490_0.txt\n",
            "aclImdb/train/unsup/48489_0.txt\n",
            "aclImdb/train/unsup/48488_0.txt\n",
            "aclImdb/train/unsup/48487_0.txt\n",
            "aclImdb/train/unsup/48486_0.txt\n",
            "aclImdb/train/unsup/48485_0.txt\n",
            "aclImdb/train/unsup/48484_0.txt\n",
            "aclImdb/train/unsup/48483_0.txt\n",
            "aclImdb/train/unsup/48482_0.txt\n",
            "aclImdb/train/unsup/48481_0.txt\n",
            "aclImdb/train/unsup/48480_0.txt\n",
            "aclImdb/train/unsup/48479_0.txt\n",
            "aclImdb/train/unsup/48478_0.txt\n",
            "aclImdb/train/unsup/48477_0.txt\n",
            "aclImdb/train/unsup/48476_0.txt\n",
            "aclImdb/train/unsup/48475_0.txt\n",
            "aclImdb/train/unsup/48474_0.txt\n",
            "aclImdb/train/unsup/48473_0.txt\n",
            "aclImdb/train/unsup/48472_0.txt\n",
            "aclImdb/train/unsup/48471_0.txt\n",
            "aclImdb/train/unsup/48470_0.txt\n",
            "aclImdb/train/unsup/48469_0.txt\n",
            "aclImdb/train/unsup/48468_0.txt\n",
            "aclImdb/train/unsup/48467_0.txt\n",
            "aclImdb/train/unsup/48466_0.txt\n",
            "aclImdb/train/unsup/48465_0.txt\n",
            "aclImdb/train/unsup/48464_0.txt\n",
            "aclImdb/train/unsup/48463_0.txt\n",
            "aclImdb/train/unsup/48462_0.txt\n",
            "aclImdb/train/unsup/48461_0.txt\n",
            "aclImdb/train/unsup/48460_0.txt\n",
            "aclImdb/train/unsup/48459_0.txt\n",
            "aclImdb/train/unsup/48458_0.txt\n",
            "aclImdb/train/unsup/48457_0.txt\n",
            "aclImdb/train/unsup/48456_0.txt\n",
            "aclImdb/train/unsup/48455_0.txt\n",
            "aclImdb/train/unsup/48454_0.txt\n",
            "aclImdb/train/unsup/48453_0.txt\n",
            "aclImdb/train/unsup/48452_0.txt\n",
            "aclImdb/train/unsup/48451_0.txt\n",
            "aclImdb/train/unsup/48450_0.txt\n",
            "aclImdb/train/unsup/48449_0.txt\n",
            "aclImdb/train/unsup/48448_0.txt\n",
            "aclImdb/train/unsup/48447_0.txt\n",
            "aclImdb/train/unsup/48446_0.txt\n",
            "aclImdb/train/unsup/48445_0.txt\n",
            "aclImdb/train/unsup/48444_0.txt\n",
            "aclImdb/train/unsup/48443_0.txt\n",
            "aclImdb/train/unsup/48442_0.txt\n",
            "aclImdb/train/unsup/48441_0.txt\n",
            "aclImdb/train/unsup/48440_0.txt\n",
            "aclImdb/train/unsup/48439_0.txt\n",
            "aclImdb/train/unsup/48438_0.txt\n",
            "aclImdb/train/unsup/48437_0.txt\n",
            "aclImdb/train/unsup/48436_0.txt\n",
            "aclImdb/train/unsup/48435_0.txt\n",
            "aclImdb/train/unsup/48434_0.txt\n",
            "aclImdb/train/unsup/48433_0.txt\n",
            "aclImdb/train/unsup/48432_0.txt\n",
            "aclImdb/train/unsup/48431_0.txt\n",
            "aclImdb/train/unsup/48430_0.txt\n",
            "aclImdb/train/unsup/48429_0.txt\n",
            "aclImdb/train/unsup/48428_0.txt\n",
            "aclImdb/train/unsup/48427_0.txt\n",
            "aclImdb/train/unsup/48426_0.txt\n",
            "aclImdb/train/unsup/48425_0.txt\n",
            "aclImdb/train/unsup/48424_0.txt\n",
            "aclImdb/train/unsup/48423_0.txt\n",
            "aclImdb/train/unsup/48422_0.txt\n",
            "aclImdb/train/unsup/48421_0.txt\n",
            "aclImdb/train/unsup/48420_0.txt\n",
            "aclImdb/train/unsup/48419_0.txt\n",
            "aclImdb/train/unsup/48418_0.txt\n",
            "aclImdb/train/unsup/48417_0.txt\n",
            "aclImdb/train/unsup/48416_0.txt\n",
            "aclImdb/train/unsup/48415_0.txt\n",
            "aclImdb/train/unsup/48414_0.txt\n",
            "aclImdb/train/unsup/48413_0.txt\n",
            "aclImdb/train/unsup/48412_0.txt\n",
            "aclImdb/train/unsup/48411_0.txt\n",
            "aclImdb/train/unsup/48410_0.txt\n",
            "aclImdb/train/unsup/48409_0.txt\n",
            "aclImdb/train/unsup/48408_0.txt\n",
            "aclImdb/train/unsup/48407_0.txt\n",
            "aclImdb/train/unsup/48406_0.txt\n",
            "aclImdb/train/unsup/48405_0.txt\n",
            "aclImdb/train/unsup/48404_0.txt\n",
            "aclImdb/train/unsup/48403_0.txt\n",
            "aclImdb/train/unsup/48402_0.txt\n",
            "aclImdb/train/unsup/48401_0.txt\n",
            "aclImdb/train/unsup/48400_0.txt\n",
            "aclImdb/train/unsup/48399_0.txt\n",
            "aclImdb/train/unsup/48398_0.txt\n",
            "aclImdb/train/unsup/48397_0.txt\n",
            "aclImdb/train/unsup/48396_0.txt\n",
            "aclImdb/train/unsup/48395_0.txt\n",
            "aclImdb/train/unsup/48394_0.txt\n",
            "aclImdb/train/unsup/48393_0.txt\n",
            "aclImdb/train/unsup/48392_0.txt\n",
            "aclImdb/train/unsup/48391_0.txt\n",
            "aclImdb/train/unsup/48390_0.txt\n",
            "aclImdb/train/unsup/48389_0.txt\n",
            "aclImdb/train/unsup/48388_0.txt\n",
            "aclImdb/train/unsup/48387_0.txt\n",
            "aclImdb/train/unsup/48386_0.txt\n",
            "aclImdb/train/unsup/48385_0.txt\n",
            "aclImdb/train/unsup/48384_0.txt\n",
            "aclImdb/train/unsup/48639_0.txt\n",
            "aclImdb/train/unsup/48638_0.txt\n",
            "aclImdb/train/unsup/48637_0.txt\n",
            "aclImdb/train/unsup/48636_0.txt\n",
            "aclImdb/train/unsup/48635_0.txt\n",
            "aclImdb/train/unsup/48634_0.txt\n",
            "aclImdb/train/unsup/48633_0.txt\n",
            "aclImdb/train/unsup/48632_0.txt\n",
            "aclImdb/train/unsup/48631_0.txt\n",
            "aclImdb/train/unsup/48630_0.txt\n",
            "aclImdb/train/unsup/48629_0.txt\n",
            "aclImdb/train/unsup/48628_0.txt\n",
            "aclImdb/train/unsup/48627_0.txt\n",
            "aclImdb/train/unsup/48626_0.txt\n",
            "aclImdb/train/unsup/48625_0.txt\n",
            "aclImdb/train/unsup/48624_0.txt\n",
            "aclImdb/train/unsup/48623_0.txt\n",
            "aclImdb/train/unsup/48622_0.txt\n",
            "aclImdb/train/unsup/48621_0.txt\n",
            "aclImdb/train/unsup/48620_0.txt\n",
            "aclImdb/train/unsup/48619_0.txt\n",
            "aclImdb/train/unsup/48618_0.txt\n",
            "aclImdb/train/unsup/48617_0.txt\n",
            "aclImdb/train/unsup/48616_0.txt\n",
            "aclImdb/train/unsup/48615_0.txt\n",
            "aclImdb/train/unsup/48614_0.txt\n",
            "aclImdb/train/unsup/48613_0.txt\n",
            "aclImdb/train/unsup/48612_0.txt\n",
            "aclImdb/train/unsup/48611_0.txt\n",
            "aclImdb/train/unsup/48610_0.txt\n",
            "aclImdb/train/unsup/48609_0.txt\n",
            "aclImdb/train/unsup/48608_0.txt\n",
            "aclImdb/train/unsup/48607_0.txt\n",
            "aclImdb/train/unsup/48606_0.txt\n",
            "aclImdb/train/unsup/48605_0.txt\n",
            "aclImdb/train/unsup/48604_0.txt\n",
            "aclImdb/train/unsup/48603_0.txt\n",
            "aclImdb/train/unsup/48602_0.txt\n",
            "aclImdb/train/unsup/48601_0.txt\n",
            "aclImdb/train/unsup/48600_0.txt\n",
            "aclImdb/train/unsup/48599_0.txt\n",
            "aclImdb/train/unsup/48598_0.txt\n",
            "aclImdb/train/unsup/48597_0.txt\n",
            "aclImdb/train/unsup/48596_0.txt\n",
            "aclImdb/train/unsup/48595_0.txt\n",
            "aclImdb/train/unsup/48594_0.txt\n",
            "aclImdb/train/unsup/48593_0.txt\n",
            "aclImdb/train/unsup/48592_0.txt\n",
            "aclImdb/train/unsup/48591_0.txt\n",
            "aclImdb/train/unsup/48590_0.txt\n",
            "aclImdb/train/unsup/48589_0.txt\n",
            "aclImdb/train/unsup/48588_0.txt\n",
            "aclImdb/train/unsup/48587_0.txt\n",
            "aclImdb/train/unsup/48586_0.txt\n",
            "aclImdb/train/unsup/48585_0.txt\n",
            "aclImdb/train/unsup/48584_0.txt\n",
            "aclImdb/train/unsup/48583_0.txt\n",
            "aclImdb/train/unsup/48582_0.txt\n",
            "aclImdb/train/unsup/48581_0.txt\n",
            "aclImdb/train/unsup/48580_0.txt\n",
            "aclImdb/train/unsup/48579_0.txt\n",
            "aclImdb/train/unsup/48578_0.txt\n",
            "aclImdb/train/unsup/48577_0.txt\n",
            "aclImdb/train/unsup/48576_0.txt\n",
            "aclImdb/train/unsup/48575_0.txt\n",
            "aclImdb/train/unsup/48574_0.txt\n",
            "aclImdb/train/unsup/48573_0.txt\n",
            "aclImdb/train/unsup/48572_0.txt\n",
            "aclImdb/train/unsup/48571_0.txt\n",
            "aclImdb/train/unsup/48570_0.txt\n",
            "aclImdb/train/unsup/48569_0.txt\n",
            "aclImdb/train/unsup/48568_0.txt\n",
            "aclImdb/train/unsup/48567_0.txt\n",
            "aclImdb/train/unsup/48566_0.txt\n",
            "aclImdb/train/unsup/48565_0.txt\n",
            "aclImdb/train/unsup/48564_0.txt\n",
            "aclImdb/train/unsup/48563_0.txt\n",
            "aclImdb/train/unsup/48562_0.txt\n",
            "aclImdb/train/unsup/48561_0.txt\n",
            "aclImdb/train/unsup/48560_0.txt\n",
            "aclImdb/train/unsup/48559_0.txt\n",
            "aclImdb/train/unsup/48558_0.txt\n",
            "aclImdb/train/unsup/48557_0.txt\n",
            "aclImdb/train/unsup/48556_0.txt\n",
            "aclImdb/train/unsup/48555_0.txt\n",
            "aclImdb/train/unsup/48554_0.txt\n",
            "aclImdb/train/unsup/48553_0.txt\n",
            "aclImdb/train/unsup/48552_0.txt\n",
            "aclImdb/train/unsup/48551_0.txt\n",
            "aclImdb/train/unsup/48550_0.txt\n",
            "aclImdb/train/unsup/48549_0.txt\n",
            "aclImdb/train/unsup/48548_0.txt\n",
            "aclImdb/train/unsup/48547_0.txt\n",
            "aclImdb/train/unsup/48546_0.txt\n",
            "aclImdb/train/unsup/48545_0.txt\n",
            "aclImdb/train/unsup/48544_0.txt\n",
            "aclImdb/train/unsup/48543_0.txt\n",
            "aclImdb/train/unsup/48542_0.txt\n",
            "aclImdb/train/unsup/48541_0.txt\n",
            "aclImdb/train/unsup/48540_0.txt\n",
            "aclImdb/train/unsup/48539_0.txt\n",
            "aclImdb/train/unsup/48538_0.txt\n",
            "aclImdb/train/unsup/48537_0.txt\n",
            "aclImdb/train/unsup/48536_0.txt\n",
            "aclImdb/train/unsup/48535_0.txt\n",
            "aclImdb/train/unsup/48534_0.txt\n",
            "aclImdb/train/unsup/48533_0.txt\n",
            "aclImdb/train/unsup/48532_0.txt\n",
            "aclImdb/train/unsup/48531_0.txt\n",
            "aclImdb/train/unsup/48530_0.txt\n",
            "aclImdb/train/unsup/48529_0.txt\n",
            "aclImdb/train/unsup/48528_0.txt\n",
            "aclImdb/train/unsup/48527_0.txt\n",
            "aclImdb/train/unsup/48526_0.txt\n",
            "aclImdb/train/unsup/48525_0.txt\n",
            "aclImdb/train/unsup/48524_0.txt\n",
            "aclImdb/train/unsup/48523_0.txt\n",
            "aclImdb/train/unsup/48522_0.txt\n",
            "aclImdb/train/unsup/48521_0.txt\n",
            "aclImdb/train/unsup/48520_0.txt\n",
            "aclImdb/train/unsup/48519_0.txt\n",
            "aclImdb/train/unsup/48518_0.txt\n",
            "aclImdb/train/unsup/48517_0.txt\n",
            "aclImdb/train/unsup/48516_0.txt\n",
            "aclImdb/train/unsup/48515_0.txt\n",
            "aclImdb/train/unsup/48514_0.txt\n",
            "aclImdb/train/unsup/48513_0.txt\n",
            "aclImdb/train/unsup/48512_0.txt\n",
            "aclImdb/train/unsup/48767_0.txt\n",
            "aclImdb/train/unsup/48766_0.txt\n",
            "aclImdb/train/unsup/48765_0.txt\n",
            "aclImdb/train/unsup/48764_0.txt\n",
            "aclImdb/train/unsup/48763_0.txt\n",
            "aclImdb/train/unsup/48762_0.txt\n",
            "aclImdb/train/unsup/48761_0.txt\n",
            "aclImdb/train/unsup/48760_0.txt\n",
            "aclImdb/train/unsup/48759_0.txt\n",
            "aclImdb/train/unsup/48758_0.txt\n",
            "aclImdb/train/unsup/48757_0.txt\n",
            "aclImdb/train/unsup/48756_0.txt\n",
            "aclImdb/train/unsup/48755_0.txt\n",
            "aclImdb/train/unsup/48754_0.txt\n",
            "aclImdb/train/unsup/48753_0.txt\n",
            "aclImdb/train/unsup/48752_0.txt\n",
            "aclImdb/train/unsup/48751_0.txt\n",
            "aclImdb/train/unsup/48750_0.txt\n",
            "aclImdb/train/unsup/48749_0.txt\n",
            "aclImdb/train/unsup/48748_0.txt\n",
            "aclImdb/train/unsup/48747_0.txt\n",
            "aclImdb/train/unsup/48746_0.txt\n",
            "aclImdb/train/unsup/48745_0.txt\n",
            "aclImdb/train/unsup/48744_0.txt\n",
            "aclImdb/train/unsup/48743_0.txt\n",
            "aclImdb/train/unsup/48742_0.txt\n",
            "aclImdb/train/unsup/48741_0.txt\n",
            "aclImdb/train/unsup/48740_0.txt\n",
            "aclImdb/train/unsup/48739_0.txt\n",
            "aclImdb/train/unsup/48738_0.txt\n",
            "aclImdb/train/unsup/48737_0.txt\n",
            "aclImdb/train/unsup/48736_0.txt\n",
            "aclImdb/train/unsup/48735_0.txt\n",
            "aclImdb/train/unsup/48734_0.txt\n",
            "aclImdb/train/unsup/48733_0.txt\n",
            "aclImdb/train/unsup/48732_0.txt\n",
            "aclImdb/train/unsup/48731_0.txt\n",
            "aclImdb/train/unsup/48730_0.txt\n",
            "aclImdb/train/unsup/48729_0.txt\n",
            "aclImdb/train/unsup/48728_0.txt\n",
            "aclImdb/train/unsup/48727_0.txt\n",
            "aclImdb/train/unsup/48726_0.txt\n",
            "aclImdb/train/unsup/48725_0.txt\n",
            "aclImdb/train/unsup/48724_0.txt\n",
            "aclImdb/train/unsup/48723_0.txt\n",
            "aclImdb/train/unsup/48722_0.txt\n",
            "aclImdb/train/unsup/48721_0.txt\n",
            "aclImdb/train/unsup/48720_0.txt\n",
            "aclImdb/train/unsup/48719_0.txt\n",
            "aclImdb/train/unsup/48718_0.txt\n",
            "aclImdb/train/unsup/48717_0.txt\n",
            "aclImdb/train/unsup/48716_0.txt\n",
            "aclImdb/train/unsup/48715_0.txt\n",
            "aclImdb/train/unsup/48714_0.txt\n",
            "aclImdb/train/unsup/48713_0.txt\n",
            "aclImdb/train/unsup/48712_0.txt\n",
            "aclImdb/train/unsup/48711_0.txt\n",
            "aclImdb/train/unsup/48710_0.txt\n",
            "aclImdb/train/unsup/48709_0.txt\n",
            "aclImdb/train/unsup/48708_0.txt\n",
            "aclImdb/train/unsup/48707_0.txt\n",
            "aclImdb/train/unsup/48706_0.txt\n",
            "aclImdb/train/unsup/48705_0.txt\n",
            "aclImdb/train/unsup/48704_0.txt\n",
            "aclImdb/train/unsup/48703_0.txt\n",
            "aclImdb/train/unsup/48702_0.txt\n",
            "aclImdb/train/unsup/48701_0.txt\n",
            "aclImdb/train/unsup/48700_0.txt\n",
            "aclImdb/train/unsup/48699_0.txt\n",
            "aclImdb/train/unsup/48698_0.txt\n",
            "aclImdb/train/unsup/48697_0.txt\n",
            "aclImdb/train/unsup/48696_0.txt\n",
            "aclImdb/train/unsup/48695_0.txt\n",
            "aclImdb/train/unsup/48694_0.txt\n",
            "aclImdb/train/unsup/48693_0.txt\n",
            "aclImdb/train/unsup/48692_0.txt\n",
            "aclImdb/train/unsup/48691_0.txt\n",
            "aclImdb/train/unsup/48690_0.txt\n",
            "aclImdb/train/unsup/48689_0.txt\n",
            "aclImdb/train/unsup/48688_0.txt\n",
            "aclImdb/train/unsup/48687_0.txt\n",
            "aclImdb/train/unsup/48686_0.txt\n",
            "aclImdb/train/unsup/48685_0.txt\n",
            "aclImdb/train/unsup/48684_0.txt\n",
            "aclImdb/train/unsup/48683_0.txt\n",
            "aclImdb/train/unsup/48682_0.txt\n",
            "aclImdb/train/unsup/48681_0.txt\n",
            "aclImdb/train/unsup/48680_0.txt\n",
            "aclImdb/train/unsup/48679_0.txt\n",
            "aclImdb/train/unsup/48678_0.txt\n",
            "aclImdb/train/unsup/48677_0.txt\n",
            "aclImdb/train/unsup/48676_0.txt\n",
            "aclImdb/train/unsup/48675_0.txt\n",
            "aclImdb/train/unsup/48674_0.txt\n",
            "aclImdb/train/unsup/48673_0.txt\n",
            "aclImdb/train/unsup/48672_0.txt\n",
            "aclImdb/train/unsup/48671_0.txt\n",
            "aclImdb/train/unsup/48670_0.txt\n",
            "aclImdb/train/unsup/48669_0.txt\n",
            "aclImdb/train/unsup/48668_0.txt\n",
            "aclImdb/train/unsup/48667_0.txt\n",
            "aclImdb/train/unsup/48666_0.txt\n",
            "aclImdb/train/unsup/48665_0.txt\n",
            "aclImdb/train/unsup/48664_0.txt\n",
            "aclImdb/train/unsup/48663_0.txt\n",
            "aclImdb/train/unsup/48662_0.txt\n",
            "aclImdb/train/unsup/48661_0.txt\n",
            "aclImdb/train/unsup/48660_0.txt\n",
            "aclImdb/train/unsup/48659_0.txt\n",
            "aclImdb/train/unsup/48658_0.txt\n",
            "aclImdb/train/unsup/48657_0.txt\n",
            "aclImdb/train/unsup/48656_0.txt\n",
            "aclImdb/train/unsup/48655_0.txt\n",
            "aclImdb/train/unsup/48654_0.txt\n",
            "aclImdb/train/unsup/48653_0.txt\n",
            "aclImdb/train/unsup/48652_0.txt\n",
            "aclImdb/train/unsup/48651_0.txt\n",
            "aclImdb/train/unsup/48650_0.txt\n",
            "aclImdb/train/unsup/48649_0.txt\n",
            "aclImdb/train/unsup/48648_0.txt\n",
            "aclImdb/train/unsup/48647_0.txt\n",
            "aclImdb/train/unsup/48646_0.txt\n",
            "aclImdb/train/unsup/48645_0.txt\n",
            "aclImdb/train/unsup/48644_0.txt\n",
            "aclImdb/train/unsup/48643_0.txt\n",
            "aclImdb/train/unsup/48642_0.txt\n",
            "aclImdb/train/unsup/48641_0.txt\n",
            "aclImdb/train/unsup/48640_0.txt\n",
            "aclImdb/train/unsup/48895_0.txt\n",
            "aclImdb/train/unsup/48894_0.txt\n",
            "aclImdb/train/unsup/48893_0.txt\n",
            "aclImdb/train/unsup/48892_0.txt\n",
            "aclImdb/train/unsup/48891_0.txt\n",
            "aclImdb/train/unsup/48890_0.txt\n",
            "aclImdb/train/unsup/48889_0.txt\n",
            "aclImdb/train/unsup/48888_0.txt\n",
            "aclImdb/train/unsup/48887_0.txt\n",
            "aclImdb/train/unsup/48886_0.txt\n",
            "aclImdb/train/unsup/48885_0.txt\n",
            "aclImdb/train/unsup/48884_0.txt\n",
            "aclImdb/train/unsup/48883_0.txt\n",
            "aclImdb/train/unsup/48882_0.txt\n",
            "aclImdb/train/unsup/48881_0.txt\n",
            "aclImdb/train/unsup/48880_0.txt\n",
            "aclImdb/train/unsup/48879_0.txt\n",
            "aclImdb/train/unsup/48878_0.txt\n",
            "aclImdb/train/unsup/48877_0.txt\n",
            "aclImdb/train/unsup/48876_0.txt\n",
            "aclImdb/train/unsup/48875_0.txt\n",
            "aclImdb/train/unsup/48874_0.txt\n",
            "aclImdb/train/unsup/48873_0.txt\n",
            "aclImdb/train/unsup/48872_0.txt\n",
            "aclImdb/train/unsup/48871_0.txt\n",
            "aclImdb/train/unsup/48870_0.txt\n",
            "aclImdb/train/unsup/48869_0.txt\n",
            "aclImdb/train/unsup/48868_0.txt\n",
            "aclImdb/train/unsup/48867_0.txt\n",
            "aclImdb/train/unsup/48866_0.txt\n",
            "aclImdb/train/unsup/48865_0.txt\n",
            "aclImdb/train/unsup/48864_0.txt\n",
            "aclImdb/train/unsup/48863_0.txt\n",
            "aclImdb/train/unsup/48862_0.txt\n",
            "aclImdb/train/unsup/48861_0.txt\n",
            "aclImdb/train/unsup/48860_0.txt\n",
            "aclImdb/train/unsup/48859_0.txt\n",
            "aclImdb/train/unsup/48858_0.txt\n",
            "aclImdb/train/unsup/48857_0.txt\n",
            "aclImdb/train/unsup/48856_0.txt\n",
            "aclImdb/train/unsup/48855_0.txt\n",
            "aclImdb/train/unsup/48854_0.txt\n",
            "aclImdb/train/unsup/48853_0.txt\n",
            "aclImdb/train/unsup/48852_0.txt\n",
            "aclImdb/train/unsup/48851_0.txt\n",
            "aclImdb/train/unsup/48850_0.txt\n",
            "aclImdb/train/unsup/48849_0.txt\n",
            "aclImdb/train/unsup/48848_0.txt\n",
            "aclImdb/train/unsup/48847_0.txt\n",
            "aclImdb/train/unsup/48846_0.txt\n",
            "aclImdb/train/unsup/48845_0.txt\n",
            "aclImdb/train/unsup/48844_0.txt\n",
            "aclImdb/train/unsup/48843_0.txt\n",
            "aclImdb/train/unsup/48842_0.txt\n",
            "aclImdb/train/unsup/48841_0.txt\n",
            "aclImdb/train/unsup/48840_0.txt\n",
            "aclImdb/train/unsup/48839_0.txt\n",
            "aclImdb/train/unsup/48838_0.txt\n",
            "aclImdb/train/unsup/48837_0.txt\n",
            "aclImdb/train/unsup/48836_0.txt\n",
            "aclImdb/train/unsup/48835_0.txt\n",
            "aclImdb/train/unsup/48834_0.txt\n",
            "aclImdb/train/unsup/48833_0.txt\n",
            "aclImdb/train/unsup/48832_0.txt\n",
            "aclImdb/train/unsup/48831_0.txt\n",
            "aclImdb/train/unsup/48830_0.txt\n",
            "aclImdb/train/unsup/48829_0.txt\n",
            "aclImdb/train/unsup/48828_0.txt\n",
            "aclImdb/train/unsup/48827_0.txt\n",
            "aclImdb/train/unsup/48826_0.txt\n",
            "aclImdb/train/unsup/48825_0.txt\n",
            "aclImdb/train/unsup/48824_0.txt\n",
            "aclImdb/train/unsup/48823_0.txt\n",
            "aclImdb/train/unsup/48822_0.txt\n",
            "aclImdb/train/unsup/48821_0.txt\n",
            "aclImdb/train/unsup/48820_0.txt\n",
            "aclImdb/train/unsup/48819_0.txt\n",
            "aclImdb/train/unsup/48818_0.txt\n",
            "aclImdb/train/unsup/48817_0.txt\n",
            "aclImdb/train/unsup/48816_0.txt\n",
            "aclImdb/train/unsup/48815_0.txt\n",
            "aclImdb/train/unsup/48814_0.txt\n",
            "aclImdb/train/unsup/48813_0.txt\n",
            "aclImdb/train/unsup/48812_0.txt\n",
            "aclImdb/train/unsup/48811_0.txt\n",
            "aclImdb/train/unsup/48810_0.txt\n",
            "aclImdb/train/unsup/48809_0.txt\n",
            "aclImdb/train/unsup/48808_0.txt\n",
            "aclImdb/train/unsup/48807_0.txt\n",
            "aclImdb/train/unsup/48806_0.txt\n",
            "aclImdb/train/unsup/48805_0.txt\n",
            "aclImdb/train/unsup/48804_0.txt\n",
            "aclImdb/train/unsup/48803_0.txt\n",
            "aclImdb/train/unsup/48802_0.txt\n",
            "aclImdb/train/unsup/48801_0.txt\n",
            "aclImdb/train/unsup/48800_0.txt\n",
            "aclImdb/train/unsup/48799_0.txt\n",
            "aclImdb/train/unsup/48798_0.txt\n",
            "aclImdb/train/unsup/48797_0.txt\n",
            "aclImdb/train/unsup/48796_0.txt\n",
            "aclImdb/train/unsup/48795_0.txt\n",
            "aclImdb/train/unsup/48794_0.txt\n",
            "aclImdb/train/unsup/48793_0.txt\n",
            "aclImdb/train/unsup/48792_0.txt\n",
            "aclImdb/train/unsup/48791_0.txt\n",
            "aclImdb/train/unsup/48790_0.txt\n",
            "aclImdb/train/unsup/48789_0.txt\n",
            "aclImdb/train/unsup/48788_0.txt\n",
            "aclImdb/train/unsup/48787_0.txt\n",
            "aclImdb/train/unsup/48786_0.txt\n",
            "aclImdb/train/unsup/48785_0.txt\n",
            "aclImdb/train/unsup/48784_0.txt\n",
            "aclImdb/train/unsup/48783_0.txt\n",
            "aclImdb/train/unsup/48782_0.txt\n",
            "aclImdb/train/unsup/48781_0.txt\n",
            "aclImdb/train/unsup/48780_0.txt\n",
            "aclImdb/train/unsup/48779_0.txt\n",
            "aclImdb/train/unsup/48778_0.txt\n",
            "aclImdb/train/unsup/48777_0.txt\n",
            "aclImdb/train/unsup/48776_0.txt\n",
            "aclImdb/train/unsup/48775_0.txt\n",
            "aclImdb/train/unsup/48774_0.txt\n",
            "aclImdb/train/unsup/48773_0.txt\n",
            "aclImdb/train/unsup/48772_0.txt\n",
            "aclImdb/train/unsup/48771_0.txt\n",
            "aclImdb/train/unsup/48770_0.txt\n",
            "aclImdb/train/unsup/48769_0.txt\n",
            "aclImdb/train/unsup/48768_0.txt\n",
            "aclImdb/train/unsup/49023_0.txt\n",
            "aclImdb/train/unsup/49022_0.txt\n",
            "aclImdb/train/unsup/49021_0.txt\n",
            "aclImdb/train/unsup/49020_0.txt\n",
            "aclImdb/train/unsup/49019_0.txt\n",
            "aclImdb/train/unsup/49018_0.txt\n",
            "aclImdb/train/unsup/49017_0.txt\n",
            "aclImdb/train/unsup/49016_0.txt\n",
            "aclImdb/train/unsup/49015_0.txt\n",
            "aclImdb/train/unsup/49014_0.txt\n",
            "aclImdb/train/unsup/49013_0.txt\n",
            "aclImdb/train/unsup/49012_0.txt\n",
            "aclImdb/train/unsup/49011_0.txt\n",
            "aclImdb/train/unsup/49010_0.txt\n",
            "aclImdb/train/unsup/49009_0.txt\n",
            "aclImdb/train/unsup/49008_0.txt\n",
            "aclImdb/train/unsup/49007_0.txt\n",
            "aclImdb/train/unsup/49006_0.txt\n",
            "aclImdb/train/unsup/49005_0.txt\n",
            "aclImdb/train/unsup/49004_0.txt\n",
            "aclImdb/train/unsup/49003_0.txt\n",
            "aclImdb/train/unsup/49002_0.txt\n",
            "aclImdb/train/unsup/49001_0.txt\n",
            "aclImdb/train/unsup/49000_0.txt\n",
            "aclImdb/train/unsup/48999_0.txt\n",
            "aclImdb/train/unsup/48998_0.txt\n",
            "aclImdb/train/unsup/48997_0.txt\n",
            "aclImdb/train/unsup/48996_0.txt\n",
            "aclImdb/train/unsup/48995_0.txt\n",
            "aclImdb/train/unsup/48994_0.txt\n",
            "aclImdb/train/unsup/48993_0.txt\n",
            "aclImdb/train/unsup/48992_0.txt\n",
            "aclImdb/train/unsup/48991_0.txt\n",
            "aclImdb/train/unsup/48990_0.txt\n",
            "aclImdb/train/unsup/48989_0.txt\n",
            "aclImdb/train/unsup/48988_0.txt\n",
            "aclImdb/train/unsup/48987_0.txt\n",
            "aclImdb/train/unsup/48986_0.txt\n",
            "aclImdb/train/unsup/48985_0.txt\n",
            "aclImdb/train/unsup/48984_0.txt\n",
            "aclImdb/train/unsup/48983_0.txt\n",
            "aclImdb/train/unsup/48982_0.txt\n",
            "aclImdb/train/unsup/48981_0.txt\n",
            "aclImdb/train/unsup/48980_0.txt\n",
            "aclImdb/train/unsup/48979_0.txt\n",
            "aclImdb/train/unsup/48978_0.txt\n",
            "aclImdb/train/unsup/48977_0.txt\n",
            "aclImdb/train/unsup/48976_0.txt\n",
            "aclImdb/train/unsup/48975_0.txt\n",
            "aclImdb/train/unsup/48974_0.txt\n",
            "aclImdb/train/unsup/48973_0.txt\n",
            "aclImdb/train/unsup/48972_0.txt\n",
            "aclImdb/train/unsup/48971_0.txt\n",
            "aclImdb/train/unsup/48970_0.txt\n",
            "aclImdb/train/unsup/48969_0.txt\n",
            "aclImdb/train/unsup/48968_0.txt\n",
            "aclImdb/train/unsup/48967_0.txt\n",
            "aclImdb/train/unsup/48966_0.txt\n",
            "aclImdb/train/unsup/48965_0.txt\n",
            "aclImdb/train/unsup/48964_0.txt\n",
            "aclImdb/train/unsup/48963_0.txt\n",
            "aclImdb/train/unsup/48962_0.txt\n",
            "aclImdb/train/unsup/48961_0.txt\n",
            "aclImdb/train/unsup/48960_0.txt\n",
            "aclImdb/train/unsup/48959_0.txt\n",
            "aclImdb/train/unsup/48958_0.txt\n",
            "aclImdb/train/unsup/48957_0.txt\n",
            "aclImdb/train/unsup/48956_0.txt\n",
            "aclImdb/train/unsup/48955_0.txt\n",
            "aclImdb/train/unsup/48954_0.txt\n",
            "aclImdb/train/unsup/48953_0.txt\n",
            "aclImdb/train/unsup/48952_0.txt\n",
            "aclImdb/train/unsup/48951_0.txt\n",
            "aclImdb/train/unsup/48950_0.txt\n",
            "aclImdb/train/unsup/48949_0.txt\n",
            "aclImdb/train/unsup/48948_0.txt\n",
            "aclImdb/train/unsup/48947_0.txt\n",
            "aclImdb/train/unsup/48946_0.txt\n",
            "aclImdb/train/unsup/48945_0.txt\n",
            "aclImdb/train/unsup/48944_0.txt\n",
            "aclImdb/train/unsup/48943_0.txt\n",
            "aclImdb/train/unsup/48942_0.txt\n",
            "aclImdb/train/unsup/48941_0.txt\n",
            "aclImdb/train/unsup/48940_0.txt\n",
            "aclImdb/train/unsup/48939_0.txt\n",
            "aclImdb/train/unsup/48938_0.txt\n",
            "aclImdb/train/unsup/48937_0.txt\n",
            "aclImdb/train/unsup/48936_0.txt\n",
            "aclImdb/train/unsup/48935_0.txt\n",
            "aclImdb/train/unsup/48934_0.txt\n",
            "aclImdb/train/unsup/48933_0.txt\n",
            "aclImdb/train/unsup/48932_0.txt\n",
            "aclImdb/train/unsup/48931_0.txt\n",
            "aclImdb/train/unsup/48930_0.txt\n",
            "aclImdb/train/unsup/48929_0.txt\n",
            "aclImdb/train/unsup/48928_0.txt\n",
            "aclImdb/train/unsup/48927_0.txt\n",
            "aclImdb/train/unsup/48926_0.txt\n",
            "aclImdb/train/unsup/48925_0.txt\n",
            "aclImdb/train/unsup/48924_0.txt\n",
            "aclImdb/train/unsup/48923_0.txt\n",
            "aclImdb/train/unsup/48922_0.txt\n",
            "aclImdb/train/unsup/48921_0.txt\n",
            "aclImdb/train/unsup/48920_0.txt\n",
            "aclImdb/train/unsup/48919_0.txt\n",
            "aclImdb/train/unsup/48918_0.txt\n",
            "aclImdb/train/unsup/48917_0.txt\n",
            "aclImdb/train/unsup/48916_0.txt\n",
            "aclImdb/train/unsup/48915_0.txt\n",
            "aclImdb/train/unsup/48914_0.txt\n",
            "aclImdb/train/unsup/48913_0.txt\n",
            "aclImdb/train/unsup/48912_0.txt\n",
            "aclImdb/train/unsup/48911_0.txt\n",
            "aclImdb/train/unsup/48910_0.txt\n",
            "aclImdb/train/unsup/48909_0.txt\n",
            "aclImdb/train/unsup/48908_0.txt\n",
            "aclImdb/train/unsup/48907_0.txt\n",
            "aclImdb/train/unsup/48906_0.txt\n",
            "aclImdb/train/unsup/48905_0.txt\n",
            "aclImdb/train/unsup/48904_0.txt\n",
            "aclImdb/train/unsup/48903_0.txt\n",
            "aclImdb/train/unsup/48902_0.txt\n",
            "aclImdb/train/unsup/48901_0.txt\n",
            "aclImdb/train/unsup/48900_0.txt\n",
            "aclImdb/train/unsup/48899_0.txt\n",
            "aclImdb/train/unsup/48898_0.txt\n",
            "aclImdb/train/unsup/48897_0.txt\n",
            "aclImdb/train/unsup/48896_0.txt\n",
            "aclImdb/train/unsup/49151_0.txt\n",
            "aclImdb/train/unsup/49150_0.txt\n",
            "aclImdb/train/unsup/49149_0.txt\n",
            "aclImdb/train/unsup/49148_0.txt\n",
            "aclImdb/train/unsup/49147_0.txt\n",
            "aclImdb/train/unsup/49146_0.txt\n",
            "aclImdb/train/unsup/49145_0.txt\n",
            "aclImdb/train/unsup/49144_0.txt\n",
            "aclImdb/train/unsup/49143_0.txt\n",
            "aclImdb/train/unsup/49142_0.txt\n",
            "aclImdb/train/unsup/49141_0.txt\n",
            "aclImdb/train/unsup/49140_0.txt\n",
            "aclImdb/train/unsup/49139_0.txt\n",
            "aclImdb/train/unsup/49138_0.txt\n",
            "aclImdb/train/unsup/49137_0.txt\n",
            "aclImdb/train/unsup/49136_0.txt\n",
            "aclImdb/train/unsup/49135_0.txt\n",
            "aclImdb/train/unsup/49134_0.txt\n",
            "aclImdb/train/unsup/49133_0.txt\n",
            "aclImdb/train/unsup/49132_0.txt\n",
            "aclImdb/train/unsup/49131_0.txt\n",
            "aclImdb/train/unsup/49130_0.txt\n",
            "aclImdb/train/unsup/49129_0.txt\n",
            "aclImdb/train/unsup/49128_0.txt\n",
            "aclImdb/train/unsup/49127_0.txt\n",
            "aclImdb/train/unsup/49126_0.txt\n",
            "aclImdb/train/unsup/49125_0.txt\n",
            "aclImdb/train/unsup/49124_0.txt\n",
            "aclImdb/train/unsup/49123_0.txt\n",
            "aclImdb/train/unsup/49122_0.txt\n",
            "aclImdb/train/unsup/49121_0.txt\n",
            "aclImdb/train/unsup/49120_0.txt\n",
            "aclImdb/train/unsup/49119_0.txt\n",
            "aclImdb/train/unsup/49118_0.txt\n",
            "aclImdb/train/unsup/49117_0.txt\n",
            "aclImdb/train/unsup/49116_0.txt\n",
            "aclImdb/train/unsup/49115_0.txt\n",
            "aclImdb/train/unsup/49114_0.txt\n",
            "aclImdb/train/unsup/49113_0.txt\n",
            "aclImdb/train/unsup/49112_0.txt\n",
            "aclImdb/train/unsup/49111_0.txt\n",
            "aclImdb/train/unsup/49110_0.txt\n",
            "aclImdb/train/unsup/49109_0.txt\n",
            "aclImdb/train/unsup/49108_0.txt\n",
            "aclImdb/train/unsup/49107_0.txt\n",
            "aclImdb/train/unsup/49106_0.txt\n",
            "aclImdb/train/unsup/49105_0.txt\n",
            "aclImdb/train/unsup/49104_0.txt\n",
            "aclImdb/train/unsup/49103_0.txt\n",
            "aclImdb/train/unsup/49102_0.txt\n",
            "aclImdb/train/unsup/49101_0.txt\n",
            "aclImdb/train/unsup/49100_0.txt\n",
            "aclImdb/train/unsup/49099_0.txt\n",
            "aclImdb/train/unsup/49098_0.txt\n",
            "aclImdb/train/unsup/49097_0.txt\n",
            "aclImdb/train/unsup/49096_0.txt\n",
            "aclImdb/train/unsup/49095_0.txt\n",
            "aclImdb/train/unsup/49094_0.txt\n",
            "aclImdb/train/unsup/49093_0.txt\n",
            "aclImdb/train/unsup/49092_0.txt\n",
            "aclImdb/train/unsup/49091_0.txt\n",
            "aclImdb/train/unsup/49090_0.txt\n",
            "aclImdb/train/unsup/49089_0.txt\n",
            "aclImdb/train/unsup/49088_0.txt\n",
            "aclImdb/train/unsup/49087_0.txt\n",
            "aclImdb/train/unsup/49086_0.txt\n",
            "aclImdb/train/unsup/49085_0.txt\n",
            "aclImdb/train/unsup/49084_0.txt\n",
            "aclImdb/train/unsup/49083_0.txt\n",
            "aclImdb/train/unsup/49082_0.txt\n",
            "aclImdb/train/unsup/49081_0.txt\n",
            "aclImdb/train/unsup/49080_0.txt\n",
            "aclImdb/train/unsup/49079_0.txt\n",
            "aclImdb/train/unsup/49078_0.txt\n",
            "aclImdb/train/unsup/49077_0.txt\n",
            "aclImdb/train/unsup/49076_0.txt\n",
            "aclImdb/train/unsup/49075_0.txt\n",
            "aclImdb/train/unsup/49074_0.txt\n",
            "aclImdb/train/unsup/49073_0.txt\n",
            "aclImdb/train/unsup/49072_0.txt\n",
            "aclImdb/train/unsup/49071_0.txt\n",
            "aclImdb/train/unsup/49070_0.txt\n",
            "aclImdb/train/unsup/49069_0.txt\n",
            "aclImdb/train/unsup/49068_0.txt\n",
            "aclImdb/train/unsup/49067_0.txt\n",
            "aclImdb/train/unsup/49066_0.txt\n",
            "aclImdb/train/unsup/49065_0.txt\n",
            "aclImdb/train/unsup/49064_0.txt\n",
            "aclImdb/train/unsup/49063_0.txt\n",
            "aclImdb/train/unsup/49062_0.txt\n",
            "aclImdb/train/unsup/49061_0.txt\n",
            "aclImdb/train/unsup/49060_0.txt\n",
            "aclImdb/train/unsup/49059_0.txt\n",
            "aclImdb/train/unsup/49058_0.txt\n",
            "aclImdb/train/unsup/49057_0.txt\n",
            "aclImdb/train/unsup/49056_0.txt\n",
            "aclImdb/train/unsup/49055_0.txt\n",
            "aclImdb/train/unsup/49054_0.txt\n",
            "aclImdb/train/unsup/49053_0.txt\n",
            "aclImdb/train/unsup/49052_0.txt\n",
            "aclImdb/train/unsup/49051_0.txt\n",
            "aclImdb/train/unsup/49050_0.txt\n",
            "aclImdb/train/unsup/49049_0.txt\n",
            "aclImdb/train/unsup/49048_0.txt\n",
            "aclImdb/train/unsup/49047_0.txt\n",
            "aclImdb/train/unsup/49046_0.txt\n",
            "aclImdb/train/unsup/49045_0.txt\n",
            "aclImdb/train/unsup/49044_0.txt\n",
            "aclImdb/train/unsup/49043_0.txt\n",
            "aclImdb/train/unsup/49042_0.txt\n",
            "aclImdb/train/unsup/49041_0.txt\n",
            "aclImdb/train/unsup/49040_0.txt\n",
            "aclImdb/train/unsup/49039_0.txt\n",
            "aclImdb/train/unsup/49038_0.txt\n",
            "aclImdb/train/unsup/49037_0.txt\n",
            "aclImdb/train/unsup/49036_0.txt\n",
            "aclImdb/train/unsup/49035_0.txt\n",
            "aclImdb/train/unsup/49034_0.txt\n",
            "aclImdb/train/unsup/49033_0.txt\n",
            "aclImdb/train/unsup/49032_0.txt\n",
            "aclImdb/train/unsup/49031_0.txt\n",
            "aclImdb/train/unsup/49030_0.txt\n",
            "aclImdb/train/unsup/49029_0.txt\n",
            "aclImdb/train/unsup/49028_0.txt\n",
            "aclImdb/train/unsup/49027_0.txt\n",
            "aclImdb/train/unsup/49026_0.txt\n",
            "aclImdb/train/unsup/49025_0.txt\n",
            "aclImdb/train/unsup/49024_0.txt\n",
            "aclImdb/train/unsup/49279_0.txt\n",
            "aclImdb/train/unsup/49278_0.txt\n",
            "aclImdb/train/unsup/49277_0.txt\n",
            "aclImdb/train/unsup/49276_0.txt\n",
            "aclImdb/train/unsup/49275_0.txt\n",
            "aclImdb/train/unsup/49274_0.txt\n",
            "aclImdb/train/unsup/49273_0.txt\n",
            "aclImdb/train/unsup/49272_0.txt\n",
            "aclImdb/train/unsup/49271_0.txt\n",
            "aclImdb/train/unsup/49270_0.txt\n",
            "aclImdb/train/unsup/49269_0.txt\n",
            "aclImdb/train/unsup/49268_0.txt\n",
            "aclImdb/train/unsup/49267_0.txt\n",
            "aclImdb/train/unsup/49266_0.txt\n",
            "aclImdb/train/unsup/49265_0.txt\n",
            "aclImdb/train/unsup/49264_0.txt\n",
            "aclImdb/train/unsup/49263_0.txt\n",
            "aclImdb/train/unsup/49262_0.txt\n",
            "aclImdb/train/unsup/49261_0.txt\n",
            "aclImdb/train/unsup/49260_0.txt\n",
            "aclImdb/train/unsup/49259_0.txt\n",
            "aclImdb/train/unsup/49258_0.txt\n",
            "aclImdb/train/unsup/49257_0.txt\n",
            "aclImdb/train/unsup/49256_0.txt\n",
            "aclImdb/train/unsup/49255_0.txt\n",
            "aclImdb/train/unsup/49254_0.txt\n",
            "aclImdb/train/unsup/49253_0.txt\n",
            "aclImdb/train/unsup/49252_0.txt\n",
            "aclImdb/train/unsup/49251_0.txt\n",
            "aclImdb/train/unsup/49250_0.txt\n",
            "aclImdb/train/unsup/49249_0.txt\n",
            "aclImdb/train/unsup/49248_0.txt\n",
            "aclImdb/train/unsup/49247_0.txt\n",
            "aclImdb/train/unsup/49246_0.txt\n",
            "aclImdb/train/unsup/49245_0.txt\n",
            "aclImdb/train/unsup/49244_0.txt\n",
            "aclImdb/train/unsup/49243_0.txt\n",
            "aclImdb/train/unsup/49242_0.txt\n",
            "aclImdb/train/unsup/49241_0.txt\n",
            "aclImdb/train/unsup/49240_0.txt\n",
            "aclImdb/train/unsup/49239_0.txt\n",
            "aclImdb/train/unsup/49238_0.txt\n",
            "aclImdb/train/unsup/49237_0.txt\n",
            "aclImdb/train/unsup/49236_0.txt\n",
            "aclImdb/train/unsup/49235_0.txt\n",
            "aclImdb/train/unsup/49234_0.txt\n",
            "aclImdb/train/unsup/49233_0.txt\n",
            "aclImdb/train/unsup/49232_0.txt\n",
            "aclImdb/train/unsup/49231_0.txt\n",
            "aclImdb/train/unsup/49230_0.txt\n",
            "aclImdb/train/unsup/49229_0.txt\n",
            "aclImdb/train/unsup/49228_0.txt\n",
            "aclImdb/train/unsup/49227_0.txt\n",
            "aclImdb/train/unsup/49226_0.txt\n",
            "aclImdb/train/unsup/49225_0.txt\n",
            "aclImdb/train/unsup/49224_0.txt\n",
            "aclImdb/train/unsup/49223_0.txt\n",
            "aclImdb/train/unsup/49222_0.txt\n",
            "aclImdb/train/unsup/49221_0.txt\n",
            "aclImdb/train/unsup/49220_0.txt\n",
            "aclImdb/train/unsup/49219_0.txt\n",
            "aclImdb/train/unsup/49218_0.txt\n",
            "aclImdb/train/unsup/49217_0.txt\n",
            "aclImdb/train/unsup/49216_0.txt\n",
            "aclImdb/train/unsup/49215_0.txt\n",
            "aclImdb/train/unsup/49214_0.txt\n",
            "aclImdb/train/unsup/49213_0.txt\n",
            "aclImdb/train/unsup/49212_0.txt\n",
            "aclImdb/train/unsup/49211_0.txt\n",
            "aclImdb/train/unsup/49210_0.txt\n",
            "aclImdb/train/unsup/49209_0.txt\n",
            "aclImdb/train/unsup/49208_0.txt\n",
            "aclImdb/train/unsup/49207_0.txt\n",
            "aclImdb/train/unsup/49206_0.txt\n",
            "aclImdb/train/unsup/49205_0.txt\n",
            "aclImdb/train/unsup/49204_0.txt\n",
            "aclImdb/train/unsup/49203_0.txt\n",
            "aclImdb/train/unsup/49202_0.txt\n",
            "aclImdb/train/unsup/49201_0.txt\n",
            "aclImdb/train/unsup/49200_0.txt\n",
            "aclImdb/train/unsup/49199_0.txt\n",
            "aclImdb/train/unsup/49198_0.txt\n",
            "aclImdb/train/unsup/49197_0.txt\n",
            "aclImdb/train/unsup/49196_0.txt\n",
            "aclImdb/train/unsup/49195_0.txt\n",
            "aclImdb/train/unsup/49194_0.txt\n",
            "aclImdb/train/unsup/49193_0.txt\n",
            "aclImdb/train/unsup/49192_0.txt\n",
            "aclImdb/train/unsup/49191_0.txt\n",
            "aclImdb/train/unsup/49190_0.txt\n",
            "aclImdb/train/unsup/49189_0.txt\n",
            "aclImdb/train/unsup/49188_0.txt\n",
            "aclImdb/train/unsup/49187_0.txt\n",
            "aclImdb/train/unsup/49186_0.txt\n",
            "aclImdb/train/unsup/49185_0.txt\n",
            "aclImdb/train/unsup/49184_0.txt\n",
            "aclImdb/train/unsup/49183_0.txt\n",
            "aclImdb/train/unsup/49182_0.txt\n",
            "aclImdb/train/unsup/49181_0.txt\n",
            "aclImdb/train/unsup/49180_0.txt\n",
            "aclImdb/train/unsup/49179_0.txt\n",
            "aclImdb/train/unsup/49178_0.txt\n",
            "aclImdb/train/unsup/49177_0.txt\n",
            "aclImdb/train/unsup/49176_0.txt\n",
            "aclImdb/train/unsup/49175_0.txt\n",
            "aclImdb/train/unsup/49174_0.txt\n",
            "aclImdb/train/unsup/49173_0.txt\n",
            "aclImdb/train/unsup/49172_0.txt\n",
            "aclImdb/train/unsup/49171_0.txt\n",
            "aclImdb/train/unsup/49170_0.txt\n",
            "aclImdb/train/unsup/49169_0.txt\n",
            "aclImdb/train/unsup/49168_0.txt\n",
            "aclImdb/train/unsup/49167_0.txt\n",
            "aclImdb/train/unsup/49166_0.txt\n",
            "aclImdb/train/unsup/49165_0.txt\n",
            "aclImdb/train/unsup/49164_0.txt\n",
            "aclImdb/train/unsup/49163_0.txt\n",
            "aclImdb/train/unsup/49162_0.txt\n",
            "aclImdb/train/unsup/49161_0.txt\n",
            "aclImdb/train/unsup/49160_0.txt\n",
            "aclImdb/train/unsup/49159_0.txt\n",
            "aclImdb/train/unsup/49158_0.txt\n",
            "aclImdb/train/unsup/49157_0.txt\n",
            "aclImdb/train/unsup/49156_0.txt\n",
            "aclImdb/train/unsup/49155_0.txt\n",
            "aclImdb/train/unsup/49154_0.txt\n",
            "aclImdb/train/unsup/49153_0.txt\n",
            "aclImdb/train/unsup/49152_0.txt\n",
            "aclImdb/train/unsup/49407_0.txt\n",
            "aclImdb/train/unsup/49406_0.txt\n",
            "aclImdb/train/unsup/49405_0.txt\n",
            "aclImdb/train/unsup/49404_0.txt\n",
            "aclImdb/train/unsup/49403_0.txt\n",
            "aclImdb/train/unsup/49402_0.txt\n",
            "aclImdb/train/unsup/49401_0.txt\n",
            "aclImdb/train/unsup/49400_0.txt\n",
            "aclImdb/train/unsup/49399_0.txt\n",
            "aclImdb/train/unsup/49398_0.txt\n",
            "aclImdb/train/unsup/49397_0.txt\n",
            "aclImdb/train/unsup/49396_0.txt\n",
            "aclImdb/train/unsup/49395_0.txt\n",
            "aclImdb/train/unsup/49394_0.txt\n",
            "aclImdb/train/unsup/49393_0.txt\n",
            "aclImdb/train/unsup/49392_0.txt\n",
            "aclImdb/train/unsup/49391_0.txt\n",
            "aclImdb/train/unsup/49390_0.txt\n",
            "aclImdb/train/unsup/49389_0.txt\n",
            "aclImdb/train/unsup/49388_0.txt\n",
            "aclImdb/train/unsup/49387_0.txt\n",
            "aclImdb/train/unsup/49386_0.txt\n",
            "aclImdb/train/unsup/49385_0.txt\n",
            "aclImdb/train/unsup/49384_0.txt\n",
            "aclImdb/train/unsup/49383_0.txt\n",
            "aclImdb/train/unsup/49382_0.txt\n",
            "aclImdb/train/unsup/49381_0.txt\n",
            "aclImdb/train/unsup/49380_0.txt\n",
            "aclImdb/train/unsup/49379_0.txt\n",
            "aclImdb/train/unsup/49378_0.txt\n",
            "aclImdb/train/unsup/49377_0.txt\n",
            "aclImdb/train/unsup/49376_0.txt\n",
            "aclImdb/train/unsup/49375_0.txt\n",
            "aclImdb/train/unsup/49374_0.txt\n",
            "aclImdb/train/unsup/49373_0.txt\n",
            "aclImdb/train/unsup/49372_0.txt\n",
            "aclImdb/train/unsup/49371_0.txt\n",
            "aclImdb/train/unsup/49370_0.txt\n",
            "aclImdb/train/unsup/49369_0.txt\n",
            "aclImdb/train/unsup/49368_0.txt\n",
            "aclImdb/train/unsup/49367_0.txt\n",
            "aclImdb/train/unsup/49366_0.txt\n",
            "aclImdb/train/unsup/49365_0.txt\n",
            "aclImdb/train/unsup/49364_0.txt\n",
            "aclImdb/train/unsup/49363_0.txt\n",
            "aclImdb/train/unsup/49362_0.txt\n",
            "aclImdb/train/unsup/49361_0.txt\n",
            "aclImdb/train/unsup/49360_0.txt\n",
            "aclImdb/train/unsup/49359_0.txt\n",
            "aclImdb/train/unsup/49358_0.txt\n",
            "aclImdb/train/unsup/49357_0.txt\n",
            "aclImdb/train/unsup/49356_0.txt\n",
            "aclImdb/train/unsup/49355_0.txt\n",
            "aclImdb/train/unsup/49354_0.txt\n",
            "aclImdb/train/unsup/49353_0.txt\n",
            "aclImdb/train/unsup/49352_0.txt\n",
            "aclImdb/train/unsup/49351_0.txt\n",
            "aclImdb/train/unsup/49350_0.txt\n",
            "aclImdb/train/unsup/49349_0.txt\n",
            "aclImdb/train/unsup/49348_0.txt\n",
            "aclImdb/train/unsup/49347_0.txt\n",
            "aclImdb/train/unsup/49346_0.txt\n",
            "aclImdb/train/unsup/49345_0.txt\n",
            "aclImdb/train/unsup/49344_0.txt\n",
            "aclImdb/train/unsup/49343_0.txt\n",
            "aclImdb/train/unsup/49342_0.txt\n",
            "aclImdb/train/unsup/49341_0.txt\n",
            "aclImdb/train/unsup/49340_0.txt\n",
            "aclImdb/train/unsup/49339_0.txt\n",
            "aclImdb/train/unsup/49338_0.txt\n",
            "aclImdb/train/unsup/49337_0.txt\n",
            "aclImdb/train/unsup/49336_0.txt\n",
            "aclImdb/train/unsup/49335_0.txt\n",
            "aclImdb/train/unsup/49334_0.txt\n",
            "aclImdb/train/unsup/49333_0.txt\n",
            "aclImdb/train/unsup/49332_0.txt\n",
            "aclImdb/train/unsup/49331_0.txt\n",
            "aclImdb/train/unsup/49330_0.txt\n",
            "aclImdb/train/unsup/49329_0.txt\n",
            "aclImdb/train/unsup/49328_0.txt\n",
            "aclImdb/train/unsup/49327_0.txt\n",
            "aclImdb/train/unsup/49326_0.txt\n",
            "aclImdb/train/unsup/49325_0.txt\n",
            "aclImdb/train/unsup/49324_0.txt\n",
            "aclImdb/train/unsup/49323_0.txt\n",
            "aclImdb/train/unsup/49322_0.txt\n",
            "aclImdb/train/unsup/49321_0.txt\n",
            "aclImdb/train/unsup/49320_0.txt\n",
            "aclImdb/train/unsup/49319_0.txt\n",
            "aclImdb/train/unsup/49318_0.txt\n",
            "aclImdb/train/unsup/49317_0.txt\n",
            "aclImdb/train/unsup/49316_0.txt\n",
            "aclImdb/train/unsup/49315_0.txt\n",
            "aclImdb/train/unsup/49314_0.txt\n",
            "aclImdb/train/unsup/49313_0.txt\n",
            "aclImdb/train/unsup/49312_0.txt\n",
            "aclImdb/train/unsup/49311_0.txt\n",
            "aclImdb/train/unsup/49310_0.txt\n",
            "aclImdb/train/unsup/49309_0.txt\n",
            "aclImdb/train/unsup/49308_0.txt\n",
            "aclImdb/train/unsup/49307_0.txt\n",
            "aclImdb/train/unsup/49306_0.txt\n",
            "aclImdb/train/unsup/49305_0.txt\n",
            "aclImdb/train/unsup/49304_0.txt\n",
            "aclImdb/train/unsup/49303_0.txt\n",
            "aclImdb/train/unsup/49302_0.txt\n",
            "aclImdb/train/unsup/49301_0.txt\n",
            "aclImdb/train/unsup/49300_0.txt\n",
            "aclImdb/train/unsup/49299_0.txt\n",
            "aclImdb/train/unsup/49298_0.txt\n",
            "aclImdb/train/unsup/49297_0.txt\n",
            "aclImdb/train/unsup/49296_0.txt\n",
            "aclImdb/train/unsup/49295_0.txt\n",
            "aclImdb/train/unsup/49294_0.txt\n",
            "aclImdb/train/unsup/49293_0.txt\n",
            "aclImdb/train/unsup/49292_0.txt\n",
            "aclImdb/train/unsup/49291_0.txt\n",
            "aclImdb/train/unsup/49290_0.txt\n",
            "aclImdb/train/unsup/49289_0.txt\n",
            "aclImdb/train/unsup/49288_0.txt\n",
            "aclImdb/train/unsup/49287_0.txt\n",
            "aclImdb/train/unsup/49286_0.txt\n",
            "aclImdb/train/unsup/49285_0.txt\n",
            "aclImdb/train/unsup/49284_0.txt\n",
            "aclImdb/train/unsup/49283_0.txt\n",
            "aclImdb/train/unsup/49282_0.txt\n",
            "aclImdb/train/unsup/49281_0.txt\n",
            "aclImdb/train/unsup/49280_0.txt\n",
            "aclImdb/train/unsup/49535_0.txt\n",
            "aclImdb/train/unsup/49534_0.txt\n",
            "aclImdb/train/unsup/49533_0.txt\n",
            "aclImdb/train/unsup/49532_0.txt\n",
            "aclImdb/train/unsup/49531_0.txt\n",
            "aclImdb/train/unsup/49530_0.txt\n",
            "aclImdb/train/unsup/49529_0.txt\n",
            "aclImdb/train/unsup/49528_0.txt\n",
            "aclImdb/train/unsup/49527_0.txt\n",
            "aclImdb/train/unsup/49526_0.txt\n",
            "aclImdb/train/unsup/49525_0.txt\n",
            "aclImdb/train/unsup/49524_0.txt\n",
            "aclImdb/train/unsup/49523_0.txt\n",
            "aclImdb/train/unsup/49522_0.txt\n",
            "aclImdb/train/unsup/49521_0.txt\n",
            "aclImdb/train/unsup/49520_0.txt\n",
            "aclImdb/train/unsup/49519_0.txt\n",
            "aclImdb/train/unsup/49518_0.txt\n",
            "aclImdb/train/unsup/49517_0.txt\n",
            "aclImdb/train/unsup/49516_0.txt\n",
            "aclImdb/train/unsup/49515_0.txt\n",
            "aclImdb/train/unsup/49514_0.txt\n",
            "aclImdb/train/unsup/49513_0.txt\n",
            "aclImdb/train/unsup/49512_0.txt\n",
            "aclImdb/train/unsup/49511_0.txt\n",
            "aclImdb/train/unsup/49510_0.txt\n",
            "aclImdb/train/unsup/49509_0.txt\n",
            "aclImdb/train/unsup/49508_0.txt\n",
            "aclImdb/train/unsup/49507_0.txt\n",
            "aclImdb/train/unsup/49506_0.txt\n",
            "aclImdb/train/unsup/49505_0.txt\n",
            "aclImdb/train/unsup/49504_0.txt\n",
            "aclImdb/train/unsup/49503_0.txt\n",
            "aclImdb/train/unsup/49502_0.txt\n",
            "aclImdb/train/unsup/49501_0.txt\n",
            "aclImdb/train/unsup/49500_0.txt\n",
            "aclImdb/train/unsup/49499_0.txt\n",
            "aclImdb/train/unsup/49498_0.txt\n",
            "aclImdb/train/unsup/49497_0.txt\n",
            "aclImdb/train/unsup/49496_0.txt\n",
            "aclImdb/train/unsup/49495_0.txt\n",
            "aclImdb/train/unsup/49494_0.txt\n",
            "aclImdb/train/unsup/49493_0.txt\n",
            "aclImdb/train/unsup/49492_0.txt\n",
            "aclImdb/train/unsup/49491_0.txt\n",
            "aclImdb/train/unsup/49490_0.txt\n",
            "aclImdb/train/unsup/49489_0.txt\n",
            "aclImdb/train/unsup/49488_0.txt\n",
            "aclImdb/train/unsup/49487_0.txt\n",
            "aclImdb/train/unsup/49486_0.txt\n",
            "aclImdb/train/unsup/49485_0.txt\n",
            "aclImdb/train/unsup/49484_0.txt\n",
            "aclImdb/train/unsup/49483_0.txt\n",
            "aclImdb/train/unsup/49482_0.txt\n",
            "aclImdb/train/unsup/49481_0.txt\n",
            "aclImdb/train/unsup/49480_0.txt\n",
            "aclImdb/train/unsup/49479_0.txt\n",
            "aclImdb/train/unsup/49478_0.txt\n",
            "aclImdb/train/unsup/49477_0.txt\n",
            "aclImdb/train/unsup/49476_0.txt\n",
            "aclImdb/train/unsup/49475_0.txt\n",
            "aclImdb/train/unsup/49474_0.txt\n",
            "aclImdb/train/unsup/49473_0.txt\n",
            "aclImdb/train/unsup/49472_0.txt\n",
            "aclImdb/train/unsup/49471_0.txt\n",
            "aclImdb/train/unsup/49470_0.txt\n",
            "aclImdb/train/unsup/49469_0.txt\n",
            "aclImdb/train/unsup/49468_0.txt\n",
            "aclImdb/train/unsup/49467_0.txt\n",
            "aclImdb/train/unsup/49466_0.txt\n",
            "aclImdb/train/unsup/49465_0.txt\n",
            "aclImdb/train/unsup/49464_0.txt\n",
            "aclImdb/train/unsup/49463_0.txt\n",
            "aclImdb/train/unsup/49462_0.txt\n",
            "aclImdb/train/unsup/49461_0.txt\n",
            "aclImdb/train/unsup/49460_0.txt\n",
            "aclImdb/train/unsup/49459_0.txt\n",
            "aclImdb/train/unsup/49458_0.txt\n",
            "aclImdb/train/unsup/49457_0.txt\n",
            "aclImdb/train/unsup/49456_0.txt\n",
            "aclImdb/train/unsup/49455_0.txt\n",
            "aclImdb/train/unsup/49454_0.txt\n",
            "aclImdb/train/unsup/49453_0.txt\n",
            "aclImdb/train/unsup/49452_0.txt\n",
            "aclImdb/train/unsup/49451_0.txt\n",
            "aclImdb/train/unsup/49450_0.txt\n",
            "aclImdb/train/unsup/49449_0.txt\n",
            "aclImdb/train/unsup/49448_0.txt\n",
            "aclImdb/train/unsup/49447_0.txt\n",
            "aclImdb/train/unsup/49446_0.txt\n",
            "aclImdb/train/unsup/49445_0.txt\n",
            "aclImdb/train/unsup/49444_0.txt\n",
            "aclImdb/train/unsup/49443_0.txt\n",
            "aclImdb/train/unsup/49442_0.txt\n",
            "aclImdb/train/unsup/49441_0.txt\n",
            "aclImdb/train/unsup/49440_0.txt\n",
            "aclImdb/train/unsup/49439_0.txt\n",
            "aclImdb/train/unsup/49438_0.txt\n",
            "aclImdb/train/unsup/49437_0.txt\n",
            "aclImdb/train/unsup/49436_0.txt\n",
            "aclImdb/train/unsup/49435_0.txt\n",
            "aclImdb/train/unsup/49434_0.txt\n",
            "aclImdb/train/unsup/49433_0.txt\n",
            "aclImdb/train/unsup/49432_0.txt\n",
            "aclImdb/train/unsup/49431_0.txt\n",
            "aclImdb/train/unsup/49430_0.txt\n",
            "aclImdb/train/unsup/49429_0.txt\n",
            "aclImdb/train/unsup/49428_0.txt\n",
            "aclImdb/train/unsup/49427_0.txt\n",
            "aclImdb/train/unsup/49426_0.txt\n",
            "aclImdb/train/unsup/49425_0.txt\n",
            "aclImdb/train/unsup/49424_0.txt\n",
            "aclImdb/train/unsup/49423_0.txt\n",
            "aclImdb/train/unsup/49422_0.txt\n",
            "aclImdb/train/unsup/49421_0.txt\n",
            "aclImdb/train/unsup/49420_0.txt\n",
            "aclImdb/train/unsup/49419_0.txt\n",
            "aclImdb/train/unsup/49418_0.txt\n",
            "aclImdb/train/unsup/49417_0.txt\n",
            "aclImdb/train/unsup/49416_0.txt\n",
            "aclImdb/train/unsup/49415_0.txt\n",
            "aclImdb/train/unsup/49414_0.txt\n",
            "aclImdb/train/unsup/49413_0.txt\n",
            "aclImdb/train/unsup/49412_0.txt\n",
            "aclImdb/train/unsup/49411_0.txt\n",
            "aclImdb/train/unsup/49410_0.txt\n",
            "aclImdb/train/unsup/49409_0.txt\n",
            "aclImdb/train/unsup/49408_0.txt\n",
            "aclImdb/train/unsup/49663_0.txt\n",
            "aclImdb/train/unsup/49662_0.txt\n",
            "aclImdb/train/unsup/49661_0.txt\n",
            "aclImdb/train/unsup/49660_0.txt\n",
            "aclImdb/train/unsup/49659_0.txt\n",
            "aclImdb/train/unsup/49658_0.txt\n",
            "aclImdb/train/unsup/49657_0.txt\n",
            "aclImdb/train/unsup/49656_0.txt\n",
            "aclImdb/train/unsup/49655_0.txt\n",
            "aclImdb/train/unsup/49654_0.txt\n",
            "aclImdb/train/unsup/49653_0.txt\n",
            "aclImdb/train/unsup/49652_0.txt\n",
            "aclImdb/train/unsup/49651_0.txt\n",
            "aclImdb/train/unsup/49650_0.txt\n",
            "aclImdb/train/unsup/49649_0.txt\n",
            "aclImdb/train/unsup/49648_0.txt\n",
            "aclImdb/train/unsup/49647_0.txt\n",
            "aclImdb/train/unsup/49646_0.txt\n",
            "aclImdb/train/unsup/49645_0.txt\n",
            "aclImdb/train/unsup/49644_0.txt\n",
            "aclImdb/train/unsup/49643_0.txt\n",
            "aclImdb/train/unsup/49642_0.txt\n",
            "aclImdb/train/unsup/49641_0.txt\n",
            "aclImdb/train/unsup/49640_0.txt\n",
            "aclImdb/train/unsup/49639_0.txt\n",
            "aclImdb/train/unsup/49638_0.txt\n",
            "aclImdb/train/unsup/49637_0.txt\n",
            "aclImdb/train/unsup/49636_0.txt\n",
            "aclImdb/train/unsup/49635_0.txt\n",
            "aclImdb/train/unsup/49634_0.txt\n",
            "aclImdb/train/unsup/49633_0.txt\n",
            "aclImdb/train/unsup/49632_0.txt\n",
            "aclImdb/train/unsup/49631_0.txt\n",
            "aclImdb/train/unsup/49630_0.txt\n",
            "aclImdb/train/unsup/49629_0.txt\n",
            "aclImdb/train/unsup/49628_0.txt\n",
            "aclImdb/train/unsup/49627_0.txt\n",
            "aclImdb/train/unsup/49626_0.txt\n",
            "aclImdb/train/unsup/49625_0.txt\n",
            "aclImdb/train/unsup/49624_0.txt\n",
            "aclImdb/train/unsup/49623_0.txt\n",
            "aclImdb/train/unsup/49622_0.txt\n",
            "aclImdb/train/unsup/49621_0.txt\n",
            "aclImdb/train/unsup/49620_0.txt\n",
            "aclImdb/train/unsup/49619_0.txt\n",
            "aclImdb/train/unsup/49618_0.txt\n",
            "aclImdb/train/unsup/49617_0.txt\n",
            "aclImdb/train/unsup/49616_0.txt\n",
            "aclImdb/train/unsup/49615_0.txt\n",
            "aclImdb/train/unsup/49614_0.txt\n",
            "aclImdb/train/unsup/49613_0.txt\n",
            "aclImdb/train/unsup/49612_0.txt\n",
            "aclImdb/train/unsup/49611_0.txt\n",
            "aclImdb/train/unsup/49610_0.txt\n",
            "aclImdb/train/unsup/49609_0.txt\n",
            "aclImdb/train/unsup/49608_0.txt\n",
            "aclImdb/train/unsup/49607_0.txt\n",
            "aclImdb/train/unsup/49606_0.txt\n",
            "aclImdb/train/unsup/49605_0.txt\n",
            "aclImdb/train/unsup/49604_0.txt\n",
            "aclImdb/train/unsup/49603_0.txt\n",
            "aclImdb/train/unsup/49602_0.txt\n",
            "aclImdb/train/unsup/49601_0.txt\n",
            "aclImdb/train/unsup/49600_0.txt\n",
            "aclImdb/train/unsup/49599_0.txt\n",
            "aclImdb/train/unsup/49598_0.txt\n",
            "aclImdb/train/unsup/49597_0.txt\n",
            "aclImdb/train/unsup/49596_0.txt\n",
            "aclImdb/train/unsup/49595_0.txt\n",
            "aclImdb/train/unsup/49594_0.txt\n",
            "aclImdb/train/unsup/49593_0.txt\n",
            "aclImdb/train/unsup/49592_0.txt\n",
            "aclImdb/train/unsup/49591_0.txt\n",
            "aclImdb/train/unsup/49590_0.txt\n",
            "aclImdb/train/unsup/49589_0.txt\n",
            "aclImdb/train/unsup/49588_0.txt\n",
            "aclImdb/train/unsup/49587_0.txt\n",
            "aclImdb/train/unsup/49586_0.txt\n",
            "aclImdb/train/unsup/49585_0.txt\n",
            "aclImdb/train/unsup/49584_0.txt\n",
            "aclImdb/train/unsup/49583_0.txt\n",
            "aclImdb/train/unsup/49582_0.txt\n",
            "aclImdb/train/unsup/49581_0.txt\n",
            "aclImdb/train/unsup/49580_0.txt\n",
            "aclImdb/train/unsup/49579_0.txt\n",
            "aclImdb/train/unsup/49578_0.txt\n",
            "aclImdb/train/unsup/49577_0.txt\n",
            "aclImdb/train/unsup/49576_0.txt\n",
            "aclImdb/train/unsup/49575_0.txt\n",
            "aclImdb/train/unsup/49574_0.txt\n",
            "aclImdb/train/unsup/49573_0.txt\n",
            "aclImdb/train/unsup/49572_0.txt\n",
            "aclImdb/train/unsup/49571_0.txt\n",
            "aclImdb/train/unsup/49570_0.txt\n",
            "aclImdb/train/unsup/49569_0.txt\n",
            "aclImdb/train/unsup/49568_0.txt\n",
            "aclImdb/train/unsup/49567_0.txt\n",
            "aclImdb/train/unsup/49566_0.txt\n",
            "aclImdb/train/unsup/49565_0.txt\n",
            "aclImdb/train/unsup/49564_0.txt\n",
            "aclImdb/train/unsup/49563_0.txt\n",
            "aclImdb/train/unsup/49562_0.txt\n",
            "aclImdb/train/unsup/49561_0.txt\n",
            "aclImdb/train/unsup/49560_0.txt\n",
            "aclImdb/train/unsup/49559_0.txt\n",
            "aclImdb/train/unsup/49558_0.txt\n",
            "aclImdb/train/unsup/49557_0.txt\n",
            "aclImdb/train/unsup/49556_0.txt\n",
            "aclImdb/train/unsup/49555_0.txt\n",
            "aclImdb/train/unsup/49554_0.txt\n",
            "aclImdb/train/unsup/49553_0.txt\n",
            "aclImdb/train/unsup/49552_0.txt\n",
            "aclImdb/train/unsup/49551_0.txt\n",
            "aclImdb/train/unsup/49550_0.txt\n",
            "aclImdb/train/unsup/49549_0.txt\n",
            "aclImdb/train/unsup/49548_0.txt\n",
            "aclImdb/train/unsup/49547_0.txt\n",
            "aclImdb/train/unsup/49546_0.txt\n",
            "aclImdb/train/unsup/49545_0.txt\n",
            "aclImdb/train/unsup/49544_0.txt\n",
            "aclImdb/train/unsup/49543_0.txt\n",
            "aclImdb/train/unsup/49542_0.txt\n",
            "aclImdb/train/unsup/49541_0.txt\n",
            "aclImdb/train/unsup/49540_0.txt\n",
            "aclImdb/train/unsup/49539_0.txt\n",
            "aclImdb/train/unsup/49538_0.txt\n",
            "aclImdb/train/unsup/49537_0.txt\n",
            "aclImdb/train/unsup/49536_0.txt\n",
            "aclImdb/train/unsup/49791_0.txt\n",
            "aclImdb/train/unsup/49790_0.txt\n",
            "aclImdb/train/unsup/49789_0.txt\n",
            "aclImdb/train/unsup/49788_0.txt\n",
            "aclImdb/train/unsup/49787_0.txt\n",
            "aclImdb/train/unsup/49786_0.txt\n",
            "aclImdb/train/unsup/49785_0.txt\n",
            "aclImdb/train/unsup/49784_0.txt\n",
            "aclImdb/train/unsup/49783_0.txt\n",
            "aclImdb/train/unsup/49782_0.txt\n",
            "aclImdb/train/unsup/49781_0.txt\n",
            "aclImdb/train/unsup/49780_0.txt\n",
            "aclImdb/train/unsup/49779_0.txt\n",
            "aclImdb/train/unsup/49778_0.txt\n",
            "aclImdb/train/unsup/49777_0.txt\n",
            "aclImdb/train/unsup/49776_0.txt\n",
            "aclImdb/train/unsup/49775_0.txt\n",
            "aclImdb/train/unsup/49774_0.txt\n",
            "aclImdb/train/unsup/49773_0.txt\n",
            "aclImdb/train/unsup/49772_0.txt\n",
            "aclImdb/train/unsup/49771_0.txt\n",
            "aclImdb/train/unsup/49770_0.txt\n",
            "aclImdb/train/unsup/49769_0.txt\n",
            "aclImdb/train/unsup/49768_0.txt\n",
            "aclImdb/train/unsup/49767_0.txt\n",
            "aclImdb/train/unsup/49766_0.txt\n",
            "aclImdb/train/unsup/49765_0.txt\n",
            "aclImdb/train/unsup/49764_0.txt\n",
            "aclImdb/train/unsup/49763_0.txt\n",
            "aclImdb/train/unsup/49762_0.txt\n",
            "aclImdb/train/unsup/49761_0.txt\n",
            "aclImdb/train/unsup/49760_0.txt\n",
            "aclImdb/train/unsup/49759_0.txt\n",
            "aclImdb/train/unsup/49758_0.txt\n",
            "aclImdb/train/unsup/49757_0.txt\n",
            "aclImdb/train/unsup/49756_0.txt\n",
            "aclImdb/train/unsup/49755_0.txt\n",
            "aclImdb/train/unsup/49754_0.txt\n",
            "aclImdb/train/unsup/49753_0.txt\n",
            "aclImdb/train/unsup/49752_0.txt\n",
            "aclImdb/train/unsup/49751_0.txt\n",
            "aclImdb/train/unsup/49750_0.txt\n",
            "aclImdb/train/unsup/49749_0.txt\n",
            "aclImdb/train/unsup/49748_0.txt\n",
            "aclImdb/train/unsup/49747_0.txt\n",
            "aclImdb/train/unsup/49746_0.txt\n",
            "aclImdb/train/unsup/49745_0.txt\n",
            "aclImdb/train/unsup/49744_0.txt\n",
            "aclImdb/train/unsup/49743_0.txt\n",
            "aclImdb/train/unsup/49742_0.txt\n",
            "aclImdb/train/unsup/49741_0.txt\n",
            "aclImdb/train/unsup/49740_0.txt\n",
            "aclImdb/train/unsup/49739_0.txt\n",
            "aclImdb/train/unsup/49738_0.txt\n",
            "aclImdb/train/unsup/49737_0.txt\n",
            "aclImdb/train/unsup/49736_0.txt\n",
            "aclImdb/train/unsup/49735_0.txt\n",
            "aclImdb/train/unsup/49734_0.txt\n",
            "aclImdb/train/unsup/49733_0.txt\n",
            "aclImdb/train/unsup/49732_0.txt\n",
            "aclImdb/train/unsup/49731_0.txt\n",
            "aclImdb/train/unsup/49730_0.txt\n",
            "aclImdb/train/unsup/49729_0.txt\n",
            "aclImdb/train/unsup/49728_0.txt\n",
            "aclImdb/train/unsup/49727_0.txt\n",
            "aclImdb/train/unsup/49726_0.txt\n",
            "aclImdb/train/unsup/49725_0.txt\n",
            "aclImdb/train/unsup/49724_0.txt\n",
            "aclImdb/train/unsup/49723_0.txt\n",
            "aclImdb/train/unsup/49722_0.txt\n",
            "aclImdb/train/unsup/49721_0.txt\n",
            "aclImdb/train/unsup/49720_0.txt\n",
            "aclImdb/train/unsup/49719_0.txt\n",
            "aclImdb/train/unsup/49718_0.txt\n",
            "aclImdb/train/unsup/49717_0.txt\n",
            "aclImdb/train/unsup/49716_0.txt\n",
            "aclImdb/train/unsup/49715_0.txt\n",
            "aclImdb/train/unsup/49714_0.txt\n",
            "aclImdb/train/unsup/49713_0.txt\n",
            "aclImdb/train/unsup/49712_0.txt\n",
            "aclImdb/train/unsup/49711_0.txt\n",
            "aclImdb/train/unsup/49710_0.txt\n",
            "aclImdb/train/unsup/49709_0.txt\n",
            "aclImdb/train/unsup/49708_0.txt\n",
            "aclImdb/train/unsup/49707_0.txt\n",
            "aclImdb/train/unsup/49706_0.txt\n",
            "aclImdb/train/unsup/49705_0.txt\n",
            "aclImdb/train/unsup/49704_0.txt\n",
            "aclImdb/train/unsup/49703_0.txt\n",
            "aclImdb/train/unsup/49702_0.txt\n",
            "aclImdb/train/unsup/49701_0.txt\n",
            "aclImdb/train/unsup/49700_0.txt\n",
            "aclImdb/train/unsup/49699_0.txt\n",
            "aclImdb/train/unsup/49698_0.txt\n",
            "aclImdb/train/unsup/49697_0.txt\n",
            "aclImdb/train/unsup/49696_0.txt\n",
            "aclImdb/train/unsup/49695_0.txt\n",
            "aclImdb/train/unsup/49694_0.txt\n",
            "aclImdb/train/unsup/49693_0.txt\n",
            "aclImdb/train/unsup/49692_0.txt\n",
            "aclImdb/train/unsup/49691_0.txt\n",
            "aclImdb/train/unsup/49690_0.txt\n",
            "aclImdb/train/unsup/49689_0.txt\n",
            "aclImdb/train/unsup/49688_0.txt\n",
            "aclImdb/train/unsup/49687_0.txt\n",
            "aclImdb/train/unsup/49686_0.txt\n",
            "aclImdb/train/unsup/49685_0.txt\n",
            "aclImdb/train/unsup/49684_0.txt\n",
            "aclImdb/train/unsup/49683_0.txt\n",
            "aclImdb/train/unsup/49682_0.txt\n",
            "aclImdb/train/unsup/49681_0.txt\n",
            "aclImdb/train/unsup/49680_0.txt\n",
            "aclImdb/train/unsup/49679_0.txt\n",
            "aclImdb/train/unsup/49678_0.txt\n",
            "aclImdb/train/unsup/49677_0.txt\n",
            "aclImdb/train/unsup/49676_0.txt\n",
            "aclImdb/train/unsup/49675_0.txt\n",
            "aclImdb/train/unsup/49674_0.txt\n",
            "aclImdb/train/unsup/49673_0.txt\n",
            "aclImdb/train/unsup/49672_0.txt\n",
            "aclImdb/train/unsup/49671_0.txt\n",
            "aclImdb/train/unsup/49670_0.txt\n",
            "aclImdb/train/unsup/49669_0.txt\n",
            "aclImdb/train/unsup/49668_0.txt\n",
            "aclImdb/train/unsup/49667_0.txt\n",
            "aclImdb/train/unsup/49666_0.txt\n",
            "aclImdb/train/unsup/49665_0.txt\n",
            "aclImdb/train/unsup/49664_0.txt\n",
            "aclImdb/train/unsup/49919_0.txt\n",
            "aclImdb/train/unsup/49918_0.txt\n",
            "aclImdb/train/unsup/49917_0.txt\n",
            "aclImdb/train/unsup/49916_0.txt\n",
            "aclImdb/train/unsup/49915_0.txt\n",
            "aclImdb/train/unsup/49914_0.txt\n",
            "aclImdb/train/unsup/49913_0.txt\n",
            "aclImdb/train/unsup/49912_0.txt\n",
            "aclImdb/train/unsup/49911_0.txt\n",
            "aclImdb/train/unsup/49910_0.txt\n",
            "aclImdb/train/unsup/49909_0.txt\n",
            "aclImdb/train/unsup/49908_0.txt\n",
            "aclImdb/train/unsup/49907_0.txt\n",
            "aclImdb/train/unsup/49906_0.txt\n",
            "aclImdb/train/unsup/49905_0.txt\n",
            "aclImdb/train/unsup/49904_0.txt\n",
            "aclImdb/train/unsup/49903_0.txt\n",
            "aclImdb/train/unsup/49902_0.txt\n",
            "aclImdb/train/unsup/49901_0.txt\n",
            "aclImdb/train/unsup/49900_0.txt\n",
            "aclImdb/train/unsup/49899_0.txt\n",
            "aclImdb/train/unsup/49898_0.txt\n",
            "aclImdb/train/unsup/49897_0.txt\n",
            "aclImdb/train/unsup/49896_0.txt\n",
            "aclImdb/train/unsup/49895_0.txt\n",
            "aclImdb/train/unsup/49894_0.txt\n",
            "aclImdb/train/unsup/49893_0.txt\n",
            "aclImdb/train/unsup/49892_0.txt\n",
            "aclImdb/train/unsup/49891_0.txt\n",
            "aclImdb/train/unsup/49890_0.txt\n",
            "aclImdb/train/unsup/49889_0.txt\n",
            "aclImdb/train/unsup/49888_0.txt\n",
            "aclImdb/train/unsup/49887_0.txt\n",
            "aclImdb/train/unsup/49886_0.txt\n",
            "aclImdb/train/unsup/49885_0.txt\n",
            "aclImdb/train/unsup/49884_0.txt\n",
            "aclImdb/train/unsup/49883_0.txt\n",
            "aclImdb/train/unsup/49882_0.txt\n",
            "aclImdb/train/unsup/49881_0.txt\n",
            "aclImdb/train/unsup/49880_0.txt\n",
            "aclImdb/train/unsup/49879_0.txt\n",
            "aclImdb/train/unsup/49878_0.txt\n",
            "aclImdb/train/unsup/49877_0.txt\n",
            "aclImdb/train/unsup/49876_0.txt\n",
            "aclImdb/train/unsup/49875_0.txt\n",
            "aclImdb/train/unsup/49874_0.txt\n",
            "aclImdb/train/unsup/49873_0.txt\n",
            "aclImdb/train/unsup/49872_0.txt\n",
            "aclImdb/train/unsup/49871_0.txt\n",
            "aclImdb/train/unsup/49870_0.txt\n",
            "aclImdb/train/unsup/49869_0.txt\n",
            "aclImdb/train/unsup/49868_0.txt\n",
            "aclImdb/train/unsup/49867_0.txt\n",
            "aclImdb/train/unsup/49866_0.txt\n",
            "aclImdb/train/unsup/49865_0.txt\n",
            "aclImdb/train/unsup/49864_0.txt\n",
            "aclImdb/train/unsup/49863_0.txt\n",
            "aclImdb/train/unsup/49862_0.txt\n",
            "aclImdb/train/unsup/49861_0.txt\n",
            "aclImdb/train/unsup/49860_0.txt\n",
            "aclImdb/train/unsup/49859_0.txt\n",
            "aclImdb/train/unsup/49858_0.txt\n",
            "aclImdb/train/unsup/49857_0.txt\n",
            "aclImdb/train/unsup/49856_0.txt\n",
            "aclImdb/train/unsup/49855_0.txt\n",
            "aclImdb/train/unsup/49854_0.txt\n",
            "aclImdb/train/unsup/49853_0.txt\n",
            "aclImdb/train/unsup/49852_0.txt\n",
            "aclImdb/train/unsup/49851_0.txt\n",
            "aclImdb/train/unsup/49850_0.txt\n",
            "aclImdb/train/unsup/49849_0.txt\n",
            "aclImdb/train/unsup/49848_0.txt\n",
            "aclImdb/train/unsup/49847_0.txt\n",
            "aclImdb/train/unsup/49846_0.txt\n",
            "aclImdb/train/unsup/49845_0.txt\n",
            "aclImdb/train/unsup/49844_0.txt\n",
            "aclImdb/train/unsup/49843_0.txt\n",
            "aclImdb/train/unsup/49842_0.txt\n",
            "aclImdb/train/unsup/49841_0.txt\n",
            "aclImdb/train/unsup/49840_0.txt\n",
            "aclImdb/train/unsup/49839_0.txt\n",
            "aclImdb/train/unsup/49838_0.txt\n",
            "aclImdb/train/unsup/49837_0.txt\n",
            "aclImdb/train/unsup/49836_0.txt\n",
            "aclImdb/train/unsup/49835_0.txt\n",
            "aclImdb/train/unsup/49834_0.txt\n",
            "aclImdb/train/unsup/49833_0.txt\n",
            "aclImdb/train/unsup/49832_0.txt\n",
            "aclImdb/train/unsup/49831_0.txt\n",
            "aclImdb/train/unsup/49830_0.txt\n",
            "aclImdb/train/unsup/49829_0.txt\n",
            "aclImdb/train/unsup/49828_0.txt\n",
            "aclImdb/train/unsup/49827_0.txt\n",
            "aclImdb/train/unsup/49826_0.txt\n",
            "aclImdb/train/unsup/49825_0.txt\n",
            "aclImdb/train/unsup/49824_0.txt\n",
            "aclImdb/train/unsup/49823_0.txt\n",
            "aclImdb/train/unsup/49822_0.txt\n",
            "aclImdb/train/unsup/49821_0.txt\n",
            "aclImdb/train/unsup/49820_0.txt\n",
            "aclImdb/train/unsup/49819_0.txt\n",
            "aclImdb/train/unsup/49818_0.txt\n",
            "aclImdb/train/unsup/49817_0.txt\n",
            "aclImdb/train/unsup/49816_0.txt\n",
            "aclImdb/train/unsup/49815_0.txt\n",
            "aclImdb/train/unsup/49814_0.txt\n",
            "aclImdb/train/unsup/49813_0.txt\n",
            "aclImdb/train/unsup/49812_0.txt\n",
            "aclImdb/train/unsup/49811_0.txt\n",
            "aclImdb/train/unsup/49810_0.txt\n",
            "aclImdb/train/unsup/49809_0.txt\n",
            "aclImdb/train/unsup/49808_0.txt\n",
            "aclImdb/train/unsup/49807_0.txt\n",
            "aclImdb/train/unsup/49806_0.txt\n",
            "aclImdb/train/unsup/49805_0.txt\n",
            "aclImdb/train/unsup/49804_0.txt\n",
            "aclImdb/train/unsup/49803_0.txt\n",
            "aclImdb/train/unsup/49802_0.txt\n",
            "aclImdb/train/unsup/49801_0.txt\n",
            "aclImdb/train/unsup/49800_0.txt\n",
            "aclImdb/train/unsup/49799_0.txt\n",
            "aclImdb/train/unsup/49798_0.txt\n",
            "aclImdb/train/unsup/49797_0.txt\n",
            "aclImdb/train/unsup/49796_0.txt\n",
            "aclImdb/train/unsup/49795_0.txt\n",
            "aclImdb/train/unsup/49794_0.txt\n",
            "aclImdb/train/unsup/49793_0.txt\n",
            "aclImdb/train/unsup/49792_0.txt\n",
            "aclImdb/train/unsup/49999_0.txt\n",
            "aclImdb/train/unsup/49998_0.txt\n",
            "aclImdb/train/unsup/49997_0.txt\n",
            "aclImdb/train/unsup/49996_0.txt\n",
            "aclImdb/train/unsup/49995_0.txt\n",
            "aclImdb/train/unsup/49994_0.txt\n",
            "aclImdb/train/unsup/49993_0.txt\n",
            "aclImdb/train/unsup/49992_0.txt\n",
            "aclImdb/train/unsup/49991_0.txt\n",
            "aclImdb/train/unsup/49990_0.txt\n",
            "aclImdb/train/unsup/49989_0.txt\n",
            "aclImdb/train/unsup/49988_0.txt\n",
            "aclImdb/train/unsup/49987_0.txt\n",
            "aclImdb/train/unsup/49986_0.txt\n",
            "aclImdb/train/unsup/49985_0.txt\n",
            "aclImdb/train/unsup/49984_0.txt\n",
            "aclImdb/train/unsup/49983_0.txt\n",
            "aclImdb/train/unsup/49982_0.txt\n",
            "aclImdb/train/unsup/49981_0.txt\n",
            "aclImdb/train/unsup/49980_0.txt\n",
            "aclImdb/train/unsup/49979_0.txt\n",
            "aclImdb/train/unsup/49978_0.txt\n",
            "aclImdb/train/unsup/49977_0.txt\n",
            "aclImdb/train/unsup/49976_0.txt\n",
            "aclImdb/train/unsup/49975_0.txt\n",
            "aclImdb/train/unsup/49974_0.txt\n",
            "aclImdb/train/unsup/49973_0.txt\n",
            "aclImdb/train/unsup/49972_0.txt\n",
            "aclImdb/train/unsup/49971_0.txt\n",
            "aclImdb/train/unsup/49970_0.txt\n",
            "aclImdb/train/unsup/49969_0.txt\n",
            "aclImdb/train/unsup/49968_0.txt\n",
            "aclImdb/train/unsup/49967_0.txt\n",
            "aclImdb/train/unsup/49966_0.txt\n",
            "aclImdb/train/unsup/49965_0.txt\n",
            "aclImdb/train/unsup/49964_0.txt\n",
            "aclImdb/train/unsup/49963_0.txt\n",
            "aclImdb/train/unsup/49962_0.txt\n",
            "aclImdb/train/unsup/49961_0.txt\n",
            "aclImdb/train/unsup/49960_0.txt\n",
            "aclImdb/train/unsup/49959_0.txt\n",
            "aclImdb/train/unsup/49958_0.txt\n",
            "aclImdb/train/unsup/49957_0.txt\n",
            "aclImdb/train/unsup/49956_0.txt\n",
            "aclImdb/train/unsup/49955_0.txt\n",
            "aclImdb/train/unsup/49954_0.txt\n",
            "aclImdb/train/unsup/49953_0.txt\n",
            "aclImdb/train/unsup/49952_0.txt\n",
            "aclImdb/train/unsup/49951_0.txt\n",
            "aclImdb/train/unsup/49950_0.txt\n",
            "aclImdb/train/unsup/49949_0.txt\n",
            "aclImdb/train/unsup/49948_0.txt\n",
            "aclImdb/train/unsup/49947_0.txt\n",
            "aclImdb/train/unsup/49946_0.txt\n",
            "aclImdb/train/unsup/49945_0.txt\n",
            "aclImdb/train/unsup/49944_0.txt\n",
            "aclImdb/train/unsup/49943_0.txt\n",
            "aclImdb/train/unsup/49942_0.txt\n",
            "aclImdb/train/unsup/49941_0.txt\n",
            "aclImdb/train/unsup/49940_0.txt\n",
            "aclImdb/train/unsup/49939_0.txt\n",
            "aclImdb/train/unsup/49938_0.txt\n",
            "aclImdb/train/unsup/49937_0.txt\n",
            "aclImdb/train/unsup/49936_0.txt\n",
            "aclImdb/train/unsup/49935_0.txt\n",
            "aclImdb/train/unsup/49934_0.txt\n",
            "aclImdb/train/unsup/49933_0.txt\n",
            "aclImdb/train/unsup/49932_0.txt\n",
            "aclImdb/train/unsup/49931_0.txt\n",
            "aclImdb/train/unsup/49930_0.txt\n",
            "aclImdb/train/unsup/49929_0.txt\n",
            "aclImdb/train/unsup/49928_0.txt\n",
            "aclImdb/train/unsup/49927_0.txt\n",
            "aclImdb/train/unsup/49926_0.txt\n",
            "aclImdb/train/unsup/49925_0.txt\n",
            "aclImdb/train/unsup/49924_0.txt\n",
            "aclImdb/train/unsup/49923_0.txt\n",
            "aclImdb/train/unsup/49922_0.txt\n",
            "aclImdb/train/unsup/49921_0.txt\n",
            "aclImdb/train/unsup/49920_0.txt\n"
          ]
        }
      ],
      "source": [
        "!tar -xvzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixau5Bhfifu_"
      },
      "source": [
        "Посмотрите в файле `./aclImdb/README` как организованы данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:55:43.946032Z",
          "start_time": "2021-04-01T23:55:43.814779Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpBT95zzifvA",
        "outputId": "bb3baca5-710c-433b-bc3c-97089df986ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well."
          ]
        }
      ],
      "source": [
        "! cat ./aclImdb/train/pos/10003_8.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:33.729663Z",
          "start_time": "2021-04-02T00:04:33.710871Z"
        },
        "id": "GYMI4jW4ifvA"
      },
      "outputs": [],
      "source": [
        "test_data_path = './aclImdb/test/'\n",
        "train_data_path = './aclImdb/train/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:33.709378Z",
          "start_time": "2021-04-02T00:04:32.220580Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8lcaeySifvB",
        "outputId": "19eb66cb-76a6-4b55-918f-b362a2a3421a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/br0fire/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from functools import partial\n",
        "from collections import defaultdict\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import regex\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyPMYeY8ifvB"
      },
      "source": [
        "Стандартной предобработкой данных является токенизация текстов. Полученные токены можно будет закодировать и затем подавать на вход нейронной сети. Ключевым моментом, который влияет на скорость работы нейросети и её размер в памяти — размер словаря, используемого при токенизации. Для задачи классификации мы можем убрать часть слов (стоп слова, редкие слова), ускорив обучение без потери в качестве."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:35.270825Z",
          "start_time": "2021-04-02T00:04:35.250283Z"
        },
        "id": "6W8EJvFaifvB"
      },
      "outputs": [],
      "source": [
        "STOPWORDS = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0YYuMEoifvC"
      },
      "source": [
        "Реализуйте функцию для токенизации текста. Выполнять токенизацию можно по-разному, но в данном задании предлагается это делать следующим образом:\n",
        "1. Привести текст к нижнему регистру\n",
        "2. Убрать html разметку из текстов (`<br />`, ...)\n",
        "3. Убрать все символы кроме латинских букв\n",
        "4. Разбить строку по пробелам\n",
        "5. Убрать стоп слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:36.003194Z",
          "start_time": "2021-04-02T00:04:35.980408Z"
        },
        "id": "II6C1dlWifvC"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param str text: Input text\n",
        "    :return List[str]: List of words\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = regex.sub('<br />', '', text)\n",
        "    text = regex.sub(r'[^a-z ]', '', text).split(' ')\n",
        "    text = [w for w in text if w not in set(STOPWORDS) and w != '']\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:27:12.428149Z",
          "start_time": "2021-04-01T21:27:12.402448Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3-kCEygifvC",
        "outputId": "2a6990c5-23f2-4a23-d03a-d531b38d1f8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hello', 'words']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenize('1. Hello <br /> words!! <br />')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4oqS3NAifvD"
      },
      "source": [
        "Теперь мы можем создать словарь, с помощью которого мы будем численно кодировать токены из текста и наоборот.\n",
        "\n",
        "Удобной обёрткой для создания словарей является класс `torchtext.vocab.Vocab` и фабрика для создания таких классов `torchtext.vocab.vocab`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:27:21.466887Z",
          "start_time": "2021-04-01T21:27:21.352085Z"
        },
        "id": "upjFw7yXifvD",
        "scrolled": false,
        "outputId": "aca9f806-bdfd-45d3-a120-73edbee58115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m     \n",
            "Base class for all neural network modules.\n",
            "\n",
            "Your models should also subclass this class.\n",
            "\n",
            "Modules can also contain other Modules, allowing to nest them in\n",
            "a tree structure. You can assign the submodules as regular attributes::\n",
            "\n",
            "    import torch.nn as nn\n",
            "    import torch.nn.functional as F\n",
            "\n",
            "    class Model(nn.Module):\n",
            "        def __init__(self):\n",
            "            super().__init__()\n",
            "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
            "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
            "\n",
            "        def forward(self, x):\n",
            "            x = F.relu(self.conv1(x))\n",
            "            return F.relu(self.conv2(x))\n",
            "\n",
            "Submodules assigned in this way will be registered, and will have their\n",
            "parameters converted too when you call :meth:`to`, etc.\n",
            "\n",
            ".. note::\n",
            "    As per the example above, an ``__init__()`` call to the parent class\n",
            "    must be made before assignment on the child.\n",
            "\n",
            ":ivar training: Boolean represents whether this module is in training or\n",
            "                evaluation mode.\n",
            ":vartype training: bool\n",
            "\u001b[0;31mSource:\u001b[0m        \n",
            "\u001b[0;32mclass\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0m__jit_unused_properties__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"is_jitable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Creates a vocab object which maps tokens to indices.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    Args:\u001b[0m\n",
            "\u001b[0;34m        vocab (torch.classes.torchtext.Vocab or torchtext._torchtext.Vocab): a cpp vocab object.\u001b[0m\n",
            "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0m_log_class_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mis_jitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Calls the `lookup_indices` method\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            tokens: a list of tokens used to lookup their corresponding `indices`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            The indices associated with a list of `tokens`.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            The length of the vocab.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            token: The token for which to check the membership.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Whether the token is member of vocab or not.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            token: The token used to lookup the corresponding index.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            The index corresponding to the associated token.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            index: Value of default index. This index will be returned when OOV token is queried.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Value of default index if it is set.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0minsert_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            token: The token used to lookup the corresponding index.\u001b[0m\n",
            "\u001b[0;34m            index: The index corresponding to the associated token.\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            RuntimeError: If `index` is not in range [0, Vocab.size()] or if `token` already exists in the vocab.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mappend_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            token: The token used to lookup the corresponding index.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            RuntimeError: If `token` already exists in the vocab\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlookup_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            index: The index corresponding to the associated token.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            token: The token used to lookup the corresponding index.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            RuntimeError: If `index` not in range [0, itos.size()).\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlookup_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            indices: The `indices` used to lookup their corresponding`tokens`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            The `tokens` associated with `indices`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Raises:\u001b[0m\n",
            "\u001b[0;34m            RuntimeError: If an index within `indices` is not int range [0, itos.size()).\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlookup_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Args:\u001b[0m\n",
            "\u001b[0;34m            tokens: the tokens used to lookup their corresponding `indices`.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            The 'indices` associated with `tokens`.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_stoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            Dictionary mapping tokens to indices.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_itos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Returns:\u001b[0m\n",
            "\u001b[0;34m            List mapping indices to tokens.\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_itos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__prepare_scriptable__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Return a JITable Vocab.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_jitable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mcpp_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.10/site-packages/torchtext/vocab/vocab.py\n",
            "\u001b[0;31mType:\u001b[0m           type\n",
            "\u001b[0;31mSubclasses:\u001b[0m     "
          ]
        }
      ],
      "source": [
        "torchtext.vocab.Vocab??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T19:51:55.300753Z",
          "start_time": "2021-04-01T19:51:55.275188Z"
        },
        "id": "0wXaMXvpifvD"
      },
      "source": [
        "Чтобы создать такой словарь, сначала нужно создать словарь со всеми токенами в тексте и их частотами встречаемости:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.547038Z",
          "start_time": "2021-04-02T00:04:38.190688Z"
        },
        "id": "0Xv55TTBifvD"
      },
      "outputs": [],
      "source": [
        "counter = defaultdict(int)\n",
        "\n",
        "for path in ['./aclImdb/test/neg', './aclImdb/test/pos', './aclImdb/train/neg', './aclImdb/train/pos']:\n",
        "    for file_path in os.listdir(path):\n",
        "        text = open(os.path.join(path, file_path), 'r', encoding='utf-8', errors='ignore').read().strip()\n",
        "        for token in tokenize(text):\n",
        "            counter[token] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1G8BCPQifvE"
      },
      "source": [
        "Для работы с текстами нам необходимо зарезервировать два специальных токена:\n",
        "1. `<pad>` для токена означающего паддинг\n",
        "2. `<unk>` для токенов, которые отсутствуют в словаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:18.239274Z",
          "start_time": "2021-04-01T21:28:18.214979Z"
        },
        "id": "jDHMFC68ifvE"
      },
      "outputs": [],
      "source": [
        "specials = ['<pad>', '<unk>']\n",
        "for special in specials:\n",
        "    counter[special] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXgQ2ZBfifvE"
      },
      "source": [
        "Создайте словарь из словаря частот `counter`. Наименьшие *id* отдайте под специальные токены.\n",
        "\n",
        "Отбросьте низкочастотные слова, оставив только `top_n_words` слов. Можете использовать любой способ реализации этого условия, например:\n",
        "1. Оставить в словаре `counter` нужное число слов\n",
        "2. Подобрать параметр `min_freq`, чтобы оставшееся число слов было близко к необходимому порогу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHjYKcHXwp1W"
      },
      "outputs": [],
      "source": [
        "import torchtext.vocab as vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCkWfEIgwyUP"
      },
      "outputs": [],
      "source": [
        "vocab = vocab.vocab(counter, min_freq=146)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8vTVwl90FdV",
        "outputId": "fb654d6e-a995-46f6-b840-df285fdfb8f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2dHVo060HIK"
      },
      "outputs": [],
      "source": [
        "vocab.insert_token('<pad>', 0)\n",
        "vocab.insert_token('<unk>', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSLEQgWB6Lhg"
      },
      "outputs": [],
      "source": [
        "vocab.set_default_index(vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:24.332126Z",
          "start_time": "2021-04-01T21:28:24.306890Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPtkds5aifvE",
        "outputId": "4f39dec7-696f-4e6d-8dd0-5fecb5600673"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab.lookup_indices(['<pad>', '<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:26.254910Z",
          "start_time": "2021-04-01T21:28:26.231012Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lKEu0H5ifvF",
        "outputId": "947f7580-8fec-48d9-9d97-ddc44063c361"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 25, 1, 539]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab.lookup_indices(['this', 'film', 'was', 'awful']) #[1, 3, 1, 254]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLnGc8Q7ifvF"
      },
      "source": [
        "Теперь мы готовы создать обёртку-датасет для наших данных.\n",
        "\n",
        "Необходимо добавить несколько опции, которые понадобятся во второй части задания:\n",
        "1. Ограничение на максимальную длину текста в токенах. Если текст оказывается длиннее, то последние токены отбрасываются\n",
        "2. Возможность добавить в специальные токены `<sos>`, `<eos>` в начало и конец токенизированного текста\n",
        "\n",
        "**tips:**\n",
        "1. Обратите особое внимание, что у длинных текстов не должен обрезаться паддинг\n",
        "2. В исходных данных рейтинг закодирован в названии файла в виде числа от $1$ до $10$. Для удобства, вычтите $1$, чтобы рейтинг был от $0$ до $9$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.573249Z",
          "start_time": "2021-04-02T00:05:13.548593Z"
        },
        "id": "zVFTzcS6ifvF"
      },
      "outputs": [],
      "source": [
        "class LargeMovieReviewDataset(Dataset):\n",
        "    def __init__(self, data_path, vocab, max_len, pad_sos=False, pad_eos=False):\n",
        "        \"\"\"\n",
        "        :param str data_path: Path to folder with one of the data splits (train or test)\n",
        "        :param torchtext.vocab.Vocab vocab: dictionary with lookup_indices method\n",
        "        :param int max_len: Maximum length of tokenized text\n",
        "        :param bool pad_sos: If True pad sequence at the beginning with <sos>\n",
        "        :param bool pad_eos: If True pad sequence at the end with <eos>\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.pad_sos = pad_sos\n",
        "        if self.pad_sos:\n",
        "            self.sos_id = vocab.lookup_indices(['<sos>'])[0]\n",
        "        self.pad_eos = pad_eos\n",
        "        if self.pad_eos:\n",
        "            self.eos_id = vocab.lookup_indices(['<eos>'])[0]\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "        self.data_path = data_path\n",
        "        self.negative_path = os.path.join(data_path, 'neg')\n",
        "        self.positive_path = os.path.join(data_path, 'pos')\n",
        "\n",
        "        self.negative_paths = []\n",
        "        self.positive_paths = []\n",
        "\n",
        "        for file_path in os.listdir(self.negative_path):\n",
        "            self.negative_paths.append(os.path.join(self.negative_path, file_path))\n",
        "\n",
        "        for file_path in os.listdir(self.positive_path):\n",
        "            self.positive_paths.append(os.path.join(self.positive_path, file_path))\n",
        "\n",
        "        self.texts = []\n",
        "        self.tokens = []\n",
        "        self.ratings = []\n",
        "        self.labels = [0] * len(self.negative_paths) + [1] * len(self.positive_paths)\n",
        "\n",
        "        # Read each file in data_path, tokenize it, get tokens ids, its rating and store\n",
        "        for path in self.negative_paths + self.positive_paths:\n",
        "            text = open(path, 'r', encoding='utf-8', errors='ignore').read()\n",
        "            self.texts.append(text)\n",
        "            tokens = tokenize(text.strip())\n",
        "            if len(tokens) > self.max_len:\n",
        "                tokens = tokens[0:self.max_len]\n",
        "            token_ids = self.vocab.lookup_indices(tokens)\n",
        "            self.tokens.append(token_ids)\n",
        "            rate = path[-6:-4]\n",
        "            if rate[0] == '_':\n",
        "                rate = int(rate[1]) - 1\n",
        "            else:\n",
        "                rate = 9\n",
        "            self.ratings.append(rate)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        :param int idx: index of object in dataset\n",
        "        :return dict: Dictionary with all useful object data\n",
        "            {\n",
        "                'text' str: unprocessed text,\n",
        "                'label' torch.Tensor(dtype=torch.long): sentiment of the text (0 for negative, 1 for positive)\n",
        "                'rating' torch.Tensor(dtype=torch.long): rating of the text\n",
        "                'tokens' torch.Tensor(dtype=torch.long): tensor of tokens ids for the text\n",
        "                'tokens_len' torch.Tensor(dtype=torch.long): number of tokens\n",
        "            }\n",
        "        \"\"\"\n",
        "        tokens = self.tokens[idx]\n",
        "        tokens_len = len(tokens)\n",
        "        if self.pad_sos:\n",
        "            tokens = [self.sos_id] + tokens\n",
        "            tokens_len += 1\n",
        "        if self.pad_eos:\n",
        "            tokens = tokens + [self.eos_id]\n",
        "            tokens_len += 1\n",
        "\n",
        "        res = {'text': self.texts[idx], 'label': torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "               'rating': torch.tensor(self.ratings[idx], dtype=torch.long),\n",
        "               'tokens': torch.tensor(tokens, dtype=torch.long),\n",
        "               'tokens_len': torch.tensor(tokens_len, dtype=torch.long)}\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        :return int: number of objects in dataset\n",
        "        \"\"\"\n",
        "        return len(self.texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SktB_waNifvG"
      },
      "source": [
        "Создайте датасеты для тестовой и обучающей выборки.\n",
        "\n",
        "Обратите внимание, что для задачи классификации нам не потребуется паддинг с помощью `<sos>`, `<eos>`.\n",
        "\n",
        "Не забудьте обрезать длинные тексты, передав параметр `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:31:32.123618Z",
          "start_time": "2021-04-01T21:30:54.950259Z"
        },
        "id": "db_CIfF4ifvG"
      },
      "outputs": [],
      "source": [
        "test_dataset = LargeMovieReviewDataset(data_path=test_data_path, vocab=vocab, max_len=max_length)\n",
        "train_dataset = LargeMovieReviewDataset(data_path=train_data_path, vocab=vocab, max_len=max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDHCUAQIifvG"
      },
      "source": [
        "Посмотрим, как выглядит объект в датасете:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:31:36.017106Z",
          "start_time": "2021-04-01T21:31:35.988797Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W5zylVGifvG",
        "outputId": "1665db40-223e-4b70-b28d-e26f7e9ea4de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'This opens with the company credits informing us it`s by World International Network . I knew I`d seen this company credit before but couldn`t remember where , but knew it was at the start of a really bad movie I`d seen so I seriously thought about changing channels , only thing was I`d seen every film on the other channels which is one of the problems of being an IMDB reviewer . What the hell I thought it won`t really matter if WANTED is good or bad because I`ll still be able to review it for this site.<br /><br />As I expected WANTED wasn`t all that good . It`s a plot I`d seen so many times ( Too many times ) before involving a fugitive on the run , a bit like THE INCREDIBLE HULK TV series without the shirt ripping . Jimmy crosses the mob in an entirely contrived way and goes on the run and in an entirely contrived manner finds himself working at a catholic reform school . Have you noticed an oft used description in the last sentence ? \" Entirely contrived \" is the answer . Let me repeat for the hard of thinking that this is an entirely contrived film where everything relies on coincidence . Another problem I had was the reform school run by the church - it`s far too compassionate and kind , I`m led to believe these type of establishments make Alcatraz look like a country club , I`m saying this is a fact but when the head priest looks like the spitting image of Donald Rumsfeld you do feel there`s a large amount of sugar coating going on .<br /><br />To be honest despite the ridiculous plot twists etc WANTED isn`t really a bad thriller though it`s a terribly good one either . I never really had the urge to switch it off no matter how contrived it became which is an under hand compliment to the movie',\n",
              " 'label': tensor(0),\n",
              " 'rating': tensor(3),\n",
              " 'tokens': tensor([  2,   3,   4,   1,   5,   6,   7,   8,   9,  10,  11,   3,  12,  13,\n",
              "          14,   9,  15,  16,  17,  18,  10,  11,  19,  20,  21,  22,  23,  10,\n",
              "          11,  24,  25,  22,  26,  27,  28,  29,  30,  20,  31,  16,  32,  33,\n",
              "          34,  17,  35,  36,  37,  38,   1,  39,  33,  40,  34,  41,  10,  11,\n",
              "          42,  43,  42,  43,  44,   1,  45,  46,  47,  48,   1,  49,  50,  51,\n",
              "          52,   1,  53,   1,  54,  55,  56,  57,  58,  45,  55,  56,  59,  60,\n",
              "          61,  62,   1,  63,  64,   1,  65,  66,  67,  68,  55,  56,  69,  70,\n",
              "          71,  72,  73,  55,  56,  25,  74,  75,  76,  77,  78,   1,  63,  45,\n",
              "          79,  80,   1,  81,  82,  83,  84,  85,   1,  86,   1,  87,  47,  88,\n",
              "          89,  82,  90,  91,  92,  93,  94,  47,   1,  95,  96,   1,  97,  98,\n",
              "          99, 100,   1,   1, 101, 102, 103, 104,  41, 105, 106,  33, 107,  16,\n",
              "          17, 108, 109, 110,  34,  26, 111, 112,  16, 113, 114,  32,  56, 115,\n",
              "         116,   1,  18]),\n",
              " 'tokens_len': tensor(171)}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA2Or8aFjOyP",
        "outputId": "76862be7-2717-4a32-f9b4-e1f1af9c83fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'This opens with the company credits informing us it`s by World International Network . I knew I`d seen this company credit before but couldn`t remember where , but knew it was at the start of a really bad movie I`d seen so I seriously thought about changing channels , only thing was I`d seen every film on the other channels which is one of the problems of being an IMDB reviewer . What the hell I thought it won`t really matter if WANTED is good or bad because I`ll still be able to review it for this site.<br /><br />As I expected WANTED wasn`t all that good . It`s a plot I`d seen so many times ( Too many times ) before involving a fugitive on the run , a bit like THE INCREDIBLE HULK TV series without the shirt ripping . Jimmy crosses the mob in an entirely contrived way and goes on the run and in an entirely contrived manner finds himself working at a catholic reform school . Have you noticed an oft used description in the last sentence ? \" Entirely contrived \" is the answer . Let me repeat for the hard of thinking that this is an entirely contrived film where everything relies on coincidence . Another problem I had was the reform school run by the church - it`s far too compassionate and kind , I`m led to believe these type of establishments make Alcatraz look like a country club , I`m saying this is a fact but when the head priest looks like the spitting image of Donald Rumsfeld you do feel there`s a large amount of sugar coating going on .<br /><br />To be honest despite the ridiculous plot twists etc WANTED isn`t really a bad thriller though it`s a terribly good one either . I never really had the urge to switch it off no matter how contrived it became which is an under hand compliment to the movie',\n",
              " 'label': tensor(0),\n",
              " 'rating': tensor(3),\n",
              " 'tokens': tensor([  2,   3,   4,   1,   5,   6,   7,   8,   9,  10,  11,   3,  12,  13,\n",
              "          14,   9,  15,  16,  17,  18,  10,  11,  19,  20,  21,  22,  23,  10,\n",
              "          11,  24,  25,  22,  26,  27,  28,  29,  30,  20,  31,  16,  32,  33,\n",
              "          34,  17,  35,  36,  37,  38,   1,  39,  33,  40,  34,  41,  10,  11,\n",
              "          42,  43,  42,  43,  44,   1,  45,  46,  47,  48,   1,  49,  50,  51,\n",
              "          52,   1,  53,   1,  54,  55,  56,  57,  58,  45,  55,  56,  59,  60,\n",
              "          61,  62,   1,  63,  64,   1,  65,  66,  67,  68,  55,  56,  69,  70,\n",
              "          71,  72,  73,  55,  56,  25,  74,  75,  76,  77,  78,   1,  63,  45,\n",
              "          79,  80,   1,  81,  82,  83,  84,  85,   1,  86,   1,  87,  47,  88,\n",
              "          89,  82,  90,  91,  92,  93,  94,  47,   1,  95,  96,   1,  97,  98,\n",
              "          99, 100,   1,   1, 101, 102, 103, 104,  41, 105, 106,  33, 107,  16,\n",
              "          17, 108, 109, 110,  34,  26, 111, 112,  16, 113, 114,  32,  56, 115,\n",
              "         116,   1,  18]),\n",
              " 'tokens_len': tensor(171)}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBsIC9pJifvH"
      },
      "source": [
        "Теперь нам нужно создать `DataLoader` для наших данных. `DataLoader` умеет из коробки объединять список объектов из датасета в один батч, даже когда датасет возвращает словарь тензоров. Однако, это работает только в случае когда все эти тензоры имеют один и тот же размер во всех батчах. В нашем случае, это не так, так как разные тексты могут иметь разную длину.\n",
        "\n",
        "Чтобы обойти эту проблему у `DataLoader` есть параметр `collate_fn`, который позволяет задать функцию для объединения списка объектов в один батч."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcXpggeIifvH"
      },
      "source": [
        "Чтобы объединить несколько тензоров разной длины в один можно использовать функцию `torch.nn.utils.rnn.pad_sequence`\n",
        "\n",
        "Обратите внимание на её аргументы:\n",
        "1. `batch_first` определяет по какой оси \"складывать\" тензоры. Предпочтительнее использовать `batch_first=False` так как это может упростить выполнение задания в дальнейшем\n",
        "2. `padding_value` — число, которое будет использоваться в качестве паддинга, чтобы сделать все тензоры одинаковой длины"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:33:06.372403Z",
          "start_time": "2021-04-01T21:33:06.344559Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s57s6v6SifvH",
        "outputId": "9fc848d9-3c2d-4f84-ad12-53c33b55f7da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  4,  6],\n",
              "        [ 2,  5,  7],\n",
              "        [ 3, -1,  8],\n",
              "        [-1, -1,  9]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.nn.utils.rnn.pad_sequence([\n",
        "    torch.tensor([1, 2, 3]),\n",
        "    torch.tensor([4, 5]),\n",
        "    torch.tensor([6, 7, 8, 9])\n",
        "], batch_first=False, padding_value=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.709466Z",
          "start_time": "2021-04-02T00:05:13.575053Z"
        },
        "id": "3_4VNsWeifvH"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, padding_value, batch_first=False):\n",
        "    \"\"\"\n",
        "    :param List[Dict] batch: List of objects from dataset\n",
        "    :param int padding_value: Value that will be used to pad tokens\n",
        "    :param bool batch_first: If True resulting tensor with tokens must have shape [B, T] otherwise [T, B]\n",
        "    :return dict: Dictionary with all data collated\n",
        "        {\n",
        "            'ratings' torch.Tensor(dtype=torch.long): rating of the text for each object in batch\n",
        "            'labels' torch.Tensor(dtype=torch.long): sentiment of the text for each object in batch\n",
        "\n",
        "            'texts' List[str]: All texts in one list\n",
        "            'tokens' torch.Tensor(dtype=torch.long): tensor of tokens ids padded with @padding_value\n",
        "            'tokens_lens' torch.Tensor(dtype=torch.long): number of tokens for each object in batch\n",
        "        }\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    ratings = torch.tensor([], dtype=torch.long)\n",
        "    labels = torch.tensor([], dtype=torch.long)\n",
        "    tokens_lens = torch.tensor([], dtype=torch.long)\n",
        "    tokens_list = []\n",
        "    for data in batch:\n",
        "        texts.append(data['text'])\n",
        "        ratings = torch.hstack((ratings, data['rating']))\n",
        "        labels = torch.hstack((labels, data['label']))\n",
        "        tokens_lens = torch.hstack((tokens_lens, data['tokens_len']))\n",
        "        tokens_list.append(data['tokens'])\n",
        "    tokens = torch.nn.utils.rnn.pad_sequence(tokens_list, batch_first=batch_first, padding_value=padding_value)\n",
        "    res = {'ratings': ratings, 'labels': labels, 'texts': texts, 'tokens': tokens, 'tokens_lens': tokens_lens}\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rcSsKPRifvI"
      },
      "source": [
        "Создайте даталоадеры с использованием `collate_fn`.\n",
        "\n",
        "**tips**:\n",
        "1. Передать в `collate_fn` правильное значение паддинга можно, например, с помощью `functools.partial`\n",
        "2. Если вы работаете в Google Colab, то, возможно, вам будет необходимо установить `num_workers=0` во избежание падения ноутбука."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:33:37.872760Z",
          "start_time": "2021-04-01T21:33:37.847071Z"
        },
        "id": "-BfuCNzWifvI"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=partial(collate_fn, padding_value=0))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=partial(collate_fn, padding_value=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vck840JqifvI"
      },
      "source": [
        "Посмотрим на какой-нибудь батч:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:33:46.922744Z",
          "start_time": "2021-04-01T21:33:46.755275Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKo8p7wmifvI",
        "outputId": "5a7c6fdd-2d23-4350-ea53-40e9e0db4e1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dict_keys(['ratings', 'labels', 'texts', 'tokens', 'tokens_lens']),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor([3, 0, 0, 0, 3, 0, 2, 2, 1, 1, 0, 0, 0, 3, 2, 0, 0, 0, 2, 1, 0, 3, 1, 2,\n",
              "         3, 1, 0, 1, 0, 3, 0, 3, 0, 1, 0, 0, 0, 1, 1, 2, 0, 1, 2, 3, 0, 0, 2, 2,\n",
              "         0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 3, 2, 0, 0]),\n",
              " tensor([[   2,  117,  285,  ...,  262,   26,   82],\n",
              "         [   3,  118,  286,  ..., 1168,  317,  357],\n",
              "         [   4,  119,   18,  ...,    1,  122, 1245],\n",
              "         ...,\n",
              "         [   0,  239,    0,  ...,    0,    0,    0],\n",
              "         [   0,  240,    0,  ...,    0,    0,    0],\n",
              "         [   0,   47,    0,  ...,    0,    0,    0]]),\n",
              " tensor([171, 200,  79, 123,  63, 117, 112, 149,  83,  57, 109, 119, 116, 200,\n",
              "          88,  73, 102,  56, 139,  79,  64,  28, 200,  67, 200, 200,  96,  72,\n",
              "         136,  82, 118, 117,  69,  23, 118,  89, 188,  67, 157,  70,  92, 161,\n",
              "         118,  80, 127,  96,  57, 200, 104,  55,  49, 118, 122,  55,  96, 170,\n",
              "         200,  77,  79,  79,  68,  31,  52,  71]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(test_dataloader))\n",
        "batch.keys(), batch['labels'], batch['ratings'], batch['tokens'], batch['tokens_lens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkj6BtVPifvI"
      },
      "source": [
        "# `Часть 1. Классификация текстов (4 балла)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ9iJZeLifvJ"
      },
      "source": [
        "## `Сборка и обучение RNN в pytorch (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfFQ1xjcifvJ"
      },
      "source": [
        "Создадим переменные для device-agnostic кода:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.809416Z",
          "start_time": "2021-04-02T00:05:13.711383Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9RD-1f2ifvJ",
        "outputId": "a94de339-9e72-4acc-c4f4-75acc6946a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0, dtype: torch.float32\n"
          ]
        }
      ],
      "source": [
        "dtype, device, cuda_device_id = torch.float32, None, 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
        "if cuda_device_id is not None and torch.cuda.is_available():\n",
        "    device = 'cuda:{0:d}'.format(0)\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Using device: {device}, dtype: {dtype}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWbrU5d3ifvJ"
      },
      "source": [
        "Наша нейросеть будет обрабатывать входную последовательность по словам (word level). Мы будем использовать простую и стандартную рекуррентную архитектуру для классификации:\n",
        "1. Слой представлений, превращающий id токена в вектор-эмбеддинг этого слова\n",
        "2. Слой LSTM\n",
        "3. Полносвязный слой, предсказывающий выход по последнему скрытому состоянию\n",
        "\n",
        "Ниже дан код для сборки и обучения нашей нейросети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WydvHnHtifvJ"
      },
      "source": [
        "Допишите класс-обёртку над LSTM для задачи классификации.\n",
        "**Не используйте циклы.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T20:59:16.467178Z",
          "start_time": "2021-04-01T20:59:16.441112Z"
        },
        "id": "h-7LLRjZifvK"
      },
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.873713Z",
          "start_time": "2021-04-02T00:05:13.810690Z"
        },
        "id": "rsF5A_P4ifvK"
      },
      "outputs": [],
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self, embedding_dim, hidden_dim, output_size, vocab,\n",
        "        rec_layer=torch.nn.LSTM, dropout=None, **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Create a simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #    Use torch.nn.Embedding. Do not forget specify padding_idx!\n",
        "        # YOUR CODE HERE\n",
        "        self.word_embeddings = torch.nn.Embedding (num_embeddings=len(self.vocab),\n",
        "                                                   embedding_dim=self.embedding_dim,\n",
        "                                                   padding_idx=self.vocab.lookup_indices(['<pad>'])[0])\n",
        "\n",
        "        if dropout is not None:\n",
        "            self.rnn = rec_layer(self.embedding_dim, self.hidden_dim, dropout=self.dropout, **kwargs)\n",
        "        else:\n",
        "            self.rnn = rec_layer(self.embedding_dim, self.hidden_dim, **kwargs)\n",
        "\n",
        "        # Create linear layer for classification\n",
        "        # YOUR CODE HERE\n",
        "        self.output  = torch.nn.Linear(in_features=hidden_dim, out_features=output_size)\n",
        "\n",
        "    def forward(self, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor(dtype=torch.long) tokens: Batch of texts represented with tokens.\n",
        "        :param torch.Tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch.\n",
        "        :return torch.Tensor(dtype=torch.long): Vector representation for each sequence in batch\n",
        "        \"\"\"\n",
        "        # Evaluate embeddings\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        # Make forward pass through recurrent network\n",
        "        rnn_output = self.rnn(embeddings)[0]\n",
        "\n",
        "        # Pass output from rnn to linear layer\n",
        "        # Note: each object in batch has its own length\n",
        "        #     so we must take rnn hidden state after the last token for each text in batch\n",
        "        rnn_output = rnn_output[tokens_lens - 1, torch.arange(len(tokens_lens))]\n",
        "        output = self.output(rnn_output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpPIbsAQifvK"
      },
      "source": [
        "[Исходный код LSTM](http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUxRNMWeifvK"
      },
      "source": [
        "Допишите функции для обучения и оценки модели:\n",
        "\n",
        "**tip:**\n",
        "1. В функции `evaluate` при подсчёте метрик учитывайте, что батчи могут иметь разный размер. (в частности последний батч)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.969665Z",
          "start_time": "2021-04-02T00:05:13.875379Z"
        },
        "id": "8kA9ewUJifvK"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
        "        labels = data['ratings'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(tokens, tokens_lens)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(dataloader):\n",
        "            # 1. Take data from batch\n",
        "            ratings = data['ratings'].to(device)\n",
        "            tokens = data['tokens'].to(device)\n",
        "            tokens_lens = data['tokens_lens'].to(device)\n",
        "            # 2. Perform forward pass\n",
        "            outputs = model(tokens, tokens_lens)\n",
        "            # 3. Evaluate loss\n",
        "            loss = len(ratings) * loss_fn(outputs, ratings).cpu().item()\n",
        "            total_loss += loss\n",
        "            # 4. Evaluate accuracy\n",
        "            accuracy = torch.sum(torch.argmax(outputs, dim=1) == ratings)\n",
        "            total_accuracy += accuracy.item()\n",
        "\n",
        "    return total_loss / len(dataloader.dataset), total_accuracy / len(dataloader.dataset)\n",
        "\n",
        "def train(\n",
        "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
        "):\n",
        "    test_losses = []\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    train_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_epoch(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "        train_loss, train_acc = evaluate(train_loader, model, loss_fn, device)\n",
        "        train_accuracies.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_loss, test_acc = evaluate(test_loader, model, loss_fn, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\n",
        "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
        "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "            )\n",
        "        )\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F28Yoj9YifvL"
      },
      "source": [
        "Создадим модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:39:36.315652Z",
          "start_time": "2021-04-01T21:39:33.667776Z"
        },
        "id": "MRK-E9HrifvL"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=torch.nn.LSTM, dropout=None\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ32oq3JifvL"
      },
      "source": [
        "Создадим класс для подсчёта функции потерь и оптимизатор:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:39:38.737281Z",
          "start_time": "2021-04-01T21:39:38.711948Z"
        },
        "id": "WuACPkgTifvL"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrksnT3DifvL"
      },
      "source": [
        "Попробуем обучить модель:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvFA0DdoifvL"
      },
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXxPHvBdXumd",
        "outputId": "4b33d0e5-f77b-4339-8a77-d1082adbc6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.970/1.973. Accuracy (Train/Test): 0.263/0.268\n",
            "Epoch: 2/15. Loss (Train/Test): 1.982/1.993. Accuracy (Train/Test): 0.262/0.263\n",
            "Epoch: 3/15. Loss (Train/Test): 1.688/1.722. Accuracy (Train/Test): 0.360/0.346\n",
            "Epoch: 4/15. Loss (Train/Test): 1.565/1.632. Accuracy (Train/Test): 0.391/0.368\n",
            "Epoch: 5/15. Loss (Train/Test): 1.488/1.585. Accuracy (Train/Test): 0.420/0.385\n",
            "Epoch: 6/15. Loss (Train/Test): 1.450/1.579. Accuracy (Train/Test): 0.433/0.383\n",
            "Epoch: 7/15. Loss (Train/Test): 1.380/1.573. Accuracy (Train/Test): 0.460/0.390\n",
            "Epoch: 8/15. Loss (Train/Test): 1.332/1.581. Accuracy (Train/Test): 0.480/0.396\n",
            "Epoch: 9/15. Loss (Train/Test): 1.291/1.585. Accuracy (Train/Test): 0.497/0.384\n",
            "Epoch: 10/15. Loss (Train/Test): 1.243/1.609. Accuracy (Train/Test): 0.519/0.379\n",
            "Epoch: 11/15. Loss (Train/Test): 1.159/1.629. Accuracy (Train/Test): 0.550/0.379\n",
            "Epoch: 12/15. Loss (Train/Test): 1.096/1.665. Accuracy (Train/Test): 0.581/0.375\n",
            "Epoch: 13/15. Loss (Train/Test): 1.023/1.728. Accuracy (Train/Test): 0.610/0.379\n",
            "Epoch: 14/15. Loss (Train/Test): 0.934/1.797. Accuracy (Train/Test): 0.649/0.377\n",
            "Epoch: 15/15. Loss (Train/Test): 0.854/1.903. Accuracy (Train/Test): 0.684/0.368\n"
          ]
        }
      ],
      "source": [
        "train_losses_pure, train_accuracies_pure, test_losses_pure, test_accuracies_pure = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyYCdNiZifvM"
      },
      "source": [
        "Нерегуляризованные LSTM часто быстро переобучаются (и мы это видим по точности на контроле). Чтобы с этим бороться, часто используют *L2-регуляризацию* и *дропаут*.\n",
        "Однако способов накладывать дропаут на рекуррентный слой достаточно много, и далеко не все хорошо работают. По [ссылке](https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b) доступен хороший обзор дропаутов для RNN.\n",
        "\n",
        "Мы реализуем два варианта DropOut для RNN (и третий дополнительно). Заодно увидим, что для реализации различных усовершенствований рекуррентной архитектуры приходится \"вскрывать\" слой до различной \"глубины\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsm01_uNifvM"
      },
      "source": [
        "## `Реализация дропаута по статье Гала и Гарамани. Variational Dropout (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVJpobzAifvM"
      },
      "source": [
        "Начнем с дропаута, описанного в [статье Гала и Гарамани](https://arxiv.org/abs/1512.05287).\n",
        "Для этого нам потребуется перейти от использования слоя `torch.nn.LSTM`, полностью скрывающего от нас рекуррентную логику, к использованию слоя `torch.nn.LSTMCell`, обрабатывающего лишь один временной шаг нашей последовательности (а всю логику вокруг придется реализовать самостоятельно).\n",
        "\n",
        "Допишите класс `RNNLayer`. При `dropout=0` ваш класс должен работать как обычный слой LSTM, а при `dropout > 0` накладывать бинарную маску на входной и скрытый вектор на каждом временном шаге, причем эта маска должна быть одинаковой во все моменты времени.\n",
        "\n",
        "Дропаут Гала и Гарамани в виде формул (m обозначает маску дропаута):\n",
        "\n",
        "$$\n",
        "h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n",
        "$$\n",
        "\n",
        "Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n",
        "\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.068954Z",
          "start_time": "2021-04-02T00:05:13.971286Z"
        },
        "id": "2TWnKQECifvM"
      },
      "outputs": [],
      "source": [
        "def init_h0_c0(num_objects, hidden_size, some_existing_tensor):\n",
        "    \"\"\"\n",
        "    return h0 and c0, use some_existing_tensor.new_zeros() to gen them\n",
        "    h0 shape: num_objects x hidden_size\n",
        "    c0 shape: num_objects x hidden_size\n",
        "    \"\"\"\n",
        "    h0 = some_existing_tensor.new_zeros(num_objects, hidden_size)\n",
        "    c0 = some_existing_tensor.new_zeros(num_objects, hidden_size)\n",
        "    return h0, c0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.131347Z",
          "start_time": "2021-04-02T00:05:14.071577Z"
        },
        "id": "by3sm-W7ifvN"
      },
      "outputs": [],
      "source": [
        "def gen_dropout_mask(input_size, hidden_size, is_training, p, some_existing_tensor):\n",
        "    \"\"\"\n",
        "    is_training: if True, gen masks from Bernoulli\n",
        "                 if False, gen masks consisting of (1-p)\n",
        "\n",
        "    return dropout masks of size input_size, hidden_size if p is not None\n",
        "    return one masks if p is None\n",
        "    \"\"\"\n",
        "    if p is None:\n",
        "        return some_existing_tensor.new_ones(input_size), some_existing_tensor.new_ones(hidden_size)\n",
        "    if is_training:\n",
        "        m_h = torch.bernoulli((1 - p) * some_existing_tensor.new_ones(input_size))\n",
        "        m_x = torch.bernoulli((1 - p) * some_existing_tensor.new_ones(hidden_size))\n",
        "    else:\n",
        "        m_h = (1 - p) * some_existing_tensor.new_ones(input_size)\n",
        "        m_x = (1 - p) * some_existing_tensor.new_ones(hidden_size)\n",
        "    return m_h, m_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:09:12.282613Z",
          "start_time": "2021-04-01T21:09:12.256019Z"
        },
        "id": "kLjWw_IgifvN"
      },
      "source": [
        "Допишите класс-обёртку над `LSTMCell` для реализации Variational Dropout. **Используйте только цикл по времени**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISal7V6ifvN"
      },
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.190066Z",
          "start_time": "2021-04-02T00:05:14.132804Z"
        },
        "id": "ikOBBndeifvN"
      },
      "outputs": [],
      "source": [
        "class RNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.rnn_cell = torch.nn.LSTMCell(self.input_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize h_0, c_0\n",
        "        h0, c0 = init_h0_c0(x.size()[1], self.hidden_size, x)\n",
        "\n",
        "        # Gen masks for input and hidden state\n",
        "        m_x, m_h = gen_dropout_mask(self.input_size, self.hidden_size,\n",
        "                                    self.training, self.dropout, x)\n",
        "        # Implement recurrent logic and return what nn.LSTM returns\n",
        "        # Do not forget to apply generated dropout masks!\n",
        "        output_h = []\n",
        "        for i in range(x.size()[0]):\n",
        "            h0, c0 = self.rnn_cell(x[i] * m_x, (h0 * m_h, c0))\n",
        "            output_h.append(h0)\n",
        "        output_h = torch.stack(output_h, dim=0)\n",
        "        return output_h, (h0, c0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLx9dWNlifvN"
      },
      "source": [
        "Протестируйте реализованную модель с выключенным дропаутом (слой `RNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Сильно ли оно увеличилось по сравнению с `torch.nn.LSTM` (LSTM \"из коробки\")?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ9G0Vo4ifvN"
      },
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:04:19.104557Z",
          "start_time": "2021-04-01T21:50:02.992858Z"
        },
        "id": "t5e6CkJ9ifvO"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=RNNLayer, dropout=None\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FSg540Za_gv"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJ81tJWbDz6",
        "outputId": "392cac6f-5dc0-48ca-8a00-d4b5135b238e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.000/2.004. Accuracy (Train/Test): 0.239/0.238\n",
            "Epoch: 2/15. Loss (Train/Test): 1.729/1.752. Accuracy (Train/Test): 0.341/0.342\n",
            "Epoch: 3/15. Loss (Train/Test): 1.590/1.649. Accuracy (Train/Test): 0.381/0.362\n",
            "Epoch: 4/15. Loss (Train/Test): 1.551/1.638. Accuracy (Train/Test): 0.393/0.374\n",
            "Epoch: 5/15. Loss (Train/Test): 1.454/1.573. Accuracy (Train/Test): 0.433/0.387\n",
            "Epoch: 6/15. Loss (Train/Test): 1.413/1.576. Accuracy (Train/Test): 0.442/0.395\n",
            "Epoch: 7/15. Loss (Train/Test): 1.351/1.549. Accuracy (Train/Test): 0.464/0.399\n",
            "Epoch: 8/15. Loss (Train/Test): 1.294/1.558. Accuracy (Train/Test): 0.488/0.403\n",
            "Epoch: 9/15. Loss (Train/Test): 1.256/1.582. Accuracy (Train/Test): 0.510/0.394\n",
            "Epoch: 10/15. Loss (Train/Test): 1.189/1.611. Accuracy (Train/Test): 0.536/0.394\n",
            "Epoch: 11/15. Loss (Train/Test): 1.124/1.638. Accuracy (Train/Test): 0.564/0.389\n",
            "Epoch: 12/15. Loss (Train/Test): 1.065/1.707. Accuracy (Train/Test): 0.588/0.386\n",
            "Epoch: 13/15. Loss (Train/Test): 0.989/1.767. Accuracy (Train/Test): 0.624/0.380\n",
            "Epoch: 14/15. Loss (Train/Test): 0.909/1.863. Accuracy (Train/Test): 0.658/0.374\n",
            "Epoch: 15/15. Loss (Train/Test): 0.830/1.892. Accuracy (Train/Test): 0.694/0.376\n",
            "CPU times: user 3min 41s, sys: 169 ms, total: 3min 41s\n",
            "Wall time: 3min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses_do11, train_accuracies_do11, test_losses_do11, test_accuracies_do11 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUxj1KtvifvO"
      },
      "source": [
        "Протестируйте полученную модель с `dropout=0.25`, вновь замерив время обучения. Получилось ли побороть переобучение? Сильно ли дольше обучается данная модель по сравнению с предыдущей? (доп. время тратится на генерацию масок дропаута)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:18:28.301613Z",
          "start_time": "2021-04-01T22:04:19.107850Z"
        },
        "id": "_lj5N2KTifvO"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=RNNLayer, dropout=0.25\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz3_CJN_bpj9"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdtIO3pMbpsX",
        "outputId": "22d6e9d1-c0d1-4f1b-bdbc-7bfa2c31a289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.003/2.008. Accuracy (Train/Test): 0.233/0.231\n",
            "Epoch: 2/15. Loss (Train/Test): 1.810/1.819. Accuracy (Train/Test): 0.326/0.334\n",
            "Epoch: 3/15. Loss (Train/Test): 1.711/1.737. Accuracy (Train/Test): 0.351/0.351\n",
            "Epoch: 4/15. Loss (Train/Test): 1.635/1.678. Accuracy (Train/Test): 0.369/0.361\n",
            "Epoch: 5/15. Loss (Train/Test): 1.594/1.644. Accuracy (Train/Test): 0.378/0.370\n",
            "Epoch: 6/15. Loss (Train/Test): 1.547/1.608. Accuracy (Train/Test): 0.391/0.377\n",
            "Epoch: 7/15. Loss (Train/Test): 1.510/1.587. Accuracy (Train/Test): 0.407/0.385\n",
            "Epoch: 8/15. Loss (Train/Test): 1.470/1.565. Accuracy (Train/Test): 0.425/0.389\n",
            "Epoch: 9/15. Loss (Train/Test): 1.442/1.548. Accuracy (Train/Test): 0.432/0.395\n",
            "Epoch: 10/15. Loss (Train/Test): 1.417/1.539. Accuracy (Train/Test): 0.444/0.397\n",
            "Epoch: 11/15. Loss (Train/Test): 1.395/1.536. Accuracy (Train/Test): 0.455/0.396\n",
            "Epoch: 12/15. Loss (Train/Test): 1.371/1.528. Accuracy (Train/Test): 0.466/0.400\n",
            "Epoch: 13/15. Loss (Train/Test): 1.350/1.521. Accuracy (Train/Test): 0.472/0.402\n",
            "Epoch: 14/15. Loss (Train/Test): 1.347/1.533. Accuracy (Train/Test): 0.467/0.407\n",
            "Epoch: 15/15. Loss (Train/Test): 1.301/1.515. Accuracy (Train/Test): 0.491/0.408\n",
            "CPU times: user 3min 40s, sys: 192 ms, total: 3min 40s\n",
            "Wall time: 3min 41s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses_do12, train_accuracies_do12, test_losses_do12, test_accuracies_do12 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDS8Oal4ifvO"
      },
      "source": [
        "## `Реализация дропаута по статье Гала и Гарамани. Дубль 2 (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v6VGFnJifvP"
      },
      "source": [
        "<начало взлома pytorch>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElvEnSjQifvP"
      },
      "source": [
        "При разворачивании цикла по времени средствами python обучение рекуррентной нейросети сильно замедляется. Однако для реализации дропаута Гала и Гарамани необязательно явно задавать в коде умножение нейронов на маски. Можно схитрить и обойтись использованием слоя `torch.nn.LSTM`: перед вызовом `forward` слоя `torch.nn.LSTM` подменять его веса на веса, домноженные по строкам на маски. А обучаемые веса хранить отдельно. Именно так этот дропаут реализован в библиотеке `fastai`, код из которой использован в ячейке ниже.\n",
        "\n",
        "Такой слой реализуется в виде обертки над `torch.nn.LSTM`. Допишите класс:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.286206Z",
          "start_time": "2021-04-02T00:05:14.191730Z"
        },
        "id": "PIn6q5KRifvP"
      },
      "outputs": [],
      "source": [
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:06:54.953123Z",
          "start_time": "2021-04-02T02:06:54.917017Z"
        },
        "id": "jry8nZ9aifvP"
      },
      "outputs": [],
      "source": [
        "class FastRNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.0, layers_dropout=0.0, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.layers_dropout = layers_dropout\n",
        "        self.module = torch.nn.LSTM(input_size, hidden_size, dropout=layers_dropout, num_layers=num_layers)\n",
        "\n",
        "        self.layer_names = []\n",
        "        for layer_n in range(self.num_layers):\n",
        "            self.layer_names += [f'weight_hh_l{layer_n}', f'weight_ih_l{layer_n}']\n",
        "\n",
        "        for layer in self.layer_names:\n",
        "            # Get torch.nn.Parameter with weights from torch.nn.LSTM instance\n",
        "            w = getattr(self.module, layer)\n",
        "\n",
        "            # Remove it from model\n",
        "            delattr(self.module, layer)\n",
        "\n",
        "            # And create new torch.nn.Parameter with the same data but different name\n",
        "            self.register_parameter(f'{layer}_raw', torch.nn.Parameter(w.data))\n",
        "\n",
        "            # Note. In torch.nn.LSTM.forward parameter with name `layer` will be used\n",
        "            #     so we must initialize it using `layer_raw` before forward pass\n",
        "\n",
        "    def _setweights(self, x):\n",
        "        \"\"\"\n",
        "            Apply dropout to the raw weights.\n",
        "        \"\"\"\n",
        "        for layer in self.layer_names:\n",
        "            # Get torch.nn.Parameter with weights\n",
        "            raw_w = getattr(self, f'{layer}_raw')\n",
        "\n",
        "            # Generate mask (use function gen_dropout_mask)\n",
        "            m_x, m_h = gen_dropout_mask(raw_w.size(), self.hidden_size,\n",
        "                                    self.training, self.dropout, x)\n",
        "\n",
        "            # Apply dropout mask\n",
        "            masked_raw_w = raw_w * m_x\n",
        "\n",
        "            # Set modified weights in its place\n",
        "            setattr(self.module, layer, masked_raw_w)\n",
        "\n",
        "    def forward(self, x, h_c=None):\n",
        "        \"\"\"\n",
        "        :param x: tensor containing the features of the input sequence.\n",
        "        :param Optional[Tuple[torch.Tensor, torch.Tensor]] h_c: initial hidden state and initial cell state\n",
        "        \"\"\"\n",
        "        with warnings.catch_warnings():\n",
        "            # To avoid the warning that comes because the weights aren't flattened.\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            # Set new weights of self.module and call its forward\n",
        "            # Pass h_c with x if it is not None. Otherwise pass only x\n",
        "            self._setweights(x)\n",
        "            if h_c is None:\n",
        "                output = self.module(x)\n",
        "            else:\n",
        "                output = self.module(x, h_c)\n",
        "            return output\n",
        "\n",
        "    def reset(self):\n",
        "        if hasattr(self.module, 'reset'):\n",
        "            self.module.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqqLE9g4ifvQ"
      },
      "source": [
        "Протестируйте реализованную модель с выключенным дропаутом (слой `FastRNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Убедитесь, что модель выдаёт такое же качество, как и оригинальная реализация LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsBoRivEifvQ"
      },
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:25:23.843846Z",
          "start_time": "2021-04-01T22:22:43.059254Z"
        },
        "id": "KtnZrrHXifvQ"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=FastRNNLayer, dropout=None\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qnCV37bn2I0"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdZT4Za8n2Ps",
        "outputId": "b613705f-9ec4-42c9-c9a0-ba65389a29f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.956/1.961. Accuracy (Train/Test): 0.263/0.268\n",
            "Epoch: 2/15. Loss (Train/Test): 1.802/1.831. Accuracy (Train/Test): 0.327/0.327\n",
            "Epoch: 3/15. Loss (Train/Test): 1.633/1.681. Accuracy (Train/Test): 0.364/0.355\n",
            "Epoch: 4/15. Loss (Train/Test): 1.536/1.621. Accuracy (Train/Test): 0.400/0.373\n",
            "Epoch: 5/15. Loss (Train/Test): 1.489/1.607. Accuracy (Train/Test): 0.417/0.373\n",
            "Epoch: 6/15. Loss (Train/Test): 1.401/1.562. Accuracy (Train/Test): 0.449/0.392\n",
            "Epoch: 7/15. Loss (Train/Test): 1.358/1.564. Accuracy (Train/Test): 0.471/0.387\n",
            "Epoch: 8/15. Loss (Train/Test): 1.309/1.576. Accuracy (Train/Test): 0.486/0.381\n",
            "Epoch: 9/15. Loss (Train/Test): 1.252/1.609. Accuracy (Train/Test): 0.507/0.386\n",
            "Epoch: 10/15. Loss (Train/Test): 1.169/1.628. Accuracy (Train/Test): 0.542/0.386\n",
            "Epoch: 11/15. Loss (Train/Test): 1.128/1.669. Accuracy (Train/Test): 0.565/0.384\n",
            "Epoch: 12/15. Loss (Train/Test): 1.038/1.702. Accuracy (Train/Test): 0.608/0.376\n",
            "Epoch: 13/15. Loss (Train/Test): 0.963/1.756. Accuracy (Train/Test): 0.644/0.372\n",
            "Epoch: 14/15. Loss (Train/Test): 0.870/1.886. Accuracy (Train/Test): 0.682/0.365\n",
            "Epoch: 15/15. Loss (Train/Test): 0.795/1.978. Accuracy (Train/Test): 0.708/0.368\n",
            "CPU times: user 51.8 s, sys: 144 ms, total: 52 s\n",
            "Wall time: 52.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses_do21, train_accuracies_do21, test_losses_do21, test_accuracies_do21 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxUdmCYnifvQ"
      },
      "source": [
        "Протестируйте полученный слой (вновь подставив его в `RNNClassifier` в качестве `rec_layer`) с `dropout=0.25`. Сравните время обучения с предыдущими моделями. Проследите, чтобы качество получилось такое же, как при первой реализации этого дропаута."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:28:38.168777Z",
          "start_time": "2021-04-01T22:25:56.717326Z"
        },
        "id": "BzRZZsUjifvQ"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=FastRNNLayer, dropout=0.25\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRFXz5pGoLpG"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMkriv4noNif",
        "outputId": "468570f2-ced6-44fc-eae0-fe95e8d8660b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.981/1.986. Accuracy (Train/Test): 0.251/0.255\n",
            "Epoch: 2/15. Loss (Train/Test): 1.780/1.800. Accuracy (Train/Test): 0.329/0.330\n",
            "Epoch: 3/15. Loss (Train/Test): 1.657/1.701. Accuracy (Train/Test): 0.363/0.357\n",
            "Epoch: 4/15. Loss (Train/Test): 1.568/1.628. Accuracy (Train/Test): 0.393/0.375\n",
            "Epoch: 5/15. Loss (Train/Test): 1.518/1.615. Accuracy (Train/Test): 0.411/0.376\n",
            "Epoch: 6/15. Loss (Train/Test): 1.460/1.570. Accuracy (Train/Test): 0.426/0.390\n",
            "Epoch: 7/15. Loss (Train/Test): 1.420/1.552. Accuracy (Train/Test): 0.439/0.399\n",
            "Epoch: 8/15. Loss (Train/Test): 1.400/1.558. Accuracy (Train/Test): 0.444/0.393\n",
            "Epoch: 9/15. Loss (Train/Test): 1.369/1.562. Accuracy (Train/Test): 0.456/0.387\n",
            "Epoch: 10/15. Loss (Train/Test): 1.333/1.569. Accuracy (Train/Test): 0.471/0.400\n",
            "Epoch: 11/15. Loss (Train/Test): 1.310/1.556. Accuracy (Train/Test): 0.478/0.408\n",
            "Epoch: 12/15. Loss (Train/Test): 1.303/1.589. Accuracy (Train/Test): 0.484/0.396\n",
            "Epoch: 13/15. Loss (Train/Test): 1.266/1.585. Accuracy (Train/Test): 0.498/0.399\n",
            "Epoch: 14/15. Loss (Train/Test): 1.239/1.606. Accuracy (Train/Test): 0.508/0.397\n",
            "Epoch: 15/15. Loss (Train/Test): 1.219/1.617. Accuracy (Train/Test): 0.519/0.395\n",
            "CPU times: user 52.1 s, sys: 185 ms, total: 52.3 s\n",
            "Wall time: 52.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses_do22, train_accuracies_do22, test_losses_do22, test_accuracies_do22 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mNdvNyTifvQ"
      },
      "source": [
        "</конец взлома pytorch>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIeXYW9oifvR"
      },
      "source": [
        "## `Реализация дропаута по статье Семениуты и др. (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC5yZJc-ifvR"
      },
      "source": [
        "Перейдем к реализации дропаута для LSTM по статье [Semeniuta et al](http://www.aclweb.org/anthology/C16-1165).\n",
        "\n",
        "Этот метод применения дропаута не менее популярен, чем предыдущий. Его особенность состоит в том, что он придуман специально для гейтовых архитектур. В контексте LSTM этот дропаут накладывается только на информационный поток ($m_h$ — маска дропаута):\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot g \\odot {\\bf m_h} \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "На входы $x_t$ маска накладывается как в предыдущем дропауте. Впрочем, на входы маску можно наложить вообще до вызова рекуррентного слоя.\n",
        "\n",
        "Согласно статье, маска дропаута может быть как одинаковая, так и разная для всех моментов времени. Мы сделаем одинаковую для всех моментов времени.\n",
        "\n",
        "Для реализации этого дропаута можно:\n",
        "1. самостоятельно реализовать LSTM (интерфейса LSTMCell не хватит)\n",
        "2. снова воспользоваться трюком с установкой весов (но тут мы опираемся на свойство $tanh(0)=0$, к тому же, трюк в данном случае выглядит менее тривиально, чем с дропаутом Гала).\n",
        "\n",
        "Предлагается реализовать дропаут по сценарию 1. Допишите класс:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpvCpFVYifvR"
      },
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.447201Z",
          "start_time": "2021-04-02T00:05:14.350457Z"
        },
        "id": "0TQMAYIFifvR"
      },
      "outputs": [],
      "source": [
        "class HandmadeLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.input_weights = torch.nn.Linear(input_size, 4 * hidden_size)\n",
        "        self.hidden_weights = torch.nn.Linear(hidden_size, 4 * hidden_size)\n",
        "\n",
        "        self.reset_params()\n",
        "\n",
        "    def reset_params(self):\n",
        "        \"\"\"\n",
        "        Initialization as in Pytorch.\n",
        "        Do not forget to call this method!\n",
        "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\n",
        "        \"\"\"\n",
        "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use functions init_h0_c0 and gen_dropout_masks defined above\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "\n",
        "        # Implement recurrent logic to mimic torch.nn.LSTM\n",
        "        # Do not forget to apply dropout mask\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "        # Use functions init_h0_c0 and gen_dropout_masks defined above\n",
        "        (h0, c0) = init_h0_c0(x.size()[1], self.hidden_size, x)                   # torch.Size([64, 128])\n",
        "                                                                                  # torch.Size([64, 128])\n",
        "\n",
        "        m_x, m_h = gen_dropout_mask(self.input_size, self.hidden_size,            # torch.Size([128])\n",
        "                                    self.training, self.dropout, x)               # torch.Size([32])\n",
        "\n",
        "        # Implement recurrent logic to mimic torch.nn.LSTM\n",
        "        # Do not forget to apply dropout mask\n",
        "        output = []\n",
        "        for i in range(x.size()[0]):\n",
        "            iofg = self.hidden_weights(h0) + self.input_weights(x[i]*m_x)         # torch.Size([64, 512])\n",
        "            iof = torch.sigmoid(iofg[:, :3*self.hidden_size])                     # torch.Size([64, 384])\n",
        "            i = iof[:, :self.hidden_size]                                         # torch.Size([64, 128])\n",
        "            o = iof[:, self.hidden_size:2*self.hidden_size]                       # torch.Size([64, 128])\n",
        "            f = iof[:, 2*self.hidden_size:3*self.hidden_size]                     # torch.Size([64, 128])\n",
        "            g = torch.tanh(iofg[:, 3*self.hidden_size:])                          # torch.Size([64, 128])\n",
        "            c0 = f * c0 + i * g * m_h                                             # torch.Size([64, 128])\n",
        "            h0 = o * torch.tanh(c0)                                               # torch.Size([64, 128])\n",
        "            output.append(h0)\n",
        "        output = torch.stack(output, dim=0)                                       # torch.Size([200, 64, 128])\n",
        "        return output, (h0, c0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0GGZDlaifvR"
      },
      "source": [
        "Протестируйте вашу реализацию без дропаута (проконтролируйте качество и сравните время обучения с временем обучения `torch.nn.LSTM` и `RNNLayer`), а также с `dropout=0.25`. Сравните качество модели с таким дропаутом с качеством модели с дропаутом Гала и Гарамани."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgd7suYUifvR"
      },
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:01:53.046622Z",
          "start_time": "2021-04-01T22:30:08.733475Z"
        },
        "id": "_e6IYxA6ifvS"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=HandmadeLSTM, dropout=None\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTolsUHlpNg7"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "Sdx0HbygpTWl",
        "outputId": "0d82fa0c-83af-4ec0-fa05-7384e5704677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.931/1.937. Accuracy (Train/Test): 0.294/0.294\n",
            "Epoch: 2/15. Loss (Train/Test): 1.693/1.726. Accuracy (Train/Test): 0.351/0.350\n",
            "Epoch: 3/15. Loss (Train/Test): 1.632/1.695. Accuracy (Train/Test): 0.366/0.356\n",
            "Epoch: 4/15. Loss (Train/Test): 1.529/1.611. Accuracy (Train/Test): 0.402/0.376\n",
            "Epoch: 5/15. Loss (Train/Test): 1.457/1.581. Accuracy (Train/Test): 0.426/0.387\n",
            "Epoch: 6/15. Loss (Train/Test): 1.418/1.575. Accuracy (Train/Test): 0.442/0.389\n",
            "Epoch: 7/15. Loss (Train/Test): 1.367/1.588. Accuracy (Train/Test): 0.458/0.397\n",
            "Epoch: 8/15. Loss (Train/Test): 1.313/1.576. Accuracy (Train/Test): 0.481/0.396\n",
            "Epoch: 9/15. Loss (Train/Test): 1.257/1.597. Accuracy (Train/Test): 0.502/0.395\n",
            "Epoch: 10/15. Loss (Train/Test): 1.202/1.632. Accuracy (Train/Test): 0.525/0.390\n",
            "Epoch: 11/15. Loss (Train/Test): 1.155/1.678. Accuracy (Train/Test): 0.547/0.375\n",
            "Epoch: 12/15. Loss (Train/Test): 1.087/1.766. Accuracy (Train/Test): 0.577/0.379\n",
            "Epoch: 13/15. Loss (Train/Test): 1.019/1.764. Accuracy (Train/Test): 0.611/0.373\n",
            "Epoch: 14/15. Loss (Train/Test): 0.959/1.810. Accuracy (Train/Test): 0.638/0.365\n",
            "Epoch: 15/15. Loss (Train/Test): 0.885/1.916. Accuracy (Train/Test): 0.673/0.361\n",
            "CPU times: user 7min 52s, sys: 243 ms, total: 7min 52s\n",
            "Wall time: 7min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses_do31, train_accuracies_do31, test_losses_do31, test_accuracies_do31 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:33:28.808063Z",
          "start_time": "2021-04-01T23:01:53.049547Z"
        },
        "id": "beAvrTBuifvS"
      },
      "outputs": [],
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=HandmadeLSTM, dropout=0.25\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKsVy0P_qBGJ"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean').to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OJ0mDafqBNp",
        "outputId": "7e1a55e9-598e-453d-af0b-99d7e423ec00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.025/2.026. Accuracy (Train/Test): 0.220/0.226\n",
            "Epoch: 2/15. Loss (Train/Test): 1.993/1.996. Accuracy (Train/Test): 0.280/0.285\n",
            "Epoch: 3/15. Loss (Train/Test): 1.744/1.754. Accuracy (Train/Test): 0.338/0.344\n",
            "Epoch: 4/15. Loss (Train/Test): 1.656/1.676. Accuracy (Train/Test): 0.359/0.359\n",
            "Epoch: 5/15. Loss (Train/Test): 1.611/1.648. Accuracy (Train/Test): 0.374/0.367\n",
            "Epoch: 6/15. Loss (Train/Test): 1.581/1.640. Accuracy (Train/Test): 0.387/0.371\n",
            "Epoch: 7/15. Loss (Train/Test): 1.546/1.620. Accuracy (Train/Test): 0.395/0.370\n",
            "Epoch: 8/15. Loss (Train/Test): 1.492/1.576. Accuracy (Train/Test): 0.418/0.388\n",
            "Epoch: 9/15. Loss (Train/Test): 1.467/1.565. Accuracy (Train/Test): 0.428/0.391\n",
            "Epoch: 10/15. Loss (Train/Test): 1.436/1.552. Accuracy (Train/Test): 0.436/0.391\n",
            "Epoch: 11/15. Loss (Train/Test): 1.415/1.541. Accuracy (Train/Test): 0.439/0.402\n",
            "Epoch: 12/15. Loss (Train/Test): 1.411/1.555. Accuracy (Train/Test): 0.445/0.403\n",
            "Epoch: 13/15. Loss (Train/Test): 1.395/1.566. Accuracy (Train/Test): 0.452/0.404\n",
            "Epoch: 14/15. Loss (Train/Test): 1.353/1.523. Accuracy (Train/Test): 0.465/0.405\n",
            "Epoch: 15/15. Loss (Train/Test): 1.355/1.544. Accuracy (Train/Test): 0.466/0.408\n"
          ]
        }
      ],
      "source": [
        "train_losses_do32, train_accuracies_do32, test_losses_do32, test_accuracies_do32 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:33:28.831346Z",
          "start_time": "2021-04-01T23:33:28.810453Z"
        },
        "id": "FPNdb4VZifvS"
      },
      "source": [
        "## `Сравнение всех предложенных моделей (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:48:05.361634Z",
          "start_time": "2021-04-01T23:48:05.333901Z"
        },
        "id": "iY_FKT0UifvS"
      },
      "source": [
        "Используя замеры времени заполните табличку с временем работы четырёх реализованных моделей в следующей ячейке: (with drop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUJMedjGifvS"
      },
      "source": [
        "| torch.nn.LSTM | RNNLayer | FastRNNLayer | HandmadeLSTM |\n",
        "|---------------|----------|--------------|--------------|\n",
        "| 0m 51s        | 3m 41s  | 0m 43s       | 31m 44s      |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.722913Z",
          "start_time": "2021-04-02T00:05:14.448857Z"
        },
        "id": "aOSlS-iMifvS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLKf6AqVifvT"
      },
      "source": [
        "Крайне желательно рисовать графики в векторном формате.\n",
        "\n",
        "Если по каким-то причинам, отрисовка не будет работать, закомментируйте следующую ячейку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.745238Z",
          "start_time": "2021-04-02T00:05:14.724188Z"
        },
        "id": "h5TnekgQifvT",
        "outputId": "1a629a26-ccfa-471c-c723-5157f726de48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4801/2508521205.py:5: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('pdf', 'svg')\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import set_matplotlib_formats\n",
        "\n",
        "set_matplotlib_formats('pdf', 'svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLOlGSt1ifvT"
      },
      "source": [
        "Нарисуйте два графика — функция потерь и качество на обучающей и тестовой выборке для всех 7 моделей обученных выше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:40:37.809057Z",
          "start_time": "2021-04-01T23:40:36.694896Z"
        },
        "id": "AdCM22GjifvT",
        "outputId": "9db8e95a-6057-47a4-a074-ab5c79f3d3d6"
      },
      "outputs": [
        {
          "data": {
            "application/pdf": "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",
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"712.773125pt\" height=\"711.034375pt\" viewBox=\"0 0 712.773125 711.034375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
              " <metadata>\n",
              "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
              "   <cc:Work>\n",
              "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
              "    <dc:date>2023-04-27T17:03:54.245039</dc:date>\n",
              "    <dc:format>image/svg+xml</dc:format>\n",
              "    <dc:creator>\n",
              "     <cc:Agent>\n",
              "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
              "     </cc:Agent>\n",
              "    </dc:creator>\n",
              "   </cc:Work>\n",
              "  </rdf:RDF>\n",
              " </metadata>\n",
              " <defs>\n",
              "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
              " </defs>\n",
              " <g id=\"figure_1\">\n",
              "  <g id=\"patch_1\">\n",
              "   <path d=\"M 0 711.034375 \n",
              "L 712.773125 711.034375 \n",
              "L 712.773125 0 \n",
              "L 0 0 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "  </g>\n",
              "  <g id=\"axes_1\">\n",
              "   <g id=\"patch_2\">\n",
              "    <path d=\"M 30.103125 318.878125 \n",
              "L 705.573125 318.878125 \n",
              "L 705.573125 22.318125 \n",
              "L 30.103125 22.318125 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_1\">\n",
              "    <g id=\"xtick_1\">\n",
              "     <g id=\"line2d_1\">\n",
              "      <path d=\"M 104.667995 318.878125 \n",
              "L 104.667995 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_2\">\n",
              "      <defs>\n",
              "       <path id=\"m5ef2147839\" d=\"M 0 0 \n",
              "L 0 3.5 \n",
              "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </defs>\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"104.667995\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_1\">\n",
              "      <!-- 2 -->\n",
              "      <g transform=\"translate(101.486745 333.476562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
              "L 3431 531 \n",
              "L 3431 0 \n",
              "L 469 0 \n",
              "L 469 531 \n",
              "Q 828 903 1448 1529 \n",
              "Q 2069 2156 2228 2338 \n",
              "Q 2531 2678 2651 2914 \n",
              "Q 2772 3150 2772 3378 \n",
              "Q 2772 3750 2511 3984 \n",
              "Q 2250 4219 1831 4219 \n",
              "Q 1534 4219 1204 4116 \n",
              "Q 875 4013 500 3803 \n",
              "L 500 4441 \n",
              "Q 881 4594 1212 4672 \n",
              "Q 1544 4750 1819 4750 \n",
              "Q 2544 4750 2975 4387 \n",
              "Q 3406 4025 3406 3419 \n",
              "Q 3406 3131 3298 2873 \n",
              "Q 3191 2616 2906 2266 \n",
              "Q 2828 2175 2409 1742 \n",
              "Q 1991 1309 1228 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_2\">\n",
              "     <g id=\"line2d_3\">\n",
              "      <path d=\"M 192.391372 318.878125 \n",
              "L 192.391372 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_4\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"192.391372\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_2\">\n",
              "      <!-- 4 -->\n",
              "      <g transform=\"translate(189.210122 333.476562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
              "L 825 1625 \n",
              "L 2419 1625 \n",
              "L 2419 4116 \n",
              "z\n",
              "M 2253 4666 \n",
              "L 3047 4666 \n",
              "L 3047 1625 \n",
              "L 3713 1625 \n",
              "L 3713 1100 \n",
              "L 3047 1100 \n",
              "L 3047 0 \n",
              "L 2419 0 \n",
              "L 2419 1100 \n",
              "L 313 1100 \n",
              "L 313 1709 \n",
              "L 2253 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_3\">\n",
              "     <g id=\"line2d_5\">\n",
              "      <path d=\"M 280.114748 318.878125 \n",
              "L 280.114748 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_6\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"280.114748\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_3\">\n",
              "      <!-- 6 -->\n",
              "      <g transform=\"translate(276.933498 333.476562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
              "Q 1688 2584 1439 2293 \n",
              "Q 1191 2003 1191 1497 \n",
              "Q 1191 994 1439 701 \n",
              "Q 1688 409 2113 409 \n",
              "Q 2538 409 2786 701 \n",
              "Q 3034 994 3034 1497 \n",
              "Q 3034 2003 2786 2293 \n",
              "Q 2538 2584 2113 2584 \n",
              "z\n",
              "M 3366 4563 \n",
              "L 3366 3988 \n",
              "Q 3128 4100 2886 4159 \n",
              "Q 2644 4219 2406 4219 \n",
              "Q 1781 4219 1451 3797 \n",
              "Q 1122 3375 1075 2522 \n",
              "Q 1259 2794 1537 2939 \n",
              "Q 1816 3084 2150 3084 \n",
              "Q 2853 3084 3261 2657 \n",
              "Q 3669 2231 3669 1497 \n",
              "Q 3669 778 3244 343 \n",
              "Q 2819 -91 2113 -91 \n",
              "Q 1303 -91 875 529 \n",
              "Q 447 1150 447 2328 \n",
              "Q 447 3434 972 4092 \n",
              "Q 1497 4750 2381 4750 \n",
              "Q 2619 4750 2861 4703 \n",
              "Q 3103 4656 3366 4563 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_4\">\n",
              "     <g id=\"line2d_7\">\n",
              "      <path d=\"M 367.838125 318.878125 \n",
              "L 367.838125 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_8\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"367.838125\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_4\">\n",
              "      <!-- 8 -->\n",
              "      <g transform=\"translate(364.656875 333.476562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
              "Q 1584 2216 1326 1975 \n",
              "Q 1069 1734 1069 1313 \n",
              "Q 1069 891 1326 650 \n",
              "Q 1584 409 2034 409 \n",
              "Q 2484 409 2743 651 \n",
              "Q 3003 894 3003 1313 \n",
              "Q 3003 1734 2745 1975 \n",
              "Q 2488 2216 2034 2216 \n",
              "z\n",
              "M 1403 2484 \n",
              "Q 997 2584 770 2862 \n",
              "Q 544 3141 544 3541 \n",
              "Q 544 4100 942 4425 \n",
              "Q 1341 4750 2034 4750 \n",
              "Q 2731 4750 3128 4425 \n",
              "Q 3525 4100 3525 3541 \n",
              "Q 3525 3141 3298 2862 \n",
              "Q 3072 2584 2669 2484 \n",
              "Q 3125 2378 3379 2068 \n",
              "Q 3634 1759 3634 1313 \n",
              "Q 3634 634 3220 271 \n",
              "Q 2806 -91 2034 -91 \n",
              "Q 1263 -91 848 271 \n",
              "Q 434 634 434 1313 \n",
              "Q 434 1759 690 2068 \n",
              "Q 947 2378 1403 2484 \n",
              "z\n",
              "M 1172 3481 \n",
              "Q 1172 3119 1398 2916 \n",
              "Q 1625 2713 2034 2713 \n",
              "Q 2441 2713 2670 2916 \n",
              "Q 2900 3119 2900 3481 \n",
              "Q 2900 3844 2670 4047 \n",
              "Q 2441 4250 2034 4250 \n",
              "Q 1625 4250 1398 4047 \n",
              "Q 1172 3844 1172 3481 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_5\">\n",
              "     <g id=\"line2d_9\">\n",
              "      <path d=\"M 455.561502 318.878125 \n",
              "L 455.561502 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_10\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"455.561502\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_5\">\n",
              "      <!-- 10 -->\n",
              "      <g transform=\"translate(449.199002 333.476562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
              "L 1825 531 \n",
              "L 1825 4091 \n",
              "L 703 3866 \n",
              "L 703 4441 \n",
              "L 1819 4666 \n",
              "L 2450 4666 \n",
              "L 2450 531 \n",
              "L 3481 531 \n",
              "L 3481 0 \n",
              "L 794 0 \n",
              "L 794 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
              "Q 1547 4250 1301 3770 \n",
              "Q 1056 3291 1056 2328 \n",
              "Q 1056 1369 1301 889 \n",
              "Q 1547 409 2034 409 \n",
              "Q 2525 409 2770 889 \n",
              "Q 3016 1369 3016 2328 \n",
              "Q 3016 3291 2770 3770 \n",
              "Q 2525 4250 2034 4250 \n",
              "z\n",
              "M 2034 4750 \n",
              "Q 2819 4750 3233 4129 \n",
              "Q 3647 3509 3647 2328 \n",
              "Q 3647 1150 3233 529 \n",
              "Q 2819 -91 2034 -91 \n",
              "Q 1250 -91 836 529 \n",
              "Q 422 1150 422 2328 \n",
              "Q 422 3509 836 4129 \n",
              "Q 1250 4750 2034 4750 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_6\">\n",
              "     <g id=\"line2d_11\">\n",
              "      <path d=\"M 543.284878 318.878125 \n",
              "L 543.284878 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_12\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"543.284878\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_6\">\n",
              "      <!-- 12 -->\n",
              "      <g transform=\"translate(536.922378 333.476562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_7\">\n",
              "     <g id=\"line2d_13\">\n",
              "      <path d=\"M 631.008255 318.878125 \n",
              "L 631.008255 22.318125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_14\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"631.008255\" y=\"318.878125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_7\">\n",
              "      <!-- 14 -->\n",
              "      <g transform=\"translate(624.645755 333.476562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_8\">\n",
              "     <!-- Epoch -->\n",
              "     <g transform=\"translate(352.527187 347.154687) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \n",
              "L 3578 4666 \n",
              "L 3578 4134 \n",
              "L 1259 4134 \n",
              "L 1259 2753 \n",
              "L 3481 2753 \n",
              "L 3481 2222 \n",
              "L 1259 2222 \n",
              "L 1259 531 \n",
              "L 3634 531 \n",
              "L 3634 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
              "L 1159 -1331 \n",
              "L 581 -1331 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2969 \n",
              "Q 1341 3281 1617 3432 \n",
              "Q 1894 3584 2278 3584 \n",
              "Q 2916 3584 3314 3078 \n",
              "Q 3713 2572 3713 1747 \n",
              "Q 3713 922 3314 415 \n",
              "Q 2916 -91 2278 -91 \n",
              "Q 1894 -91 1617 61 \n",
              "Q 1341 213 1159 525 \n",
              "z\n",
              "M 3116 1747 \n",
              "Q 3116 2381 2855 2742 \n",
              "Q 2594 3103 2138 3103 \n",
              "Q 1681 3103 1420 2742 \n",
              "Q 1159 2381 1159 1747 \n",
              "Q 1159 1113 1420 752 \n",
              "Q 1681 391 2138 391 \n",
              "Q 2594 391 2855 752 \n",
              "Q 3116 1113 3116 1747 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
              "Q 1497 3097 1228 2736 \n",
              "Q 959 2375 959 1747 \n",
              "Q 959 1119 1226 758 \n",
              "Q 1494 397 1959 397 \n",
              "Q 2419 397 2687 759 \n",
              "Q 2956 1122 2956 1747 \n",
              "Q 2956 2369 2687 2733 \n",
              "Q 2419 3097 1959 3097 \n",
              "z\n",
              "M 1959 3584 \n",
              "Q 2709 3584 3137 3096 \n",
              "Q 3566 2609 3566 1747 \n",
              "Q 3566 888 3137 398 \n",
              "Q 2709 -91 1959 -91 \n",
              "Q 1206 -91 779 398 \n",
              "Q 353 888 353 1747 \n",
              "Q 353 2609 779 3096 \n",
              "Q 1206 3584 1959 3584 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
              "L 3122 2828 \n",
              "Q 2878 2963 2633 3030 \n",
              "Q 2388 3097 2138 3097 \n",
              "Q 1578 3097 1268 2742 \n",
              "Q 959 2388 959 1747 \n",
              "Q 959 1106 1268 751 \n",
              "Q 1578 397 2138 397 \n",
              "Q 2388 397 2633 464 \n",
              "Q 2878 531 3122 666 \n",
              "L 3122 134 \n",
              "Q 2881 22 2623 -34 \n",
              "Q 2366 -91 2075 -91 \n",
              "Q 1284 -91 818 406 \n",
              "Q 353 903 353 1747 \n",
              "Q 353 2603 823 3093 \n",
              "Q 1294 3584 2113 3584 \n",
              "Q 2378 3584 2631 3529 \n",
              "Q 2884 3475 3122 3366 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
              "L 3513 0 \n",
              "L 2938 0 \n",
              "L 2938 2094 \n",
              "Q 2938 2591 2744 2837 \n",
              "Q 2550 3084 2163 3084 \n",
              "Q 1697 3084 1428 2787 \n",
              "Q 1159 2491 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 4863 \n",
              "L 1159 4863 \n",
              "L 1159 2956 \n",
              "Q 1366 3272 1645 3428 \n",
              "Q 1925 3584 2291 3584 \n",
              "Q 2894 3584 3203 3211 \n",
              "Q 3513 2838 3513 2113 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_2\">\n",
              "    <g id=\"ytick_1\">\n",
              "     <g id=\"line2d_15\">\n",
              "      <path d=\"M 30.103125 304.216272 \n",
              "L 705.573125 304.216272 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_16\">\n",
              "      <defs>\n",
              "       <path id=\"me0d5dda10c\" d=\"M 0 0 \n",
              "L -3.5 0 \n",
              "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </defs>\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"304.216272\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_9\">\n",
              "      <!-- 0.8 -->\n",
              "      <g transform=\"translate(7.2 308.015491) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
              "L 1344 794 \n",
              "L 1344 0 \n",
              "L 684 0 \n",
              "L 684 794 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_2\">\n",
              "     <g id=\"line2d_17\">\n",
              "      <path d=\"M 30.103125 260.420028 \n",
              "L 705.573125 260.420028 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_18\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"260.420028\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_10\">\n",
              "      <!-- 1.0 -->\n",
              "      <g transform=\"translate(7.2 264.219246) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_3\">\n",
              "     <g id=\"line2d_19\">\n",
              "      <path d=\"M 30.103125 216.623783 \n",
              "L 705.573125 216.623783 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_20\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"216.623783\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_11\">\n",
              "      <!-- 1.2 -->\n",
              "      <g transform=\"translate(7.2 220.423002) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_4\">\n",
              "     <g id=\"line2d_21\">\n",
              "      <path d=\"M 30.103125 172.827538 \n",
              "L 705.573125 172.827538 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_22\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"172.827538\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_12\">\n",
              "      <!-- 1.4 -->\n",
              "      <g transform=\"translate(7.2 176.626757) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_5\">\n",
              "     <g id=\"line2d_23\">\n",
              "      <path d=\"M 30.103125 129.031294 \n",
              "L 705.573125 129.031294 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_24\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"129.031294\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_13\">\n",
              "      <!-- 1.6 -->\n",
              "      <g transform=\"translate(7.2 132.830512) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_6\">\n",
              "     <g id=\"line2d_25\">\n",
              "      <path d=\"M 30.103125 85.235049 \n",
              "L 705.573125 85.235049 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_26\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"85.235049\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_14\">\n",
              "      <!-- 1.8 -->\n",
              "      <g transform=\"translate(7.2 89.034268) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_7\">\n",
              "     <g id=\"line2d_27\">\n",
              "      <path d=\"M 30.103125 41.438804 \n",
              "L 705.573125 41.438804 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_28\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"41.438804\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_15\">\n",
              "      <!-- 2.0 -->\n",
              "      <g transform=\"translate(7.2 45.238023) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_29\">\n",
              "    <path d=\"M 60.806307 48.095304 \n",
              "L 104.667995 45.377323 \n",
              "L 148.529683 109.658658 \n",
              "L 192.391372 136.753484 \n",
              "L 236.25306 153.621068 \n",
              "L 280.114748 161.813823 \n",
              "L 323.976437 177.16322 \n",
              "L 367.838125 187.64708 \n",
              "L 411.699813 196.734791 \n",
              "L 455.561502 207.264023 \n",
              "L 499.42319 225.630457 \n",
              "L 543.284878 239.464422 \n",
              "L 587.146567 255.354389 \n",
              "L 631.008255 274.926184 \n",
              "L 674.869943 292.384678 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_30\">\n",
              "    <path d=\"M 60.806307 47.264717 \n",
              "L 104.667995 43.014818 \n",
              "L 148.529683 102.286187 \n",
              "L 192.391372 121.95325 \n",
              "L 236.25306 132.421875 \n",
              "L 280.114748 133.562345 \n",
              "L 323.976437 134.972288 \n",
              "L 367.838125 133.154464 \n",
              "L 411.699813 132.418559 \n",
              "L 455.561502 127.113494 \n",
              "L 499.42319 122.732862 \n",
              "L 543.284878 114.712814 \n",
              "L 587.146567 101.018234 \n",
              "L 631.008255 85.927324 \n",
              "L 674.869943 62.692848 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_31\">\n",
              "    <path d=\"M 60.806307 41.36611 \n",
              "L 104.667995 100.756885 \n",
              "L 148.529683 131.154236 \n",
              "L 192.391372 139.690893 \n",
              "L 236.25306 160.976898 \n",
              "L 280.114748 169.939185 \n",
              "L 323.976437 183.488951 \n",
              "L 367.838125 196.122027 \n",
              "L 411.699813 204.285014 \n",
              "L 455.561502 219.136684 \n",
              "L 499.42319 233.338647 \n",
              "L 543.284878 246.214799 \n",
              "L 587.146567 262.760058 \n",
              "L 631.008255 280.36661 \n",
              "L 674.869943 297.74045 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #ff0000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_32\">\n",
              "    <path d=\"M 60.806307 40.509648 \n",
              "L 104.667995 95.782905 \n",
              "L 148.529683 118.313021 \n",
              "L 192.391372 120.767237 \n",
              "L 236.25306 135.028378 \n",
              "L 280.114748 134.345429 \n",
              "L 323.976437 140.295224 \n",
              "L 367.838125 138.132166 \n",
              "L 411.699813 132.952526 \n",
              "L 455.561502 126.570908 \n",
              "L 499.42319 120.755198 \n",
              "L 543.284878 105.705395 \n",
              "L 587.146567 92.539171 \n",
              "L 631.008255 71.428144 \n",
              "L 674.869943 65.129913 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_33\">\n",
              "    <path d=\"M 60.806307 40.745247 \n",
              "L 104.667995 83.006029 \n",
              "L 148.529683 104.637639 \n",
              "L 192.391372 121.298042 \n",
              "L 236.25306 130.291516 \n",
              "L 280.114748 140.640406 \n",
              "L 323.976437 148.825692 \n",
              "L 367.838125 157.457734 \n",
              "L 411.699813 163.672304 \n",
              "L 455.561502 169.1127 \n",
              "L 499.42319 173.923536 \n",
              "L 543.284878 179.185747 \n",
              "L 587.146567 183.684475 \n",
              "L 631.008255 184.517532 \n",
              "L 674.869943 194.558093 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #ffa500; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_34\">\n",
              "    <path d=\"M 60.806307 39.746191 \n",
              "L 104.667995 81.172632 \n",
              "L 148.529683 99.113095 \n",
              "L 192.391372 111.854144 \n",
              "L 236.25306 119.349385 \n",
              "L 280.114748 127.297606 \n",
              "L 323.976437 131.986516 \n",
              "L 367.838125 136.60788 \n",
              "L 411.699813 140.485742 \n",
              "L 455.561502 142.318395 \n",
              "L 499.42319 142.959089 \n",
              "L 543.284878 144.758583 \n",
              "L 587.146567 146.344907 \n",
              "L 631.008255 143.670638 \n",
              "L 674.869943 147.673691 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ffa500; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_35\">\n",
              "    <path d=\"M 60.806307 51.145673 \n",
              "L 104.667995 84.693107 \n",
              "L 148.529683 121.720127 \n",
              "L 192.391372 142.981725 \n",
              "L 236.25306 153.23957 \n",
              "L 280.114748 172.683745 \n",
              "L 323.976437 182.101212 \n",
              "L 367.838125 192.845741 \n",
              "L 411.699813 205.329867 \n",
              "L 455.561502 223.348409 \n",
              "L 499.42319 232.450344 \n",
              "L 543.284878 252.114117 \n",
              "L 587.146567 268.499482 \n",
              "L 631.008255 288.956723 \n",
              "L 674.869943 305.398125 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_36\">\n",
              "    <path d=\"M 60.806307 50.025032 \n",
              "L 104.667995 78.378494 \n",
              "L 148.529683 111.3074 \n",
              "L 192.391372 124.364047 \n",
              "L 236.25306 127.552355 \n",
              "L 280.114748 137.39851 \n",
              "L 323.976437 136.954425 \n",
              "L 367.838125 134.198083 \n",
              "L 411.699813 127.152727 \n",
              "L 455.561502 122.990319 \n",
              "L 499.42319 113.988564 \n",
              "L 543.284878 106.670096 \n",
              "L 587.146567 94.780888 \n",
              "L 631.008255 66.298355 \n",
              "L 674.869943 46.188009 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_37\">\n",
              "    <path d=\"M 60.806307 45.603318 \n",
              "L 104.667995 89.574633 \n",
              "L 148.529683 116.65268 \n",
              "L 192.391372 136.094099 \n",
              "L 236.25306 146.900611 \n",
              "L 280.114748 159.746684 \n",
              "L 323.976437 168.481869 \n",
              "L 367.838125 172.768436 \n",
              "L 411.699813 179.654151 \n",
              "L 455.561502 187.391422 \n",
              "L 499.42319 192.573282 \n",
              "L 543.284878 194.062015 \n",
              "L 587.146567 202.191737 \n",
              "L 631.008255 208.182614 \n",
              "L 674.869943 212.463172 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_38\">\n",
              "    <path d=\"M 60.806307 44.487165 \n",
              "L 104.667995 85.182981 \n",
              "L 148.529683 106.838075 \n",
              "L 192.391372 122.900791 \n",
              "L 236.25306 125.811438 \n",
              "L 280.114748 135.52127 \n",
              "L 323.976437 139.520203 \n",
              "L 367.838125 138.121349 \n",
              "L 411.699813 137.297379 \n",
              "L 455.561502 135.750715 \n",
              "L 499.42319 138.57206 \n",
              "L 543.284878 131.525799 \n",
              "L 587.146567 132.329965 \n",
              "L 631.008255 127.776879 \n",
              "L 674.869943 125.226062 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_39\">\n",
              "    <path d=\"M 60.806307 56.531435 \n",
              "L 104.667995 108.71482 \n",
              "L 148.529683 121.933465 \n",
              "L 192.391372 144.611219 \n",
              "L 236.25306 160.294193 \n",
              "L 280.114748 168.959741 \n",
              "L 323.976437 180.049381 \n",
              "L 367.838125 191.902559 \n",
              "L 411.699813 204.170735 \n",
              "L 455.561502 216.21302 \n",
              "L 499.42319 226.390833 \n",
              "L 543.284878 241.428251 \n",
              "L 587.146567 256.350852 \n",
              "L 631.008255 269.372065 \n",
              "L 674.869943 285.588324 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_40\">\n",
              "    <path d=\"M 60.806307 55.326563 \n",
              "L 104.667995 101.49946 \n",
              "L 148.529683 108.173179 \n",
              "L 192.391372 126.71624 \n",
              "L 236.25306 133.123486 \n",
              "L 280.114748 134.59906 \n",
              "L 323.976437 131.742012 \n",
              "L 367.838125 134.187801 \n",
              "L 411.699813 129.781344 \n",
              "L 455.561502 122.056011 \n",
              "L 499.42319 112.046938 \n",
              "L 543.284878 92.684034 \n",
              "L 587.146567 93.022381 \n",
              "L 631.008255 83.032797 \n",
              "L 674.869943 59.797485 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_41\">\n",
              "    <path d=\"M 60.806307 35.968727 \n",
              "L 104.667995 43.064821 \n",
              "L 148.529683 97.450578 \n",
              "L 192.391372 116.831382 \n",
              "L 236.25306 126.729523 \n",
              "L 280.114748 133.163961 \n",
              "L 323.976437 140.905368 \n",
              "L 367.838125 152.723107 \n",
              "L 411.699813 158.261466 \n",
              "L 455.561502 164.918906 \n",
              "L 499.42319 169.475854 \n",
              "L 543.284878 170.492557 \n",
              "L 587.146567 173.857308 \n",
              "L 631.008255 183.053082 \n",
              "L 674.869943 182.768111 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_42\">\n",
              "    <path d=\"M 60.806307 35.798125 \n",
              "L 104.667995 42.234708 \n",
              "L 148.529683 95.318496 \n",
              "L 192.391372 112.316684 \n",
              "L 236.25306 118.521998 \n",
              "L 280.114748 120.28941 \n",
              "L 323.976437 124.671182 \n",
              "L 367.838125 134.381858 \n",
              "L 411.699813 136.595835 \n",
              "L 455.561502 139.632189 \n",
              "L 499.42319 141.9773 \n",
              "L 543.284878 138.935163 \n",
              "L 587.146567 136.473876 \n",
              "L 631.008255 145.858744 \n",
              "L 674.869943 141.242168 \n",
              "\" clip-path=\"url(#p472d2898ee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_3\">\n",
              "    <path d=\"M 30.103125 318.878125 \n",
              "L 30.103125 22.318125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_4\">\n",
              "    <path d=\"M 705.573125 318.878125 \n",
              "L 705.573125 22.318125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_5\">\n",
              "    <path d=\"M 30.103125 318.878125 \n",
              "L 705.573125 318.878125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_6\">\n",
              "    <path d=\"M 30.103125 22.318125 \n",
              "L 705.573125 22.318125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_16\">\n",
              "    <!-- CrossEntropy Loss -->\n",
              "    <g transform=\"translate(313.017812 16.318125) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
              "L 4122 3641 \n",
              "Q 3803 3938 3442 4084 \n",
              "Q 3081 4231 2675 4231 \n",
              "Q 1875 4231 1450 3742 \n",
              "Q 1025 3253 1025 2328 \n",
              "Q 1025 1406 1450 917 \n",
              "Q 1875 428 2675 428 \n",
              "Q 3081 428 3442 575 \n",
              "Q 3803 722 4122 1019 \n",
              "L 4122 359 \n",
              "Q 3791 134 3420 21 \n",
              "Q 3050 -91 2638 -91 \n",
              "Q 1578 -91 968 557 \n",
              "Q 359 1206 359 2328 \n",
              "Q 359 3453 968 4101 \n",
              "Q 1578 4750 2638 4750 \n",
              "Q 3056 4750 3426 4639 \n",
              "Q 3797 4528 4122 4306 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
              "Q 2534 3019 2420 3045 \n",
              "Q 2306 3072 2169 3072 \n",
              "Q 1681 3072 1420 2755 \n",
              "Q 1159 2438 1159 1844 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1341 3275 1631 3429 \n",
              "Q 1922 3584 2338 3584 \n",
              "Q 2397 3584 2469 3576 \n",
              "Q 2541 3569 2628 3553 \n",
              "L 2631 2963 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
              "L 2834 2853 \n",
              "Q 2591 2978 2328 3040 \n",
              "Q 2066 3103 1784 3103 \n",
              "Q 1356 3103 1142 2972 \n",
              "Q 928 2841 928 2578 \n",
              "Q 928 2378 1081 2264 \n",
              "Q 1234 2150 1697 2047 \n",
              "L 1894 2003 \n",
              "Q 2506 1872 2764 1633 \n",
              "Q 3022 1394 3022 966 \n",
              "Q 3022 478 2636 193 \n",
              "Q 2250 -91 1575 -91 \n",
              "Q 1294 -91 989 -36 \n",
              "Q 684 19 347 128 \n",
              "L 347 722 \n",
              "Q 666 556 975 473 \n",
              "Q 1284 391 1588 391 \n",
              "Q 1994 391 2212 530 \n",
              "Q 2431 669 2431 922 \n",
              "Q 2431 1156 2273 1281 \n",
              "Q 2116 1406 1581 1522 \n",
              "L 1381 1569 \n",
              "Q 847 1681 609 1914 \n",
              "Q 372 2147 372 2553 \n",
              "Q 372 3047 722 3315 \n",
              "Q 1072 3584 1716 3584 \n",
              "Q 2034 3584 2315 3537 \n",
              "Q 2597 3491 2834 3397 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
              "L 3513 0 \n",
              "L 2938 0 \n",
              "L 2938 2094 \n",
              "Q 2938 2591 2744 2837 \n",
              "Q 2550 3084 2163 3084 \n",
              "Q 1697 3084 1428 2787 \n",
              "Q 1159 2491 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1366 3272 1645 3428 \n",
              "Q 1925 3584 2291 3584 \n",
              "Q 2894 3584 3203 3211 \n",
              "Q 3513 2838 3513 2113 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
              "L 1172 3500 \n",
              "L 2356 3500 \n",
              "L 2356 3053 \n",
              "L 1172 3053 \n",
              "L 1172 1153 \n",
              "Q 1172 725 1289 603 \n",
              "Q 1406 481 1766 481 \n",
              "L 2356 481 \n",
              "L 2356 0 \n",
              "L 1766 0 \n",
              "Q 1100 0 847 248 \n",
              "Q 594 497 594 1153 \n",
              "L 594 3053 \n",
              "L 172 3053 \n",
              "L 172 3500 \n",
              "L 594 3500 \n",
              "L 594 4494 \n",
              "L 1172 4494 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
              "Q 1816 -950 1584 -1140 \n",
              "Q 1353 -1331 966 -1331 \n",
              "L 506 -1331 \n",
              "L 506 -850 \n",
              "L 844 -850 \n",
              "Q 1081 -850 1212 -737 \n",
              "Q 1344 -625 1503 -206 \n",
              "L 1606 56 \n",
              "L 191 3500 \n",
              "L 800 3500 \n",
              "L 1894 763 \n",
              "L 2988 3500 \n",
              "L 3597 3500 \n",
              "L 2059 -325 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
              "L 1259 4666 \n",
              "L 1259 531 \n",
              "L 3531 531 \n",
              "L 3531 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#DejaVuSans-43\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"69.824219\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"108.6875\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"169.869141\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"221.96875\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-45\" x=\"274.068359\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6e\" x=\"337.251953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-74\" x=\"400.630859\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"439.839844\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"478.703125\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-70\" x=\"539.884766\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-79\" x=\"603.361328\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"662.541016\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-4c\" x=\"694.328125\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"748.291016\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"809.472656\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"861.572266\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_1\">\n",
              "    <g id=\"patch_7\">\n",
              "     <path d=\"M 37.103125 313.878125 \n",
              "L 160.320313 313.878125 \n",
              "Q 162.320313 313.878125 162.320313 311.878125 \n",
              "L 162.320313 107.384375 \n",
              "Q 162.320313 105.384375 160.320313 105.384375 \n",
              "L 37.103125 105.384375 \n",
              "Q 35.103125 105.384375 35.103125 107.384375 \n",
              "L 35.103125 311.878125 \n",
              "Q 35.103125 313.878125 37.103125 313.878125 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_43\">\n",
              "     <path d=\"M 39.103125 113.482812 \n",
              "L 49.103125 113.482812 \n",
              "L 59.103125 113.482812 \n",
              "\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_17\">\n",
              "     <!-- Base -->\n",
              "     <g transform=\"translate(67.103125 116.982812) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-42\" d=\"M 1259 2228 \n",
              "L 1259 519 \n",
              "L 2272 519 \n",
              "Q 2781 519 3026 730 \n",
              "Q 3272 941 3272 1375 \n",
              "Q 3272 1813 3026 2020 \n",
              "Q 2781 2228 2272 2228 \n",
              "L 1259 2228 \n",
              "z\n",
              "M 1259 4147 \n",
              "L 1259 2741 \n",
              "L 2194 2741 \n",
              "Q 2656 2741 2882 2914 \n",
              "Q 3109 3088 3109 3444 \n",
              "Q 3109 3797 2882 3972 \n",
              "Q 2656 4147 2194 4147 \n",
              "L 1259 4147 \n",
              "z\n",
              "M 628 4666 \n",
              "L 2241 4666 \n",
              "Q 2963 4666 3353 4366 \n",
              "Q 3744 4066 3744 3513 \n",
              "Q 3744 3084 3544 2831 \n",
              "Q 3344 2578 2956 2516 \n",
              "Q 3422 2416 3680 2098 \n",
              "Q 3938 1781 3938 1306 \n",
              "Q 3938 681 3513 340 \n",
              "Q 3088 0 2303 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
              "Q 1497 1759 1228 1600 \n",
              "Q 959 1441 959 1056 \n",
              "Q 959 750 1161 570 \n",
              "Q 1363 391 1709 391 \n",
              "Q 2188 391 2477 730 \n",
              "Q 2766 1069 2766 1631 \n",
              "L 2766 1759 \n",
              "L 2194 1759 \n",
              "z\n",
              "M 3341 1997 \n",
              "L 3341 0 \n",
              "L 2766 0 \n",
              "L 2766 531 \n",
              "Q 2569 213 2275 61 \n",
              "Q 1981 -91 1556 -91 \n",
              "Q 1019 -91 701 211 \n",
              "Q 384 513 384 1019 \n",
              "Q 384 1609 779 1909 \n",
              "Q 1175 2209 1959 2209 \n",
              "L 2766 2209 \n",
              "L 2766 2266 \n",
              "Q 2766 2663 2505 2880 \n",
              "Q 2244 3097 1772 3097 \n",
              "Q 1472 3097 1187 3025 \n",
              "Q 903 2953 641 2809 \n",
              "L 641 3341 \n",
              "Q 956 3463 1253 3523 \n",
              "Q 1550 3584 1831 3584 \n",
              "Q 2591 3584 2966 3190 \n",
              "Q 3341 2797 3341 1997 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
              "L 3597 1613 \n",
              "L 953 1613 \n",
              "Q 991 1019 1311 708 \n",
              "Q 1631 397 2203 397 \n",
              "Q 2534 397 2845 478 \n",
              "Q 3156 559 3463 722 \n",
              "L 3463 178 \n",
              "Q 3153 47 2828 -22 \n",
              "Q 2503 -91 2169 -91 \n",
              "Q 1331 -91 842 396 \n",
              "Q 353 884 353 1716 \n",
              "Q 353 2575 817 3079 \n",
              "Q 1281 3584 2069 3584 \n",
              "Q 2775 3584 3186 3129 \n",
              "Q 3597 2675 3597 1894 \n",
              "z\n",
              "M 3022 2063 \n",
              "Q 3016 2534 2758 2815 \n",
              "Q 2500 3097 2075 3097 \n",
              "Q 1594 3097 1305 2825 \n",
              "Q 1016 2553 972 2059 \n",
              "L 3022 2063 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-42\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"129.882812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"181.982422\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_44\">\n",
              "     <path d=\"M 39.103125 128.160937 \n",
              "L 49.103125 128.160937 \n",
              "L 59.103125 128.160937 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_18\">\n",
              "     <!-- Base -->\n",
              "     <g transform=\"translate(67.103125 131.660937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-42\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"129.882812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"181.982422\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_45\">\n",
              "     <path d=\"M 39.103125 142.839062 \n",
              "L 49.103125 142.839062 \n",
              "L 59.103125 142.839062 \n",
              "\" style=\"fill: none; stroke: #ff0000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_19\">\n",
              "     <!-- VarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 146.339062) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-56\" d=\"M 1831 0 \n",
              "L 50 4666 \n",
              "L 709 4666 \n",
              "L 2188 738 \n",
              "L 3669 4666 \n",
              "L 4325 4666 \n",
              "L 2547 0 \n",
              "L 1831 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \n",
              "L 1259 519 \n",
              "L 2022 519 \n",
              "Q 2988 519 3436 956 \n",
              "Q 3884 1394 3884 2338 \n",
              "Q 3884 3275 3436 3711 \n",
              "Q 2988 4147 2022 4147 \n",
              "L 1259 4147 \n",
              "z\n",
              "M 628 4666 \n",
              "L 1925 4666 \n",
              "Q 3281 4666 3915 4102 \n",
              "Q 4550 3538 4550 2338 \n",
              "Q 4550 1131 3912 565 \n",
              "Q 3275 0 1925 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
              "L 1159 4863 \n",
              "L 1159 1991 \n",
              "L 2875 3500 \n",
              "L 3609 3500 \n",
              "L 1753 1863 \n",
              "L 3688 0 \n",
              "L 2938 0 \n",
              "L 1159 1709 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"403.574219\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"473.398438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"536.777344\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"598.300781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"653.28125\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_46\">\n",
              "     <path d=\"M 39.103125 157.517187 \n",
              "L 49.103125 157.517187 \n",
              "L 59.103125 157.517187 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_20\">\n",
              "     <!-- VarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 161.017187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"403.574219\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"473.398438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"536.777344\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"598.300781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"653.28125\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_47\">\n",
              "     <path d=\"M 39.103125 172.195312 \n",
              "L 49.103125 172.195312 \n",
              "L 59.103125 172.195312 \n",
              "\" style=\"fill: none; stroke: #ffa500; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_21\">\n",
              "     <!-- VarDrop -->\n",
              "     <g transform=\"translate(67.103125 175.695312) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_48\">\n",
              "     <path d=\"M 39.103125 186.873437 \n",
              "L 49.103125 186.873437 \n",
              "L 59.103125 186.873437 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ffa500; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_22\">\n",
              "     <!-- VarDrop -->\n",
              "     <g transform=\"translate(67.103125 190.373437) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_49\">\n",
              "     <path d=\"M 39.103125 201.551562 \n",
              "L 49.103125 201.551562 \n",
              "L 59.103125 201.551562 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_23\">\n",
              "     <!-- FastVarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 205.051562) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-46\" d=\"M 628 4666 \n",
              "L 3309 4666 \n",
              "L 3309 4134 \n",
              "L 1259 4134 \n",
              "L 1259 2759 \n",
              "L 3109 2759 \n",
              "L 3109 2228 \n",
              "L 1259 2228 \n",
              "L 1259 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"604.556641\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"674.380859\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"737.759766\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"799.283203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"854.263672\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_50\">\n",
              "     <path d=\"M 39.103125 216.229687 \n",
              "L 49.103125 216.229687 \n",
              "L 59.103125 216.229687 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_24\">\n",
              "     <!-- FastVarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 219.729687) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"604.556641\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"674.380859\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"737.759766\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"799.283203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"854.263672\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_51\">\n",
              "     <path d=\"M 39.103125 230.907812 \n",
              "L 49.103125 230.907812 \n",
              "L 59.103125 230.907812 \n",
              "\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_25\">\n",
              "     <!-- FastVarDrop -->\n",
              "     <g transform=\"translate(67.103125 234.407812) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_52\">\n",
              "     <path d=\"M 39.103125 245.585937 \n",
              "L 49.103125 245.585937 \n",
              "L 59.103125 245.585937 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_26\">\n",
              "     <!-- FastVarDrop -->\n",
              "     <g transform=\"translate(67.103125 249.085937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_53\">\n",
              "     <path d=\"M 39.103125 260.264062 \n",
              "L 49.103125 260.264062 \n",
              "L 59.103125 260.264062 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_27\">\n",
              "     <!-- HandmadeCheck -->\n",
              "     <g transform=\"translate(67.103125 263.764062) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-48\" d=\"M 628 4666 \n",
              "L 1259 4666 \n",
              "L 1259 2753 \n",
              "L 3553 2753 \n",
              "L 3553 4666 \n",
              "L 4184 4666 \n",
              "L 4184 0 \n",
              "L 3553 0 \n",
              "L 3553 2222 \n",
              "L 1259 2222 \n",
              "L 1259 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
              "L 2906 4863 \n",
              "L 3481 4863 \n",
              "L 3481 0 \n",
              "L 2906 0 \n",
              "L 2906 525 \n",
              "Q 2725 213 2448 61 \n",
              "Q 2172 -91 1784 -91 \n",
              "Q 1150 -91 751 415 \n",
              "Q 353 922 353 1747 \n",
              "Q 353 2572 751 3078 \n",
              "Q 1150 3584 1784 3584 \n",
              "Q 2172 3584 2448 3432 \n",
              "Q 2725 3281 2906 2969 \n",
              "z\n",
              "M 947 1747 \n",
              "Q 947 1113 1208 752 \n",
              "Q 1469 391 1925 391 \n",
              "Q 2381 391 2643 752 \n",
              "Q 2906 1113 2906 1747 \n",
              "Q 2906 2381 2643 2742 \n",
              "Q 2381 3103 1925 3103 \n",
              "Q 1469 3103 1208 2742 \n",
              "Q 947 2381 947 1747 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
              "Q 3544 3216 3844 3400 \n",
              "Q 4144 3584 4550 3584 \n",
              "Q 5097 3584 5394 3201 \n",
              "Q 5691 2819 5691 2113 \n",
              "L 5691 0 \n",
              "L 5113 0 \n",
              "L 5113 2094 \n",
              "Q 5113 2597 4934 2840 \n",
              "Q 4756 3084 4391 3084 \n",
              "Q 3944 3084 3684 2787 \n",
              "Q 3425 2491 3425 1978 \n",
              "L 3425 0 \n",
              "L 2847 0 \n",
              "L 2847 2094 \n",
              "Q 2847 2600 2669 2842 \n",
              "Q 2491 3084 2119 3084 \n",
              "Q 1678 3084 1418 2786 \n",
              "Q 1159 2488 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1356 3278 1631 3431 \n",
              "Q 1906 3584 2284 3584 \n",
              "Q 2666 3584 2933 3390 \n",
              "Q 3200 3197 3328 2828 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"547.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"616.845703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"680.224609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"741.748047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"796.728516\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_54\">\n",
              "     <path d=\"M 39.103125 274.942187 \n",
              "L 49.103125 274.942187 \n",
              "L 59.103125 274.942187 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_28\">\n",
              "     <!-- HandmadeCheck -->\n",
              "     <g transform=\"translate(67.103125 278.442187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"547.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"616.845703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"680.224609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"741.748047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"796.728516\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_55\">\n",
              "     <path d=\"M 39.103125 289.620312 \n",
              "L 49.103125 289.620312 \n",
              "L 59.103125 289.620312 \n",
              "\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_29\">\n",
              "     <!-- Handmade -->\n",
              "     <g transform=\"translate(67.103125 293.120312) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_56\">\n",
              "     <path d=\"M 39.103125 304.298437 \n",
              "L 49.103125 304.298437 \n",
              "L 59.103125 304.298437 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_30\">\n",
              "     <!-- Handmade -->\n",
              "     <g transform=\"translate(67.103125 307.798437) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              "  <g id=\"axes_2\">\n",
              "   <g id=\"patch_8\">\n",
              "    <path d=\"M 30.103125 673.478125 \n",
              "L 705.573125 673.478125 \n",
              "L 705.573125 376.918125 \n",
              "L 30.103125 376.918125 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_3\">\n",
              "    <g id=\"xtick_8\">\n",
              "     <g id=\"line2d_57\">\n",
              "      <path d=\"M 104.667995 673.478125 \n",
              "L 104.667995 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_58\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"104.667995\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_31\">\n",
              "      <!-- 2 -->\n",
              "      <g transform=\"translate(101.486745 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_9\">\n",
              "     <g id=\"line2d_59\">\n",
              "      <path d=\"M 192.391372 673.478125 \n",
              "L 192.391372 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_60\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"192.391372\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_32\">\n",
              "      <!-- 4 -->\n",
              "      <g transform=\"translate(189.210122 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_10\">\n",
              "     <g id=\"line2d_61\">\n",
              "      <path d=\"M 280.114748 673.478125 \n",
              "L 280.114748 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_62\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"280.114748\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_33\">\n",
              "      <!-- 6 -->\n",
              "      <g transform=\"translate(276.933498 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_11\">\n",
              "     <g id=\"line2d_63\">\n",
              "      <path d=\"M 367.838125 673.478125 \n",
              "L 367.838125 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_64\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"367.838125\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_34\">\n",
              "      <!-- 8 -->\n",
              "      <g transform=\"translate(364.656875 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_12\">\n",
              "     <g id=\"line2d_65\">\n",
              "      <path d=\"M 455.561502 673.478125 \n",
              "L 455.561502 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_66\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"455.561502\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_35\">\n",
              "      <!-- 10 -->\n",
              "      <g transform=\"translate(449.199002 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_13\">\n",
              "     <g id=\"line2d_67\">\n",
              "      <path d=\"M 543.284878 673.478125 \n",
              "L 543.284878 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_68\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"543.284878\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_36\">\n",
              "      <!-- 12 -->\n",
              "      <g transform=\"translate(536.922378 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_14\">\n",
              "     <g id=\"line2d_69\">\n",
              "      <path d=\"M 631.008255 673.478125 \n",
              "L 631.008255 376.918125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_70\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5ef2147839\" x=\"631.008255\" y=\"673.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_37\">\n",
              "      <!-- 14 -->\n",
              "      <g transform=\"translate(624.645755 688.076562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_38\">\n",
              "     <!-- Epoch -->\n",
              "     <g transform=\"translate(352.527187 701.754687) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_4\">\n",
              "    <g id=\"ytick_8\">\n",
              "     <g id=\"line2d_71\">\n",
              "      <path d=\"M 30.103125 671.029728 \n",
              "L 705.573125 671.029728 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_72\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"671.029728\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_39\">\n",
              "      <!-- 0.2 -->\n",
              "      <g transform=\"translate(7.2 674.828947) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_9\">\n",
              "     <g id=\"line2d_73\">\n",
              "      <path d=\"M 30.103125 615.761175 \n",
              "L 705.573125 615.761175 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_74\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"615.761175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_40\">\n",
              "      <!-- 0.3 -->\n",
              "      <g transform=\"translate(7.2 619.560394) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
              "Q 3050 2419 3304 2112 \n",
              "Q 3559 1806 3559 1356 \n",
              "Q 3559 666 3084 287 \n",
              "Q 2609 -91 1734 -91 \n",
              "Q 1441 -91 1130 -33 \n",
              "Q 819 25 488 141 \n",
              "L 488 750 \n",
              "Q 750 597 1062 519 \n",
              "Q 1375 441 1716 441 \n",
              "Q 2309 441 2620 675 \n",
              "Q 2931 909 2931 1356 \n",
              "Q 2931 1769 2642 2001 \n",
              "Q 2353 2234 1838 2234 \n",
              "L 1294 2234 \n",
              "L 1294 2753 \n",
              "L 1863 2753 \n",
              "Q 2328 2753 2575 2939 \n",
              "Q 2822 3125 2822 3475 \n",
              "Q 2822 3834 2567 4026 \n",
              "Q 2313 4219 1838 4219 \n",
              "Q 1578 4219 1281 4162 \n",
              "Q 984 4106 628 3988 \n",
              "L 628 4550 \n",
              "Q 988 4650 1302 4700 \n",
              "Q 1616 4750 1894 4750 \n",
              "Q 2613 4750 3031 4423 \n",
              "Q 3450 4097 3450 3541 \n",
              "Q 3450 3153 3228 2886 \n",
              "Q 3006 2619 2597 2516 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_10\">\n",
              "     <g id=\"line2d_75\">\n",
              "      <path d=\"M 30.103125 560.492623 \n",
              "L 705.573125 560.492623 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_76\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"560.492623\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_41\">\n",
              "      <!-- 0.4 -->\n",
              "      <g transform=\"translate(7.2 564.291841) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_11\">\n",
              "     <g id=\"line2d_77\">\n",
              "      <path d=\"M 30.103125 505.22407 \n",
              "L 705.573125 505.22407 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_78\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"505.22407\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_42\">\n",
              "      <!-- 0.5 -->\n",
              "      <g transform=\"translate(7.2 509.023289) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
              "L 3169 4666 \n",
              "L 3169 4134 \n",
              "L 1269 4134 \n",
              "L 1269 2991 \n",
              "Q 1406 3038 1543 3061 \n",
              "Q 1681 3084 1819 3084 \n",
              "Q 2600 3084 3056 2656 \n",
              "Q 3513 2228 3513 1497 \n",
              "Q 3513 744 3044 326 \n",
              "Q 2575 -91 1722 -91 \n",
              "Q 1428 -91 1123 -41 \n",
              "Q 819 9 494 109 \n",
              "L 494 744 \n",
              "Q 775 591 1075 516 \n",
              "Q 1375 441 1709 441 \n",
              "Q 2250 441 2565 725 \n",
              "Q 2881 1009 2881 1497 \n",
              "Q 2881 1984 2565 2268 \n",
              "Q 2250 2553 1709 2553 \n",
              "Q 1456 2553 1204 2497 \n",
              "Q 953 2441 691 2322 \n",
              "L 691 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_12\">\n",
              "     <g id=\"line2d_79\">\n",
              "      <path d=\"M 30.103125 449.955517 \n",
              "L 705.573125 449.955517 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_80\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"449.955517\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_43\">\n",
              "      <!-- 0.6 -->\n",
              "      <g transform=\"translate(7.2 453.754736) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_13\">\n",
              "     <g id=\"line2d_81\">\n",
              "      <path d=\"M 30.103125 394.686965 \n",
              "L 705.573125 394.686965 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_82\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#me0d5dda10c\" x=\"30.103125\" y=\"394.686965\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_44\">\n",
              "      <!-- 0.7 -->\n",
              "      <g transform=\"translate(7.2 398.486183) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
              "L 3525 4666 \n",
              "L 3525 4397 \n",
              "L 1831 0 \n",
              "L 1172 0 \n",
              "L 2766 4134 \n",
              "L 525 4134 \n",
              "L 525 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_83\">\n",
              "    <path d=\"M 60.806307 636.365292 \n",
              "L 104.667995 636.741118 \n",
              "L 148.529683 582.843225 \n",
              "L 192.391372 565.334148 \n",
              "L 236.25306 549.505234 \n",
              "L 280.114748 542.010819 \n",
              "L 323.976437 527.397813 \n",
              "L 367.838125 516.344103 \n",
              "L 411.699813 506.837912 \n",
              "L 455.561502 494.700938 \n",
              "L 499.42319 477.457149 \n",
              "L 543.284878 460.721831 \n",
              "L 587.146567 444.472877 \n",
              "L 631.008255 423.139216 \n",
              "L 674.869943 403.795222 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_84\">\n",
              "    <path d=\"M 60.806307 633.358683 \n",
              "L 104.667995 636.343184 \n",
              "L 148.529683 590.09446 \n",
              "L 192.391372 578.266989 \n",
              "L 236.25306 568.782906 \n",
              "L 280.114748 570.109351 \n",
              "L 323.976437 566.218445 \n",
              "L 367.838125 562.791795 \n",
              "L 411.699813 569.357699 \n",
              "L 455.561502 572.032697 \n",
              "L 499.42319 572.275878 \n",
              "L 543.284878 574.287653 \n",
              "L 587.146567 572.187448 \n",
              "L 631.008255 573.049638 \n",
              "L 674.869943 578.355419 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_85\">\n",
              "    <path d=\"M 60.806307 649.696067 \n",
              "L 104.667995 593.123176 \n",
              "L 148.529683 570.750466 \n",
              "L 192.391372 564.604603 \n",
              "L 236.25306 542.143463 \n",
              "L 280.114748 537.191401 \n",
              "L 323.976437 524.877567 \n",
              "L 367.838125 512.121585 \n",
              "L 411.699813 499.940396 \n",
              "L 455.561502 485.415821 \n",
              "L 499.42319 469.741659 \n",
              "L 543.284878 456.676173 \n",
              "L 587.146567 436.602635 \n",
              "L 631.008255 418.142938 \n",
              "L 674.869943 397.782004 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #ff0000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_86\">\n",
              "    <path d=\"M 60.806307 650.138215 \n",
              "L 104.667995 592.703135 \n",
              "L 148.529683 581.428351 \n",
              "L 192.391372 574.641372 \n",
              "L 236.25306 567.522783 \n",
              "L 280.114748 563.366587 \n",
              "L 323.976437 561.045308 \n",
              "L 367.838125 558.922996 \n",
              "L 411.699813 563.543447 \n",
              "L 455.561502 563.543447 \n",
              "L 499.42319 566.793238 \n",
              "L 543.284878 568.296542 \n",
              "L 587.146567 571.767407 \n",
              "L 631.008255 574.884554 \n",
              "L 674.869943 574.022364 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_87\">\n",
              "    <path d=\"M 60.806307 652.702676 \n",
              "L 104.667995 601.214492 \n",
              "L 148.529683 587.574214 \n",
              "L 192.391372 577.625874 \n",
              "L 236.25306 572.607489 \n",
              "L 280.114748 565.422578 \n",
              "L 323.976437 556.535394 \n",
              "L 367.838125 546.786022 \n",
              "L 411.699813 542.541397 \n",
              "L 455.561502 536.262889 \n",
              "L 499.42319 530.161241 \n",
              "L 543.284878 524.192237 \n",
              "L 587.146567 520.898232 \n",
              "L 631.008255 523.241618 \n",
              "L 674.869943 510.242455 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #ffa500; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_88\">\n",
              "    <path d=\"M 60.806307 653.763832 \n",
              "L 104.667995 596.991975 \n",
              "L 148.529683 587.353139 \n",
              "L 192.391372 581.892606 \n",
              "L 236.25306 577.31637 \n",
              "L 280.114748 573.049638 \n",
              "L 323.976437 568.893443 \n",
              "L 367.838125 566.837453 \n",
              "L 411.699813 563.499232 \n",
              "L 455.561502 561.97382 \n",
              "L 499.42319 562.836009 \n",
              "L 543.284878 560.271549 \n",
              "L 587.146567 559.542004 \n",
              "L 631.008255 556.446965 \n",
              "L 674.869943 556.004816 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ffa500; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_89\">\n",
              "    <path d=\"M 60.806307 636.055788 \n",
              "L 104.667995 600.927096 \n",
              "L 148.529683 580.124013 \n",
              "L 192.391372 560.448408 \n",
              "L 236.25306 551.052754 \n",
              "L 280.114748 533.145743 \n",
              "L 323.976437 521.008769 \n",
              "L 367.838125 513.050097 \n",
              "L 411.699813 501.576346 \n",
              "L 455.561502 481.745989 \n",
              "L 499.42319 469.542692 \n",
              "L 543.284878 445.423496 \n",
              "L 587.146567 425.637354 \n",
              "L 631.008255 404.657412 \n",
              "L 674.869943 390.398125 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_90\">\n",
              "    <path d=\"M 60.806307 633.270253 \n",
              "L 104.667995 601.015526 \n",
              "L 148.529683 585.385579 \n",
              "L 192.391372 575.194058 \n",
              "L 236.25306 575.282487 \n",
              "L 280.114748 564.825677 \n",
              "L 323.976437 567.522783 \n",
              "L 367.838125 571.192615 \n",
              "L 411.699813 568.208113 \n",
              "L 455.561502 568.119683 \n",
              "L 499.42319 569.247161 \n",
              "L 543.284878 573.867612 \n",
              "L 587.146567 576.188892 \n",
              "L 631.008255 579.637649 \n",
              "L 674.869943 578.200667 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_91\">\n",
              "    <path d=\"M 60.806307 642.754337 \n",
              "L 104.667995 599.490114 \n",
              "L 148.529683 580.941987 \n",
              "L 192.391372 564.427744 \n",
              "L 236.25306 554.656264 \n",
              "L 280.114748 546.321766 \n",
              "L 323.976437 539.092639 \n",
              "L 367.838125 536.108137 \n",
              "L 411.699813 529.586448 \n",
              "L 455.561502 521.075091 \n",
              "L 499.42319 517.117863 \n",
              "L 543.284878 514.022824 \n",
              "L 587.146567 506.064152 \n",
              "L 631.008255 501.001553 \n",
              "L 674.869943 494.457756 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_92\">\n",
              "    <path d=\"M 60.806307 640.49938 \n",
              "L 104.667995 599.158502 \n",
              "L 148.529683 584.302315 \n",
              "L 192.391372 574.331868 \n",
              "L 236.25306 573.491786 \n",
              "L 280.114748 566.218445 \n",
              "L 323.976437 560.824234 \n",
              "L 367.838125 564.250884 \n",
              "L 411.699813 567.434353 \n",
              "L 455.561502 560.337871 \n",
              "L 499.42319 556.292213 \n",
              "L 543.284878 562.65915 \n",
              "L 587.146567 561.133738 \n",
              "L 631.008255 561.929605 \n",
              "L 674.869943 563.455017 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_93\">\n",
              "    <path d=\"M 60.806307 618.988859 \n",
              "L 104.667995 587.817395 \n",
              "L 148.529683 579.040749 \n",
              "L 192.391372 559.519896 \n",
              "L 236.25306 546.299658 \n",
              "L 280.114748 537.478797 \n",
              "L 323.976437 528.304218 \n",
              "L 367.838125 515.504021 \n",
              "L 411.699813 504.096592 \n",
              "L 455.561502 491.517469 \n",
              "L 499.42319 479.159421 \n",
              "L 543.284878 462.822036 \n",
              "L 587.146567 443.743332 \n",
              "L 631.008255 428.776608 \n",
              "L 674.869943 409.609474 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_94\">\n",
              "    <path d=\"M 60.806307 618.966751 \n",
              "L 104.667995 588.215329 \n",
              "L 148.529683 584.877108 \n",
              "L 192.391372 573.88972 \n",
              "L 236.25306 567.45646 \n",
              "L 280.114748 566.373197 \n",
              "L 323.976437 561.907498 \n",
              "L 367.838125 562.482291 \n",
              "L 411.699813 563.366587 \n",
              "L 455.561502 565.798404 \n",
              "L 499.42319 574.309761 \n",
              "L 543.284878 571.966374 \n",
              "L 587.146567 575.238273 \n",
              "L 631.008255 579.593435 \n",
              "L 674.869943 581.804177 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_95\">\n",
              "    <path d=\"M 60.806307 659.998125 \n",
              "L 104.667995 626.903316 \n",
              "L 148.529683 594.9802 \n",
              "L 192.391372 583.0643 \n",
              "L 236.25306 575.127735 \n",
              "L 280.114748 567.721749 \n",
              "L 323.976437 562.990761 \n",
              "L 367.838125 550.323209 \n",
              "L 411.699813 544.774246 \n",
              "L 455.561502 540.37487 \n",
              "L 499.42319 538.694706 \n",
              "L 543.284878 535.820741 \n",
              "L 587.146567 531.929835 \n",
              "L 631.008255 524.324882 \n",
              "L 674.869943 524.125915 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_96\">\n",
              "    <path d=\"M 60.806307 656.748334 \n",
              "L 104.667995 624.316747 \n",
              "L 148.529683 591.597764 \n",
              "L 192.391372 583.0643 \n",
              "L 236.25306 578.819675 \n",
              "L 280.114748 576.255214 \n",
              "L 323.976437 576.896329 \n",
              "L 367.838125 567.124849 \n",
              "L 411.699813 565.422578 \n",
              "L 455.561502 565.732082 \n",
              "L 499.42319 559.2325 \n",
              "L 543.284878 559.033533 \n",
              "L 587.146567 558.348203 \n",
              "L 631.008255 557.596551 \n",
              "L 674.869943 555.805849 \n",
              "\" clip-path=\"url(#pd426aee4c5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_9\">\n",
              "    <path d=\"M 30.103125 673.478125 \n",
              "L 30.103125 376.918125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_10\">\n",
              "    <path d=\"M 705.573125 673.478125 \n",
              "L 705.573125 376.918125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_11\">\n",
              "    <path d=\"M 30.103125 673.478125 \n",
              "L 705.573125 673.478125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_12\">\n",
              "    <path d=\"M 30.103125 376.918125 \n",
              "L 705.573125 376.918125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_45\">\n",
              "    <!-- Accuracy -->\n",
              "    <g transform=\"translate(340.444375 370.918125) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \n",
              "L 1331 1722 \n",
              "L 3047 1722 \n",
              "L 2188 4044 \n",
              "z\n",
              "M 1831 4666 \n",
              "L 2547 4666 \n",
              "L 4325 0 \n",
              "L 3669 0 \n",
              "L 3244 1197 \n",
              "L 1141 1197 \n",
              "L 716 0 \n",
              "L 50 0 \n",
              "L 1831 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
              "L 544 3500 \n",
              "L 1119 3500 \n",
              "L 1119 1403 \n",
              "Q 1119 906 1312 657 \n",
              "Q 1506 409 1894 409 \n",
              "Q 2359 409 2629 706 \n",
              "Q 2900 1003 2900 1516 \n",
              "L 2900 3500 \n",
              "L 3475 3500 \n",
              "L 3475 0 \n",
              "L 2900 0 \n",
              "L 2900 538 \n",
              "Q 2691 219 2414 64 \n",
              "Q 2138 -91 1772 -91 \n",
              "Q 1169 -91 856 284 \n",
              "Q 544 659 544 1381 \n",
              "z\n",
              "M 1991 3584 \n",
              "L 1991 3584 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#DejaVuSans-41\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-63\" x=\"66.658203\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-63\" x=\"121.638672\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-75\" x=\"176.619141\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"239.998047\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"281.111328\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-63\" x=\"342.390625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-79\" x=\"397.371094\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_2\">\n",
              "    <g id=\"patch_13\">\n",
              "     <path d=\"M 37.103125 590.411875 \n",
              "L 160.320313 590.411875 \n",
              "Q 162.320313 590.411875 162.320313 588.411875 \n",
              "L 162.320313 383.918125 \n",
              "Q 162.320313 381.918125 160.320313 381.918125 \n",
              "L 37.103125 381.918125 \n",
              "Q 35.103125 381.918125 35.103125 383.918125 \n",
              "L 35.103125 588.411875 \n",
              "Q 35.103125 590.411875 37.103125 590.411875 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_97\">\n",
              "     <path d=\"M 39.103125 390.016562 \n",
              "L 49.103125 390.016562 \n",
              "L 59.103125 390.016562 \n",
              "\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_46\">\n",
              "     <!-- Base -->\n",
              "     <g transform=\"translate(67.103125 393.516562) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-42\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"129.882812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"181.982422\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_98\">\n",
              "     <path d=\"M 39.103125 404.694687 \n",
              "L 49.103125 404.694687 \n",
              "L 59.103125 404.694687 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_47\">\n",
              "     <!-- Base -->\n",
              "     <g transform=\"translate(67.103125 408.194687) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-42\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"129.882812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"181.982422\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_99\">\n",
              "     <path d=\"M 39.103125 419.372812 \n",
              "L 49.103125 419.372812 \n",
              "L 59.103125 419.372812 \n",
              "\" style=\"fill: none; stroke: #ff0000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_48\">\n",
              "     <!-- VarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 422.872812) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"403.574219\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"473.398438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"536.777344\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"598.300781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"653.28125\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_100\">\n",
              "     <path d=\"M 39.103125 434.050937 \n",
              "L 49.103125 434.050937 \n",
              "L 59.103125 434.050937 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_49\">\n",
              "     <!-- VarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 437.550937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"403.574219\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"473.398438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"536.777344\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"598.300781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"653.28125\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_101\">\n",
              "     <path d=\"M 39.103125 448.729062 \n",
              "L 49.103125 448.729062 \n",
              "L 59.103125 448.729062 \n",
              "\" style=\"fill: none; stroke: #ffa500; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_50\">\n",
              "     <!-- VarDrop -->\n",
              "     <g transform=\"translate(67.103125 452.229062) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_102\">\n",
              "     <path d=\"M 39.103125 463.407187 \n",
              "L 49.103125 463.407187 \n",
              "L 59.103125 463.407187 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ffa500; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_51\">\n",
              "     <!-- VarDrop -->\n",
              "     <g transform=\"translate(67.103125 466.907187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-56\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"121.9375\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"163.050781\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"240.052734\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"278.916016\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"340.097656\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_103\">\n",
              "     <path d=\"M 39.103125 478.085312 \n",
              "L 49.103125 478.085312 \n",
              "L 59.103125 478.085312 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_52\">\n",
              "     <!-- FastVarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 481.585312) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"604.556641\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"674.380859\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"737.759766\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"799.283203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"854.263672\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_104\">\n",
              "     <path d=\"M 39.103125 492.763437 \n",
              "L 49.103125 492.763437 \n",
              "L 59.103125 492.763437 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_53\">\n",
              "     <!-- FastVarDropCheck -->\n",
              "     <g transform=\"translate(67.103125 496.263437) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"604.556641\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"674.380859\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"737.759766\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"799.283203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"854.263672\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_105\">\n",
              "     <path d=\"M 39.103125 507.441562 \n",
              "L 49.103125 507.441562 \n",
              "L 59.103125 507.441562 \n",
              "\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_54\">\n",
              "     <!-- FastVarDrop -->\n",
              "     <g transform=\"translate(67.103125 510.941562) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_106\">\n",
              "     <path d=\"M 39.103125 522.119687 \n",
              "L 49.103125 522.119687 \n",
              "L 59.103125 522.119687 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_55\">\n",
              "     <!-- FastVarDrop -->\n",
              "     <g transform=\"translate(67.103125 525.619687) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-46\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"48.394531\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"109.673828\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"161.773438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-56\" x=\"200.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"261.640625\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"322.919922\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-44\" x=\"364.033203\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"441.035156\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"479.898438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"541.080078\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_107\">\n",
              "     <path d=\"M 39.103125 536.797812 \n",
              "L 49.103125 536.797812 \n",
              "L 59.103125 536.797812 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_56\">\n",
              "     <!-- HandmadeCheck -->\n",
              "     <g transform=\"translate(67.103125 540.297812) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"547.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"616.845703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"680.224609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"741.748047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"796.728516\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_108\">\n",
              "     <path d=\"M 39.103125 551.475937 \n",
              "L 49.103125 551.475937 \n",
              "L 59.103125 551.475937 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_57\">\n",
              "     <!-- HandmadeCheck -->\n",
              "     <g transform=\"translate(67.103125 554.975937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-43\" x=\"547.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"616.845703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"680.224609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"741.748047\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6b\" x=\"796.728516\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_109\">\n",
              "     <path d=\"M 39.103125 566.154062 \n",
              "L 49.103125 566.154062 \n",
              "L 59.103125 566.154062 \n",
              "\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_58\">\n",
              "     <!-- Handmade -->\n",
              "     <g transform=\"translate(67.103125 569.654062) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_110\">\n",
              "     <path d=\"M 39.103125 580.832187 \n",
              "L 49.103125 580.832187 \n",
              "L 59.103125 580.832187 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_59\">\n",
              "     <!-- Handmade -->\n",
              "     <g transform=\"translate(67.103125 584.332187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-48\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"75.195312\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"136.474609\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"199.853516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6d\" x=\"263.330078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"360.742188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-64\" x=\"422.021484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"485.498047\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              " </g>\n",
              " <defs>\n",
              "  <clipPath id=\"p472d2898ee\">\n",
              "   <rect x=\"30.103125\" y=\"22.318125\" width=\"675.47\" height=\"296.56\"/>\n",
              "  </clipPath>\n",
              "  <clipPath id=\"pd426aee4c5\">\n",
              "   <rect x=\"30.103125\" y=\"376.918125\" width=\"675.47\" height=\"296.56\"/>\n",
              "  </clipPath>\n",
              " </defs>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
        "\n",
        "axes[0].plot(np.arange(1, 16), train_losses_pure, color='blue', ls='-', label='Base')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_pure, color='blue', ls='--', label='Base')\n",
        "axes[0].plot(np.arange(1, 16), train_losses_do11, color='r', ls='-', label='VarDropCheck')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_do11, color='r', ls='--', label='VarDropCheck')\n",
        "axes[0].plot(np.arange(1, 16), train_losses_do12, color='orange', ls='-', label='VarDrop')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_do12, color='orange', ls='--', label='VarDrop')\n",
        "axes[0].plot(np.arange(1, 16), train_losses_do21, color='black', ls='-', label='FastVarDropCheck')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_do21, color='black', ls='--', label='FastVarDropCheck')\n",
        "axes[0].plot(np.arange(1, 16), train_losses_do22, color='g', ls='-', label='FastVarDrop')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_do22, color='g', ls='--', label='FastVarDrop')\n",
        "axes[0].plot(np.arange(1, 16), train_losses_do31, color='black', ls='-', label='HandmadeCheck')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_do31, color='black', ls='--', label='HandmadeCheck')\n",
        "axes[0].plot(np.arange(1, 16), train_losses_do32, color='g', ls='-', label='Handmade')\n",
        "axes[0].plot(np.arange(1, 16), test_losses_do32, color='g', ls='--', label='Handmade')\n",
        "\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_pure, color='blue', ls='-', label='Base')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_pure, color='blue', ls='--', label='Base')\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_do11, color='r', ls='-', label='VarDropCheck')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_do11, color='r', ls='--', label='VarDropCheck')\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_do12, color='orange', ls='-', label='VarDrop')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_do12, color='orange', ls='--', label='VarDrop')\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_do21, color='black', ls='-', label='FastVarDropCheck')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_do21, color='black', ls='--', label='FastVarDropCheck')\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_do22, color='g', ls='-', label='FastVarDrop')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_do22, color='g', ls='--', label='FastVarDrop')\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_do31, color='black', ls='-', label='HandmadeCheck')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_do31, color='black', ls='--', label='HandmadeCheck')\n",
        "axes[1].plot(np.arange(1, 16), train_accuracies_do32, color='g', ls='-', label='Handmade')\n",
        "axes[1].plot(np.arange(1, 16), test_accuracies_do32, color='g', ls='--', label='Handmade')\n",
        "\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_title('CrossEntropy Loss')\n",
        "\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_title('Accuracy')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nffLjFUsifvT"
      },
      "source": [
        "Сделайте итоговые выводы о качестве работы моделей с разными реализациями DropOut:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPw-ATcRifvT"
      },
      "source": [
        "**Ответ:** Лучшее качество показывают FastDropCheck, HandmadeCheck, VarDropCheck и Base. Остальные модели переобучаются."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "74mk3-aDifvU"
      },
      "source": [
        "## `Бонус. Zoneout (0.5 балла)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "f7_PwTYwifvU"
      },
      "source": [
        "Это еще одна модификация идеи дропаута применительно к рекуррентным нейросетям. В Zoneout на каждом временном шаге с вероятностью $p$ компонента скрытого состояния обновляется, а с вероятностью $1-p$ берется с предыдущего шага.\n",
        "В Виде формул ($m^t_h$ - бинарная маска):\n",
        "\n",
        "(сначала обычный рекуррентный переход, например LSTM)\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "Затем Zoneout:\n",
        "$$\n",
        "h_t = h_t * m_h^t + h_{t-1}*(1-m_h^t)\n",
        "$$\n",
        "В этом методе маска уже должна быть разная во все моменты времени (иначе метод упрощается до дропаута Гала и Гарамани). На входы $x_t$ вновь можно накладывать маску до начала работы рекуррентного слоя.\n",
        "\n",
        "Если у вас осталось время, вы можете реализовать этот метод. Выберите основу из трех рассмотренных случаев самостоятельно.\n",
        "\n",
        "**Полный балл ставится только при наличии качественного и количественного сравнения с предыдущими моделями.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-31T16:05:00.702763Z",
          "start_time": "2021-03-31T16:05:00.674835Z"
        },
        "id": "t9Pj1WjBifvU"
      },
      "source": [
        "# `Часть 2. Language Modeling с помощью LSTM (5 баллов)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi9AiR4QifvU"
      },
      "source": [
        "Во второй части мы попробуем обучить модель для генерации отзывов по их началу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8c9qYcSifvU"
      },
      "source": [
        "Концептуально модель будет выглядеть следующим образом:\n",
        "\n",
        "![image info](https://blog.feedly.com/wp-content/uploads/2019/03/Screen-Shot-2019-03-06-at-12.08.35-PM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgqYYt2cifvU"
      },
      "source": [
        "В процессе обучения будем тренировать сеть предсказывать вероятность следующего символа при условии всех предыдущих. Эту вероятность можно моделировать с помощью скрытого состояния $h^{(t)}$ пропуская его через линейный слой с выходной размерностью равной размерности словаря:\n",
        "$$\n",
        "p(x^{t}|x^{t-1}, ..., x^{1}) = SoftMax(Linear(h^{(t)}))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j2ZyfOIifvV"
      },
      "source": [
        "Обратите внимание, что для вычисления $p(x^{t}|x^{t-1}, ..., x^{1})$ для всех моментов времени достаточно сделать один проход по RNN, а затем применить линейное преобразование ко всем скрытым состояниям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:37:56.100520Z",
          "start_time": "2021-04-02T00:37:56.072747Z"
        },
        "id": "737HpbqyifvV"
      },
      "source": [
        "В качестве функции потерь необходимо использовать `CrossEntropy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ar4j_kwifvV"
      },
      "source": [
        "Рассмотрим другой важный момент. Для того, чтобы решить данную задачу, модель должна уметь определять момент начала генерации предложения и оповещать о завершении генерации — конце предложения. Для этого добавим в словарь вспомогательные токены `<sos>`, `<eos>`. Добавив `<sos>` в начало каждого предложения и `<eos>` в конец.\n",
        "\n",
        "Модель сможет начинать генерацию как только ей будет передан токен `<sos>` и заканчивать генерацию, как только на очередном месте самым вероятным токеном оказывается `<eos>`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMAWCGdGifvV"
      },
      "source": [
        "Для решения этой задачи мы воспользуемся уже реализованной LSTM с дропаутом `FastRNNLayer` и классом `RNNClassifier`, то есть архитектура сети принципиально не поменяется."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g40_wITlifvV"
      },
      "source": [
        "## `Реализация модели и цикла обучения (2 балла)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prDNryJUifvV"
      },
      "source": [
        "**Не используйте циклы в `RNNLM`, `LMCrossEntropyLoss`, `LMAccuracy`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:02.815198Z",
          "start_time": "2021-04-02T02:07:02.787445Z"
        },
        "id": "GJCORaWEifvV"
      },
      "outputs": [],
      "source": [
        "class RNNLM(RNNClassifier):\n",
        "    def __init__(\n",
        "        self, embedding_dim, hidden_dim, vocab, dropout=0.5, layers_dropout=0.5, num_layers=1\n",
        "    ):\n",
        "        super().__init__(\n",
        "            embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=len(vocab), vocab=vocab,\n",
        "            rec_layer=FastRNNLayer, dropout=dropout, layers_dropout=layers_dropout, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor(dtype=torch.long) tokens:\n",
        "            Batch of texts represented with tokens. Shape: [T, B]\n",
        "        :param torch.Tensor(dtype=torch.long) tokens_lens:\n",
        "            Number of non-padding tokens for each object in batch. Shape: [B]\n",
        "        :return torch.Tensor:\n",
        "            Distribution of next token for each time step. Shape: [T, B, V], V — size of vocabulary\n",
        "        \"\"\"\n",
        "        # Make embeddings for all tokens\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "\n",
        "        # Forward pass embeddings through network\n",
        "        rnn_output, hidden = self.rnn(embeddings)\n",
        "\n",
        "        # Take all hidden states from the last layer of LSTM for each step and perform linear transformation\n",
        "        return self.output(rnn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVNRbLBGifvW"
      },
      "source": [
        "Реализуем функцию потерь для данной задачи.\n",
        "\n",
        "Моменты на которые нужно обратить внимание:\n",
        "1. Распределение вероятности следующего токена для последнего токена в последовательности не участвует в подсчёте функции потерь.\n",
        "2. Необходимо учитывать, что в одном батче могут быть тексты разной длины."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBLFh5kLifvW"
      },
      "source": [
        "Для решения второй проблемы можно воспользоваться функцией `torch.nn.utils.rnn.pack_padded_sequence`.\n",
        "\n",
        "Принимая на вход батч тензоров и длину каждого тензора без учёта паддинга эта функция позволяет получить все элементы в тензорах, которые не относятся к паддингу в виде плоского массива:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:54:40.004897Z",
          "start_time": "2021-04-02T00:54:39.977287Z"
        },
        "id": "7P8XIe6WifvW"
      },
      "outputs": [],
      "source": [
        "padded_tensors = torch.tensor([\n",
        "    [[1, 11, 111], [2, 22, 222], [3, 33, 333]],\n",
        "    [[4, 44, 444], [5, 55, 555], [6, 66, 666]],\n",
        "    [[7, 77, 777], [0, 0, 0], [8, 88, 888]],\n",
        "    [[9, 99, 999], [0, 0, 0], [0, 0, 0]]\n",
        "])\n",
        "tensors_lens = torch.tensor([4, 2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6eWZKU9ifvW"
      },
      "source": [
        "Обратите внимание, что `torch.nn.utils.rnn.pack_padded_sequence` автоматически переупорядочивает тензоры в батче по убыванию их длины."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:54:24.517023Z",
          "start_time": "2021-04-02T00:54:24.490588Z"
        },
        "id": "V8XMszrPifvW",
        "outputId": "3ba47a2b-a801-42c2-f971-9ceb929d1192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[  1,  11, 111],\n",
              "        [  3,  33, 333],\n",
              "        [  2,  22, 222],\n",
              "        [  4,  44, 444],\n",
              "        [  6,  66, 666],\n",
              "        [  5,  55, 555],\n",
              "        [  7,  77, 777],\n",
              "        [  8,  88, 888],\n",
              "        [  9,  99, 999]]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([0, 2, 1]), unsorted_indices=tensor([0, 2, 1]))"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.nn.utils.rnn.pack_padded_sequence(padded_tensors, tensors_lens, batch_first=False, enforce_sorted=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:06.289671Z",
          "start_time": "2021-04-02T02:07:06.262883Z"
        },
        "id": "u_W9BnGfifvW"
      },
      "outputs": [],
      "source": [
        "class LMCrossEntropyLoss(torch.nn.CrossEntropyLoss):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, outputs, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
        "        :param torch.Tensor tokens: Batch of tokens. Shape: [T, B]\n",
        "        :param torch.Tensor tokens_lens: Length of each sequence in batch\n",
        "        :return torch.Tensor: CrossEntropyLoss between corresponding logits and tokens\n",
        "        \"\"\"\n",
        "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
        "        # Do not forget specify enforce_sorted=False and correct value of batch_first\n",
        "        # YOUR CODE HERE\n",
        "        outputs = outputs[:-1, :, :].cuda()\n",
        "        tokens = tokens[1:, :].cuda()\n",
        "\n",
        "        packed_outputs = torch.nn.utils.rnn.pack_padded_sequence(outputs,\n",
        "                                                                 tokens_lens.cpu()-1,\n",
        "                                                                 batch_first=False,\n",
        "                                                                 enforce_sorted=False).data\n",
        "        packed_tokens = torch.nn.utils.rnn.pack_padded_sequence(tokens,\n",
        "                                                                tokens_lens.cpu()-1,\n",
        "                                                                batch_first=False,\n",
        "                                                                enforce_sorted=False).data\n",
        "\n",
        "        # Use super().forward(..., ...) to compute CrossEntropyLoss\n",
        "        return super().forward(packed_outputs.cuda().float(), packed_tokens.cuda().long())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLnDd_bxifvX"
      },
      "source": [
        "Для оценки качества нам также необходимо вычислять долю правильно предсказанных токенов. Реализуйте класс для вычисления точности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:07.335981Z",
          "start_time": "2021-04-02T02:07:07.309586Z"
        },
        "id": "dINVPwUCifvX"
      },
      "outputs": [],
      "source": [
        "class LMAccuracy(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, outputs, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
        "        :param torch.Tensor tokens: Batch of tokens. Shape: [T, B]\n",
        "        :param torch.Tensor tokens_lens: Length of each sequence in batch\n",
        "        :return torch.Tensor: Accuracy for given logits and tokens\n",
        "        \"\"\"\n",
        "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
        "        # Do not forget specify enforce_sorted=False and correct value of batch_first\n",
        "        outputs = outputs[:-1, :, :].cuda()\n",
        "        tokens = tokens[1:, :].cuda()\n",
        "\n",
        "        packed_outputs = torch.nn.utils.rnn.pack_padded_sequence(outputs,\n",
        "                                                                 tokens_lens.cpu()-1,\n",
        "                                                                 batch_first=False,\n",
        "                                                                 enforce_sorted=False).data\n",
        "        packed_tokens = torch.nn.utils.rnn.pack_padded_sequence(tokens,\n",
        "                                                                tokens_lens.cpu()-1,\n",
        "                                                                batch_first=False,\n",
        "                                                                enforce_sorted=False).data\n",
        "\n",
        "        return (packed_outputs.argmax(1).cuda() == packed_tokens.cuda()).float().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0MYcUWLifvX"
      },
      "source": [
        "Модифицируйте функции `train_epoch`, `evaluate`, `train` для обучения LM.\n",
        "\n",
        "**При вычислении точности, обратите внимание на то, что мы не предсказываем первый токен в каждой последовательности и токены, относящиеся к паддингу.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:31.492984Z",
          "start_time": "2021-04-02T02:07:31.459655Z"
        },
        "id": "5CV81EMqifvX"
      },
      "outputs": [],
      "source": [
        "def train_epoch_lm(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        # 1. Take data from batch\n",
        "        # 2. Perform forward pass\n",
        "        # 3. Evaluate loss\n",
        "        # 4. Make optimizer step\n",
        "        tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(tokens, tokens_lens)\n",
        "        loss = loss_fn(outputs.float(), tokens.long(), tokens_lens.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate_lm(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_tokens = 0\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    accuracy_fn = LMAccuracy()\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(dataloader):\n",
        "            # 1. Take data from batch\n",
        "            # 2. Perform forward pass\n",
        "            # 3. Evaluate loss\n",
        "            # 4. Evaluate accuracy\n",
        "            tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
        "            outputs = model(tokens, tokens_lens).to('cpu')\n",
        "\n",
        "            total_loss += loss_fn(outputs.float(), tokens.long(), tokens_lens.long())\n",
        "            total_accuracy += accuracy_fn(outputs.float(), tokens.long(), tokens_lens.long())\n",
        "            total_tokens += torch.sum(tokens_lens - 1)\n",
        "\n",
        "    return total_loss / total_tokens, total_accuracy / total_tokens\n",
        "\n",
        "def train_lm(\n",
        "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
        "):\n",
        "    test_losses = []\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    train_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_epoch_lm(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "        train_loss, train_acc = evaluate_lm(train_loader, model, loss_fn, device)\n",
        "        train_accuracies.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_loss, test_acc = evaluate_lm(test_loader, model, loss_fn, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\n",
        "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
        "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "            )\n",
        "        )\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG2uxMDUifvX"
      },
      "source": [
        "Теперь у нас всё готово для обучения модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T01:06:12.736180Z",
          "start_time": "2021-04-02T01:06:12.708814Z"
        },
        "id": "_cSSYinOifvY"
      },
      "source": [
        "Создадим словарь с `<sos>`, `<eos>` токенами.\n",
        "\n",
        "Обратите внимание, что в отличие от классификации текстов нам необходимо значительно увеличить размер словаря, чтобы доля `<unk>` токенов была не велика.\n",
        "\n",
        "Так же, так как задача генерации значительно сложнее задачи классификации текстов будем обучать модель только на префиксах рецензий длины $20$. Это позволяет значительно ускорить обучение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:06:20.093645Z",
          "start_time": "2021-04-02T00:06:19.926668Z"
        },
        "id": "xUZBYOOKifvY"
      },
      "outputs": [],
      "source": [
        "specials = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
        "for special in specials:\n",
        "    counter[special] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEndxou-ZF7W"
      },
      "outputs": [],
      "source": [
        "lm_vocab = torchtext.vocab.vocab(counter, min_freq=9)\n",
        "\n",
        "lm_vocab.insert_token('<pad>', 0)\n",
        "lm_vocab.insert_token('<unk>', 1)\n",
        "lm_vocab.insert_token('<sos>', 2)\n",
        "lm_vocab.insert_token('<eos>', 3)\n",
        "\n",
        "lm_vocab.set_default_index(lm_vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:06:58.566893Z",
          "start_time": "2021-04-02T00:06:21.430692Z"
        },
        "id": "kyJ0vFAhifvY"
      },
      "outputs": [],
      "source": [
        "lm_test_dataset = LargeMovieReviewDataset(test_data_path, lm_vocab, max_len=20, pad_sos=True, pad_eos=True)\n",
        "lm_train_dataset = LargeMovieReviewDataset(train_data_path, lm_vocab, max_len=20, pad_sos=True, pad_eos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po6H1yAjifvY"
      },
      "source": [
        "Создадим даталоадеры для тестовой и обучающей выборок:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T12:29:16.213723Z",
          "start_time": "2021-04-02T12:29:16.186954Z"
        },
        "id": "tTxq_EulifvY"
      },
      "outputs": [],
      "source": [
        "lm_test_dataloader = DataLoader(\n",
        "    lm_test_dataset, batch_size=96, shuffle=False, num_workers=3,\n",
        "    collate_fn=partial(collate_fn, padding_value=lm_vocab.lookup_indices(['<pad>'])[0])\n",
        ")\n",
        "lm_train_dataloader = DataLoader(\n",
        "    lm_train_dataset, batch_size=96, shuffle=True, num_workers=3,\n",
        "    collate_fn=partial(collate_fn, padding_value=lm_vocab.lookup_indices(['<pad>'])[0])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t82BNkJaifvY"
      },
      "source": [
        "Убедитесь, что все предложения имеют в начале `<sos>` токен, а в конце — `<eos>` токен."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T12:29:17.218115Z",
          "start_time": "2021-04-02T12:29:16.922801Z"
        },
        "id": "iVugwMxVifvZ",
        "outputId": "7439c6bc-54d4-4536-f1aa-f456e381f03f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
              "         [  687,  4757,  4019,  ...,  2344,   912,   406],\n",
              "         [  649,   277,   674,  ...,  6466,   714,  7669],\n",
              "         ...,\n",
              "         [    1,    29,    37,  ...,   483,   911, 15948],\n",
              "         [  338,   562,   411,  ...,   962,  2823,  1315],\n",
              "         [    3,     3,     3,  ...,     3,     3,     3]]),\n",
              " tensor([22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         22, 22, 22, 22, 22, 22]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(lm_train_dataloader))\n",
        "batch['tokens'], batch['tokens_lens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Ir3o2mifvZ"
      },
      "source": [
        "Создадим модель, функцию потерь и оптимизатор:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:15:32.916424Z",
          "start_time": "2021-04-02T14:15:32.525452Z"
        },
        "id": "qFpifSalifvZ"
      },
      "outputs": [],
      "source": [
        "lm_model = RNNLM(\n",
        "    embedding_dim=512, hidden_dim=512, vocab=lm_vocab, dropout=0.6, layers_dropout=0.6, num_layers=2\n",
        ").to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:15:33.332806Z",
          "start_time": "2021-04-02T14:15:33.307749Z"
        },
        "id": "l6YPZOkmifvZ"
      },
      "outputs": [],
      "source": [
        "lm_loss_fn = LMCrossEntropyLoss(reduction='mean')\n",
        "lm_optimizer = torch.optim.Adam(lm_model.parameters(), lr=0.005, weight_decay=1.2e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd-u_0uvifvZ"
      },
      "source": [
        "Обучим модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:20:33.447251Z",
          "start_time": "2021-04-02T14:15:33.797444Z"
        },
        "id": "t1-0Lw8ZifvZ",
        "outputId": "06b68f64-d009-44c9-d800-c1faceedaff0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/10. Loss (Train/Test): 0.004/0.004. Accuracy (Train/Test): 0.092/0.092\n",
            "Epoch: 2/10. Loss (Train/Test): 0.004/0.004. Accuracy (Train/Test): 0.101/0.099\n",
            "Epoch: 3/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.091/0.088\n",
            "Epoch: 4/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.111/0.105\n",
            "Epoch: 5/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.119/0.109\n",
            "Epoch: 6/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.124/0.110\n",
            "Epoch: 7/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.128/0.109\n",
            "Epoch: 8/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.135/0.109\n",
            "Epoch: 9/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.148/0.113\n",
            "Epoch: 10/10. Loss (Train/Test): 0.003/0.004. Accuracy (Train/Test): 0.156/0.109\n"
          ]
        }
      ],
      "source": [
        "lm_train_losses, lm_train_accuracies, lm_test_losses, lm_test_accuracies = train_lm(\n",
        "    lm_train_dataloader, lm_test_dataloader, lm_model, lm_loss_fn, lm_optimizer, device, 10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEOA2Z2pifva"
      },
      "source": [
        "## `Реализация декодера (1 балл)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPyga7IYifva"
      },
      "source": [
        "Теперь, реализуем последнюю деталь — декодирование с использованием обученной модели.\n",
        "Есть несколько вариантов. Рассмотрим два самых простых:\n",
        "1. **Жадное декодирование.** На каждом шаге мы выбираем токен с максимальной вероятностью и используем его для обновления скрытого состояния RNN.\n",
        "2. **Top-k sampling.** На очередном шаге рассматриваются $k$ токенов с самыми большими вероятностями. Остальные токены игнорируются. Из выбранных токенов семплируется следующий токен пропорционально их вероятностям.\n",
        "\n",
        "Прочитать подробнее про разные варианты декодирования можно по ссылкам:\n",
        "1. [От huggingface](https://huggingface.co/blog/how-to-generate)\n",
        "2. [На towardsdatascience](https://towardsdatascience.com/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft5jlze_ifva"
      },
      "source": [
        "Существенным в процессе декодирования является критерий останова. Как только очередной самый вероятный символ оказался `<eos>`, то данная последовательность считается сгенерированной. Однако, может так оказаться, что `<eos>` никогда не будет выбран, тогда необходимо прекратить генерацию, как только длина последовательности перейдёт порог `max_generated_len`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:21.578336Z",
          "start_time": "2021-04-02T14:28:21.547183Z"
        },
        "id": "UeLfGGKEifva"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def decode(model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=None):\n",
        "    \"\"\"\n",
        "    :param RNNLM model: Model\n",
        "    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
        "    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
        "    :param int max_generated_len: Maximum lenght of generated samples\n",
        "    :param Optional[int] top_k: Number of tokens with the largest probability to sample from\n",
        "    :return Tuple[torch.Tensor, torch.Tensor].\n",
        "        Newly predicted tokens and length of generated part. Shape [T*, B], [B]\n",
        "    \"\"\"\n",
        "    # Get embedding for start_tokens\n",
        "    embedding = model.word_embeddings(start_tokens)\n",
        "\n",
        "    # Pass embedding through rnn and collect hidden states and cell states for each time moment\n",
        "    all_h, all_c = [], []\n",
        "    h = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
        "    c = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
        "    for time_step in range(start_tokens.shape[0]):\n",
        "        output, (h, c) = model.rnn(torch.unsqueeze(embedding[time_step], dim=0), (h, c))\n",
        "        all_h.append(h)\n",
        "        all_c.append(c)\n",
        "\n",
        "    all_h = torch.stack(all_h, dim=1)\n",
        "    all_c = torch.stack(all_c, dim=1)\n",
        "    # Take final hidden state and cell state for each start sequence in batch\n",
        "    # We will use them as h_0, c_0 for generation new tokens\n",
        "    h = all_h[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n",
        "    c = all_c[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n",
        "\n",
        "    # List of predicted tokens for each time step\n",
        "    predicted_tokens = []\n",
        "    # Length of generated part for each object in the batch\n",
        "    decoded_lens = torch.zeros_like(start_tokens_lens, dtype=torch.long)\n",
        "    # Boolean mask where we store if the sequence has already generated\n",
        "    # i.e. `<eos>` was selected on any step\n",
        "    is_finished_decoding = torch.zeros_like(start_tokens_lens, dtype=torch.bool)\n",
        "\n",
        "    # Stop when all sequences in the batch are finished\n",
        "    while not torch.all(is_finished_decoding) and torch.max(decoded_lens) < max_generated_len:\n",
        "        # Evaluate next token distribution using hidden state h.\n",
        "        # Note. Over first dimension h has hidden states for each layer of LSTM.\n",
        "        #     We must use hidden state from the last layer\n",
        "        # YOUR CODE HERE\n",
        "        logits = model.output(h[1])\n",
        "\n",
        "        if top_k is not None:\n",
        "            # Top-k sampling. Use only top-k most probable logits to sample next token\n",
        "            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "            # Mask non top-k logits\n",
        "            logits[indices_to_remove] = -1e10\n",
        "            # Sample next_token.\n",
        "            # YOUR CODE HERE\n",
        "            next_token = torch.distributions.categorical.Categorical(logits=logits).sample()\n",
        "        else:\n",
        "            # Select most probable token\n",
        "            # YOUR CODE HERE\n",
        "            next_token = torch.argmax(logits, dim=1).reshape(-1)\n",
        "\n",
        "        predicted_tokens.append(next_token)\n",
        "\n",
        "        decoded_lens += (~is_finished_decoding)\n",
        "        is_finished_decoding |= (next_token == torch.tensor(model.vocab.lookup_indices(['<eos>'])[0]))\n",
        "\n",
        "        # Compute embedding for next token\n",
        "        embedding += model.word_embeddings(next_token)\n",
        "\n",
        "        # Update hidden and cell states\n",
        "        output, (h, c) = model.rnn(embedding, (h, c))\n",
        "\n",
        "    return torch.stack(predicted_tokens), decoded_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T01:38:06.232189Z",
          "start_time": "2021-04-02T01:38:06.205413Z"
        },
        "id": "mJM9cTURifva"
      },
      "source": [
        "Попробуем сгенерировать продолжения для нескольких префиксов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:22.568613Z",
          "start_time": "2021-04-02T14:28:22.545810Z"
        },
        "id": "tELgGOqsifvb"
      },
      "outputs": [],
      "source": [
        "start_tokens = torch.tensor([\n",
        "    lm_model.vocab.lookup_indices(['<sos>', '<pad>', '<pad>', '<pad>']),\n",
        "    lm_model.vocab.lookup_indices(['<sos>', 'my', 'favorite', 'movie']),\n",
        "    lm_model.vocab.lookup_indices(['<sos>', 'the', 'best', 'movie']),\n",
        "    lm_model.vocab.lookup_indices(['<sos>', 'the', 'worst', 'movie']),\n",
        "]).T\n",
        "\n",
        "start_tokens_lens = torch.tensor([1, 4, 4, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:28.222137Z",
          "start_time": "2021-04-02T14:28:27.930196Z"
        },
        "id": "9fKp4C31ifvb"
      },
      "outputs": [],
      "source": [
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:28.751380Z",
          "start_time": "2021-04-02T14:28:28.708461Z"
        },
        "id": "IFI8-xJ1ifvb",
        "outputId": "a700c4a9-2551-4430-a26f-5054349f71de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> movie really great good great actors story <unk> great love love story love movies movie <unk> movie one <unk> movie\n",
            "<sos> <unk> favorite movie ever made ever seen <unk> made <unk> movie <unk> <unk> little movie film <unk> <unk> little <unk> director <unk> <unk>\n",
            "<sos> <unk> best movie ever seen seen long times years since years still saw ago still ago ago since <unk> still say saw <unk>\n",
            "<sos> <unk> worst movie ever seen ever seen seen since since <unk> first <unk> first <unk> <unk> movie <unk> film one <unk> <unk> <unk>\n"
          ]
        }
      ],
      "source": [
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgaulA0Oifvb"
      },
      "source": [
        "Попробуйте выполнить семплирование для разных $k$. Сравните результаты top-k семплирования с жадным декодированием. Опишите ваши наблюдения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T17:06:36.404126Z",
          "start_time": "2021-04-02T17:06:36.399654Z"
        },
        "id": "-nYCnPPMifvb",
        "outputId": "ae9843e0-fdf6-4217-b6a4-382f9b5a0010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> movie bad bad bad bad movie bad bad movie bad bad bad movie bad bad bad movie bad bad bad\n",
            "<sos> <unk> favorite movie ever seen first saw movie first saw movie saw first movie saw first saw movie years saw movie years years\n",
            "<sos> <unk> best movie ever seen ever seen seen since since first movie <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "<sos> <unk> worst movie ever seen ever seen seen long years since since since saw <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
          ]
        }
      ],
      "source": [
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=None)\n",
        "\n",
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5bVV_8mZF7a",
        "outputId": "80816a9e-a429-4457-bfaf-b7f5f32d4c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> movie bad bad bad acting even bad bad bad <unk> <unk> bad movie movie bad movie bad bad bad movie\n",
            "<sos> <unk> favorite movie <unk> made <unk> <unk> <unk> film <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> film <unk> <unk> film <unk>\n",
            "<sos> <unk> best movie ever ever heard seen since would seen one <unk> one movie one worst worst worst worst ever ever ever ever\n",
            "<sos> <unk> worst movie ever ever seen seen since seen first saw movie <unk> <unk> first one <unk> one <unk> <unk> <unk> <unk> <unk>\n"
          ]
        }
      ],
      "source": [
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=5)\n",
        "\n",
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTwT0y51ZF7b",
        "outputId": "29fcc3d8-1376-4d4d-b1c1-d4b5844bc136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> <unk> <unk> <unk> <unk> <unk> <unk> film <unk> <unk> <unk> one <unk> la movie <unk> <unk> <unk> film <unk> <unk>\n",
            "<sos> <unk> favorite movie made really one worst best year ever seen ever think ever think bad good worst <unk> movie <unk> worst movies\n",
            "<sos> <unk> best movie ever ever seen seen saw im since first one movie one one would one saw time say movie would <unk>\n",
            "<sos> <unk> worst movie ever seen seen years years <unk> since <unk> movie <unk> saw <unk> saw <unk> movie going <unk> <unk> <unk> movie\n"
          ]
        }
      ],
      "source": [
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=10)\n",
        "\n",
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcgyH4mqZF7b",
        "outputId": "5bc9e583-cc46-4706-9d80-bca9f5ed4c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> <unk> <unk> always eastern eastern <unk> <unk> taking plot <unk> <unk> <unk> dock <unk> beautiful <unk> movie oshii dock <unk>\n",
            "<sos> <unk> favorite movie since ive ever yet ever seen seen ever since seen seen like long still <unk> still ive never seen liked\n",
            "<sos> <unk> best movie ever time remember didnt ever seen really liked one think im never cant heard saying good say didnt say good\n",
            "<sos> <unk> worst movie ever seen bad ever seen one even best seen movies acting movies watch ive usually movie bad worst life awful\n"
          ]
        }
      ],
      "source": [
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=50)\n",
        "\n",
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRUxekhYifvb"
      },
      "source": [
        "**Ответ:** С повышением значения top_k предложения становятся более разнообразными. Если выбирать top_k=1, то в предложении становится много повторений. Таким образом, увеличение top_k приводит к улучшению результата."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1gkFRXdifvc"
      },
      "source": [
        "## `Beam Search (2 балла)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eD08QOCifvc"
      },
      "source": [
        "Рассмотрим более продвинутый алгоритм для декодирования. Реализуйте алгоритм Beam Search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nAzZGA5ifvc"
      },
      "source": [
        "Несколько замечаний по имплементации:\n",
        "\n",
        "1. При больших размерах `beam_size` число гипотез ($B \\times \\text{beam\\_size}$) на очередном шаге может быть слишком большим. Поэтому может потребоваться разбить все гипотезы на отдельные батчи и делать forward-pass в несколько итераций. Используйте [`torch.split`](https://pytorch.org/docs/stable/generated/torch.split.html)\n",
        "2. Для выбора лучших гипотез используйте [`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html). Обратите внимание на индексы, которые возвращает эта функция (может пригодиться метод [`torch.remainder`](https://pytorch.org/docs/stable/generated/torch.remainder.html))\n",
        "3. Можно отслеживать, какие элементы в батче (или какие гипотезы) закончили генерацию. Делая forward-pass только для незавершённых гипотез, можно ускорить декодинг, однако, это усложнит реализацию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32T258dIifvc"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def decode_beam_search(model, start_tokens, start_tokens_lens, max_generated_len=20, beam_size=5):\n",
        "    \"\"\"\n",
        "    :param RNNLM model: Model\n",
        "    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
        "    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
        "    :param int max_generated_len: Maximum length of generated samples\n",
        "    :param int beam_size: Size of beam\n",
        "    :return Tuple[torch.Tensor, torch.Tensor, torch.Tensor].\n",
        "        Newly predicted tokens, probabilities for each hypotheses and lengths of generated parts\n",
        "        Shape [T*, B, beam_size], [T*, beam_size], [T*, beam_size]\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Initialize beams and hypotheses probabilities for each element in the batch\n",
        "    # 2. While all sequences do not end with <eos> and their length less than max_generated_len\n",
        "    #    1. Perform forward pass and obtain probabilities for all extensions\n",
        "    #    2. Compute probabilities for all hypotheses\n",
        "    #    3. Select top-beam_size hypotheses for each element in the batch\n",
        "    #    4. Take tokens that correspond to the chosen hypotheses\n",
        "    #    5. Concat new tokens to existing prefixes\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEYKDPYSifvc"
      },
      "source": [
        "Попробуйте выполнить декодинг для разных `beam_size`. Убедитесь, что при `beam_search=1` семплирование совпадает с top-1 (greedy decoding) подходом.\n",
        "\n",
        "Сравните результаты Beam Search с top-k семплированием и жадным декодированием. Опишите ваши наблюдения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKNqZTPzifvc"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T15:04:51.678260Z",
          "start_time": "2021-04-02T15:04:51.673587Z"
        },
        "id": "QREjqOXzifvd"
      },
      "source": [
        "## `Бонус. Существенное улучшение качества (до 6 баллов)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKNn-PZ4ifvd"
      },
      "source": [
        "Та модель, которая использовалась в предыдущей части во многом заимствует улучшения LSTM из статьи [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/pdf/1708.02182.pdf). Вы можете попробовать применить другие варианты регуляризации из данной статьи для существенного улучшения качества LM.\n",
        "\n",
        "Например:\n",
        "1. Dropout для эмбеддингов **(+0.25)**\n",
        "2. Dropout входов и выходов RNN **(+0.25)**\n",
        "3. Регуляризация активаций (AR/TAR) **(+1.0)**\n",
        "4. NT-ASGD **(+1.5)**\n",
        "5. Tied веса эмбеддингов и софтмакса **(+1.0)**\n",
        "6. Attention **(+2.0)**\n",
        "\n",
        "**Полные баллы ставятся только при наличии качественного и количественного сравнения с бейзлайном.**\n",
        "\n",
        "**Для эксперимента с Attention необходимо изобразить Attention Maps для нескольких примеров.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "804px",
        "left": "148px",
        "top": "50px",
        "width": "555.391px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "313px",
        "left": "926px",
        "right": "27px",
        "top": "120px",
        "width": "343px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}